def safe_validate(reply):
    try:
        if not isinstance(reply, dict):
            return reply
        # Only validate when tour is selected
        if not reply.get("tour_name"):
            return reply
        return AutoValidator.validate_response(reply)
    except Exception as e:
        try:
            reply.setdefault("warnings", []).append(str(e))
        except:
            pass
        return reply


# app.py - Ruby Wings Chatbot v4.0 (Complete Rewrite with Dataclasses)
# =========== IMPORTS ===========
import logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger("ruby-wings")
import os
import sys
import json
import threading
import logging
import re
import unicodedata
import traceback
import hashlib
import time
import random
from functools import lru_cache, wraps
from typing import List, Tuple, Dict, Optional, Any, Set, Union, Callable
from datetime import datetime, timedelta
from collections import defaultdict, deque
from difflib import SequenceMatcher
from enum import Enum
# Try to import numpy with detailed error handling
try:
    
    import numpy as np
    NUMPY_AVAILABLE = True
    logger.info("âœ… NumPy available")
except ImportError as e:
    logger.error(f"âŒ NumPy import failed: {e}")
    # Create a minimal numpy-like fallback for basic operations
    class NumpyFallback:
        def __init__(self):
            self.float32 = float
            self.int64 = int
            
        def array(self, data, dtype=None):
            # Simple list wrapper
            class SimpleArray:
                def __init__(self, data):
                    self.data = list(data)
                    self.shape = (len(data),) if isinstance(data[0], (int, float)) else (len(data), len(data[0]))
                
                def astype(self, dtype):
                    return self
                
                def reshape(self, shape):
                    return self
                
                def __getitem__(self, idx):
                    return self.data[idx]
                
                def __len__(self):
                    return len(self.data)
            
            return SimpleArray(data)
        
        def empty(self, shape, dtype):
            if len(shape) == 1:
                return [0.0] * shape[0]
            else:
                return [[0.0] * shape[1] for _ in range(shape[0])]
        
        def vstack(self, arrays):
            result = []
            for arr in arrays:
                if hasattr(arr, 'data'):
                    result.extend(arr.data)
                else:
                    result.extend(arr)
            return result
        
        def load(self, path):
            # Mock load function
            class MockNpz:
                def __init__(self):
                    self.files = ['mat']
                
                def __getitem__(self, key):
                    if key == 'mat':
                        # Return empty array
                        return self.array([[0.0]])
                    return None
            
            return MockNpz()
        
        def savez_compressed(self, path, **kwargs):
            # Mock save function
            logger.warning(f"âš ï¸ NumPy fallback: Mock saving to {path}")
            return None
    
    np = NumpyFallback()
    NUMPY_AVAILABLE = False
    logger.warning("âš ï¸ Using NumPy fallback - limited functionality")
from flask import Flask, request, jsonify, g
from flask_cors import CORS

# =========== ENTITY IMPORTS ===========
from entities import (
    QuestionType,
    ConversationState,
    PriceLevel,
    DurationType,
    Tour,
    UserProfile,
    SearchResult,
    ConversationContext,
    FilterSet,
    LLMRequest,
    ChatResponse,
    LeadData,
    CacheEntry,
    EnhancedJSONEncoder
)

# =========== CONFIGURATION ===========
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('ruby_wings.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger("rbw_v4")

# =========== IMPORTS WITH FALLBACKS ===========
HAS_FAISS = False
try:
    import faiss
    HAS_FAISS = True
    logger.info("âœ… FAISS available")
except ImportError:
    logger.warning("âš ï¸ FAISS not available, using numpy fallback")

HAS_OPENAI = False
client = None
try:
    from openai import OpenAI
    HAS_OPENAI = True
except ImportError:
    logger.warning("âš ï¸ OpenAI not available, using fallback responses")

# Google Sheets
try:
    import gspread
    from google.oauth2.service_account import Credentials
    from google.auth.exceptions import GoogleAuthError
    from gspread.exceptions import APIError, SpreadsheetNotFound, WorksheetNotFound
    HAS_GOOGLE_SHEETS = True
except ImportError:
    HAS_GOOGLE_SHEETS = False
    logger.warning("âš ï¸ Google Sheets not available")

# Meta CAPI
try:
    from meta_capi import send_meta_pageview, send_meta_lead, send_meta_call_button
    HAS_META_CAPI = True
    logger.info("âœ… Meta CAPI available")
except ImportError:
    HAS_META_CAPI = False
    logger.warning("âš ï¸ Meta CAPI not available")

# =========== ENVIRONMENT VARIABLES ===========
# Memory Profile
RAM_PROFILE = os.environ.get("RAM_PROFILE", "512").strip()
IS_LOW_RAM = RAM_PROFILE == "512"
IS_HIGH_RAM = RAM_PROFILE == "2048"

# Core API Keys
OPENAI_API_KEY = os.environ.get("OPENAI_API_KEY", "").strip()
OPENAI_BASE_URL = os.environ.get("OPENAI_BASE_URL", "").strip()
GOOGLE_SERVICE_ACCOUNT_JSON = os.environ.get("GOOGLE_SERVICE_ACCOUNT_JSON", "").strip()

# Knowledge & Index
KNOWLEDGE_PATH = os.environ.get("KNOWLEDGE_PATH", "knowledge.json")
FAISS_INDEX_PATH = os.environ.get("FAISS_INDEX_PATH", "faiss_index.bin")
FAISS_MAPPING_PATH = os.environ.get("FAISS_MAPPING_PATH", "faiss_mapping.json")
FALLBACK_VECTORS_PATH = os.environ.get("FALLBACK_VECTORS_PATH", "vectors.npz")

# Models
EMBEDDING_MODEL = os.environ.get("EMBEDDING_MODEL", "text-embedding-3-small")
CHAT_MODEL = os.environ.get("CHAT_MODEL", "gpt-4o-mini")
TOP_K = int(os.environ.get("TOP_K", "5"))

# FAISS
FAISS_ENABLED = os.environ.get("FAISS_ENABLED", "true").lower() in ("1", "true", "yes") and not IS_LOW_RAM

# Google Sheets
GOOGLE_SHEET_ID = os.environ.get("GOOGLE_SHEET_ID", "1SdVbwkuxb8l1meEW--ddyfh4WmUvSXXMOPQ5bCyPkdk")
GOOGLE_SHEET_NAME = os.environ.get("GOOGLE_SHEET_NAME", "RBW_Lead_Raw_Inbox")
ENABLE_GOOGLE_SHEETS = os.environ.get("ENABLE_GOOGLE_SHEETS", "true").lower() in ("1", "true", "yes")

# Storage
ENABLE_FALLBACK_STORAGE = os.environ.get("ENABLE_FALLBACK_STORAGE", "true").lower() in ("1", "true", "yes")
FALLBACK_STORAGE_PATH = os.environ.get("FALLBACK_STORAGE_PATH", "leads_fallback.json")

# Meta CAPI
META_CAPI_TOKEN = os.environ.get("META_CAPI_TOKEN", "").strip()
META_PIXEL_ID = os.environ.get("META_PIXEL_ID", "").strip()
META_CAPI_ENDPOINT = os.environ.get("META_CAPI_ENDPOINT", "https://graph.facebook.com/v17.0/")
ENABLE_META_CAPI_CALL = os.environ.get("ENABLE_META_CAPI_CALL", "true").lower() in ("1", "true", "yes")

# Server
FLASK_ENV = os.environ.get("FLASK_ENV", "production")
DEBUG = os.environ.get("DEBUG", "false").lower() in ("1", "true", "yes")
SECRET_KEY = os.environ.get("SECRET_KEY", "ruby-wings-secret-key-2024")
CORS_ORIGINS = os.environ.get("CORS_ORIGINS", "https://www.rubywings.vn,http://localhost:3000").split(",")
HOST = os.environ.get("HOST", "0.0.0.0")
PORT = int(os.environ.get("PORT", "10000"))

# =========== STATS TRACKING (FIX Lá»–I STATE) ===========
# ThÃªm global stats tracking system
STATS_LOCK = threading.Lock()
GLOBAL_STATS = {
    'meta_capi_calls': 0,
    'meta_capi_errors': 0,
    'leads': 0,
    'errors': 0,
    'total_requests': 0
}

def increment_stat(stat_name: str, amount: int = 1):
    """Thread-safe stat increment"""
    with STATS_LOCK:
        if stat_name in GLOBAL_STATS:
            GLOBAL_STATS[stat_name] += amount
        else:
            GLOBAL_STATS[stat_name] = amount

def get_stats() -> dict:
    """Get current stats"""
    with STATS_LOCK:
        return GLOBAL_STATS.copy()

# =========== UPGRADE FEATURE FLAGS ===========
class UpgradeFlags:
    """Control all 10 upgrades with environment variables"""
    
    @staticmethod
    def get_all_flags():
        return {
            # CORE UPGRADES (Essential fixes)
            "UPGRADE_1_MANDATORY_FILTER": os.environ.get("UPGRADE_1_MANDATORY_FILTER", "true").lower() == "true",
            "UPGRADE_2_DEDUPLICATION": os.environ.get("UPGRADE_2_DEDUPLICATION", "true").lower() == "true",
            "UPGRADE_3_ENHANCED_FIELDS": os.environ.get("UPGRADE_3_ENHANCED_FIELDS", "true").lower() == "true",
            "UPGRADE_4_QUESTION_PIPELINE": os.environ.get("UPGRADE_4_QUESTION_PIPELINE", "true").lower() == "true",
            
            # ADVANCED UPGRADES
            "UPGRADE_5_QUERY_SPLITTER": os.environ.get("UPGRADE_5_QUERY_SPLITTER", "true").lower() == "true",
            "UPGRADE_6_FUZZY_MATCHING": os.environ.get("UPGRADE_6_FUZZY_MATCHING", "true").lower() == "true",
            "UPGRADE_7_STATE_MACHINE": os.environ.get("UPGRADE_7_STATE_MACHINE", "true").lower() == "true",
            "UPGRADE_8_SEMANTIC_ANALYSIS": os.environ.get("UPGRADE_8_SEMANTIC_ANALYSIS", "true").lower() == "true",
            "UPGRADE_9_AUTO_VALIDATION": os.environ.get("UPGRADE_9_AUTO_VALIDATION", "true").lower() == "true",
            "UPGRADE_10_TEMPLATE_SYSTEM": os.environ.get("UPGRADE_10_TEMPLATE_SYSTEM", "true").lower() == "true",
            
            # PERFORMANCE OPTIONS
            "ENABLE_CACHING": os.environ.get("ENABLE_CACHING", "true").lower() == "true",
            "CACHE_TTL_SECONDS": int(os.environ.get("CACHE_TTL_SECONDS", "300")),
            "ENABLE_QUERY_LOGGING": os.environ.get("ENABLE_QUERY_LOGGING", "true").lower() == "true",
            
            # MEMORY OPTIMIZATION
            "EMBEDDING_CACHE_SIZE": 100 if IS_LOW_RAM else 1000,
            "TOUR_CACHE_ENABLED": not IS_LOW_RAM,
            "PRELOAD_EMBEDDINGS": not IS_LOW_RAM,
        }
    
    @staticmethod
    def is_enabled(upgrade_name: str) -> bool:
        flags = UpgradeFlags.get_all_flags()
        return flags.get(f"UPGRADE_{upgrade_name}", False)

# =========== FLASK APP CONFIG ===========
app = Flask(__name__)
app.json_encoder = EnhancedJSONEncoder  # Use custom JSON encoder
CORS(app, origins=CORS_ORIGINS, supports_credentials=True)

# =========== GLOBAL STATE (USING DATACLASSES) ===========
# Initialize OpenAI client
# ==== OpenAI client (SDK 1.x safe, Render compatible) ====
from openai import OpenAI
import httpx
import os

def create_openai_client():
    api_key = os.getenv("OPENAI_API_KEY")
    if not api_key:
        raise RuntimeError("OPENAI_API_KEY is not set")

    # Render-safe HTTP client (no proxies param in OpenAI 1.x)
    http_client = httpx.Client(
        timeout=60.0,
        follow_redirects=True
    )

    return OpenAI(
        api_key=api_key,
        http_client=http_client
    )

# Create global OpenAI client
client = create_openai_client()


# Knowledge base state
KNOW: Dict = {}                      # Raw knowledge.json data
FLAT_TEXTS: List[str] = []           # All text passages for indexing
MAPPING: List[Dict] = []             # Mapping from text to original path
INDEX = None                         # FAISS or numpy index
INDEX_LOCK = threading.Lock()        # Thread safety for index operations

# Tour databases (USING Tour DATACLASS)
TOUR_NAME_TO_INDEX: Dict[str, int] = {}      # Normalized tour name â†’ index
TOURS_DB: Dict[int, Tour] = {}               # Structured tour database using Tour objects
TOUR_TAGS: Dict[int, List[str]] = {}         # Auto-generated tags for filtering

# Session management (USING ConversationContext DATACLASS)
SESSION_CONTEXTS: Dict[str, ConversationContext] = {}
SESSION_LOCK = threading.Lock()
SESSION_TIMEOUT = 1800  # 30 minutes

# Cache system
_response_cache: Dict[str, CacheEntry] = {}
_cache_lock = threading.Lock()

# Embedding cache (memory optimized)
_embedding_cache: Dict[str, Tuple[List[float], int]] = {}
_embedding_cache_lock = threading.Lock()
MAX_EMBEDDING_CACHE_SIZE = UpgradeFlags.get_all_flags()["EMBEDDING_CACHE_SIZE"]

# =========== MEMORY OPTIMIZATION FUNCTIONS ===========
def optimize_for_memory_profile():
    """Apply memory optimizations based on RAM profile"""
    flags = UpgradeFlags.get_all_flags()
    
    if IS_LOW_RAM:
        logger.info("ðŸ§  Low RAM mode (512MB) - optimizing memory usage")
        # Disable heavy preloading
        global FAISS_ENABLED
        FAISS_ENABLED = False
        
        # Reduce cache sizes
        import functools
        functools.lru_cache(maxsize=128)(embed_text)
        
        # Limit tour loading
        global MAX_TOURS_TO_LOAD
        MAX_TOURS_TO_LOAD = 50
        
    elif IS_HIGH_RAM:
        logger.info("ðŸš€ High RAM mode (2GB) - enabling all features")
        # Enable all features
        FAISS_ENABLED = HAS_FAISS
        MAX_TOURS_TO_LOAD = 1000
        
        # Increase cache sizes
        import functools
        functools.lru_cache(maxsize=flags["EMBEDDING_CACHE_SIZE"])(embed_text)

# =========== UPGRADE 1: MANDATORY FILTER SYSTEM (DATACLASS COMPATIBLE) ===========
class MandatoryFilterSystem:
    """
    UPGRADE 1: Extract and apply mandatory filters BEFORE semantic search
    """
    
    FILTER_PATTERNS = {
        'duration': [
            (r'(?:thá»i gian|máº¥y ngÃ y|bao lÃ¢u|kÃ©o dÃ i)\s*(?:lÃ \s*)?(\d+)\s*(?:ngÃ y|Ä‘Ãªm)', 'exact_duration'),
            (r'(\d+)\s*ngÃ y\s*(?:vÃ \s*)?(\d+)?\s*Ä‘Ãªm', 'days_nights'),
            (r'(\d+)\s*ngÃ y\s*(?:trá»Ÿ lÃªn|trá»Ÿ xuá»‘ng)', 'duration_range'),
            (r'(?:tour|hÃ nh trÃ¬nh)\s*(?:khoáº£ng|táº§m|khoáº£ng)?\s*(\d+)\s*ngÃ y', 'approx_duration'),
        ],
        
        'price': [
            (r'dÆ°á»›i\s*(\d[\d,\.]*)\s*(triá»‡u|tr|k|nghÃ¬n)', 'max_price'),
            (r'trÃªn\s*(\d[\d,\.]*)\s*(triá»‡u|tr|k|nghÃ¬n)', 'min_price'),
            (r'khoáº£ng\s*(\d[\d,\.]*)\s*(?:Ä‘áº¿n|-)\s*(\d[\d,\.]*)\s*(triá»‡u|tr|k|nghÃ¬n)', 'price_range'),
            (r'giÃ¡\s*(?:tá»«\s*)?(\d[\d,\.]*)\s*(?:Ä‘áº¿n|-|tá»›i)\s*(\d[\d,\.]*)\s*(triá»‡u|tr|k|nghÃ¬n)', 'price_range'),
            (r'(\d[\d,\.]*)\s*(triá»‡u|tr|k|nghÃ¬n)\s*trá»Ÿ xuá»‘ng', 'max_price'),
            (r'(\d[\d,\.]*)\s*(triá»‡u|tr|k|nghÃ¬n)\s*trá»Ÿ lÃªn', 'min_price'),
        ],
        
        'location': [
            (r'(?:á»Ÿ|táº¡i|vá»|Ä‘áº¿n|thÄƒm)\s+([^.,!?\n]+?)(?:\s|$|\.|,|!|\?)', 'location'),
            (r'(?:Ä‘iá»ƒm Ä‘áº¿n|Ä‘á»‹a Ä‘iá»ƒm|nÆ¡i|vÃ¹ng)\s+(?:lÃ \s*)?([^.,!?\n]+)', 'location'),
            (r'(?:quanh|gáº§n|khu vá»±c)\s+([^.,!?\n]+)', 'near_location'),
        ],
        
        'date_time': [
            (r'(?:thÃ¡ng|vÃ o)\s*(\d{1,2})', 'month'),
            (r'(?:cuá»‘i tuáº§n|weekend)', 'weekend'),
            (r'(?:dá»‹p|lá»…|táº¿t)\s+([^.,!?\n]+)', 'holiday'),
        ],
        
        'group_type': [
            (r'(?:gia Ä‘Ã¬nh|family)', 'family'),
            (r'(?:cáº·p Ä‘Ã´i|couple|Ä‘Ã´i lá»©a)', 'couple'),
            (r'(?:nhÃ³m báº¡n|báº¡n bÃ¨|friends)', 'friends'),
            (r'(?:cÃ´ng ty|doanh nghiá»‡p|team building)', 'corporate'),
            (r'(?:má»™t mÃ¬nh|Ä‘i láº»|solo)', 'solo'),
        ],
    }
    
    @staticmethod
    def extract_filters(message: str) -> FilterSet:
        """
        Extract ALL mandatory filters from user message
        """
        filters = FilterSet()
        
        if not message:
            return filters
        
        message_lower = message.lower()
        
        # 1. DURATION FILTERS
        for pattern, filter_type in MandatoryFilterSystem.FILTER_PATTERNS['duration']:
            matches = list(re.finditer(pattern, message_lower))
            for match in matches:
                if filter_type == 'exact_duration':
                    try:
                        days = int(match.group(1))
                        filters.duration_min = days
                        filters.duration_max = days
                    except (ValueError, IndexError):
                        pass
                elif filter_type == 'days_nights':
                    try:
                        days = int(match.group(1))
                        nights = int(match.group(2)) if match.group(2) else days
                        # Store in appropriate fields
                        filters.duration_min = days
                        filters.duration_max = days
                    except (ValueError, IndexError):
                        pass
        
        # 2. PRICE FILTERS
        for pattern, filter_type in MandatoryFilterSystem.FILTER_PATTERNS['price']:
            matches = list(re.finditer(pattern, message_lower))
            for match in matches:
                try:
                    if filter_type == 'max_price':
                        amount = MandatoryFilterSystem._parse_price(match.group(1), match.group(2))
                        if amount:
                            filters.price_max = amount
                            logger.info(f"ðŸ’° Extracted MAX price filter: {amount} VND")
                    
                    elif filter_type == 'min_price':
                        amount = MandatoryFilterSystem._parse_price(match.group(1), match.group(2))
                        if amount:
                            filters.price_min = amount
                            logger.info(f"ðŸ’° Extracted MIN price filter: {amount} VND")
                    
                    elif filter_type == 'price_range':
                        min_amount = MandatoryFilterSystem._parse_price(match.group(1), match.group(3))
                        max_amount = MandatoryFilterSystem._parse_price(match.group(2), match.group(3))
                        if min_amount and max_amount:
                            filters.price_min = min_amount
                            filters.price_max = max_amount
                            logger.info(f"ðŸ’° Extracted PRICE RANGE: {min_amount} - {max_amount} VND")
                
                except (ValueError, IndexError, AttributeError):
                    continue
        
        # 3. LOCATION FILTERS
        for pattern, filter_type in MandatoryFilterSystem.FILTER_PATTERNS['location']:
            matches = list(re.finditer(pattern, message_lower))
            for match in matches:
                location = match.group(1).strip()
                if location and len(location) > 1:
                    if filter_type == 'location':
                        filters.location = location
                    elif filter_type == 'near_location':
                        filters.near_location = location
        
        # 4. DATE/TIME FILTERS
        for pattern, filter_type in MandatoryFilterSystem.FILTER_PATTERNS['date_time']:
            matches = list(re.finditer(pattern, message_lower))
            for match in matches:
                if filter_type == 'month':
                    try:
                        filters.month = int(match.group(1))
                    except (ValueError, IndexError):
                        pass
                elif filter_type == 'weekend':
                    filters.weekend = True
                elif filter_type == 'holiday':
                    filters.holiday = match.group(1).strip()
        
        # 5. GROUP TYPE FILTERS
        for pattern, filter_type in MandatoryFilterSystem.FILTER_PATTERNS['group_type']:
            if re.search(pattern, message_lower):
                filters.group_type = filter_type
        
        # 6. SPECIAL KEYWORDS
        special_keywords = {
            'ráº»': ('price_max', 1500000),
            'giÃ¡ ráº»': ('price_max', 1500000),
            'tiáº¿t kiá»‡m': ('price_max', 1500000),
            'cao cáº¥p': ('price_min', 3000000),
            'sang trá»ng': ('price_min', 3000000),
            'premium': ('price_min', 3000000),
            'ngáº¯n ngÃ y': ('duration_max', 2),
            'dÃ i ngÃ y': ('duration_min', 3),
        }
        
        for keyword, (filter_key, value) in special_keywords.items():
            if keyword in message_lower:
                if filter_key == 'price_max':
                    filters.price_max = value
                elif filter_key == 'price_min':
                    filters.price_min = value
                elif filter_key == 'duration_max':
                    filters.duration_max = value
                elif filter_key == 'duration_min':
                    filters.duration_min = value
        
        logger.info(f"ðŸŽ¯ Extracted filters: {filters}")
        return filters
    
    @staticmethod
    def _parse_price(amount_str: str, unit: str) -> Optional[int]:
        """Parse price string like '1.5 triá»‡u' to integer VND"""
        if not amount_str:
            return None
        
        try:
            amount_str = amount_str.replace(',', '').replace('.', '')
            if not amount_str.isdigit():
                return None
            
            amount = int(amount_str)
            
            if unit in ['triá»‡u', 'tr']:
                return amount * 1000000
            elif unit == 'k':
                return amount * 1000
            elif unit == 'nghÃ¬n':
                return amount * 1000
            else:
                return amount if amount > 1000 else amount * 1000
        
        except (ValueError, AttributeError):
            return None
    
    @staticmethod
    def apply_filters(tours_db: Dict[int, Tour], filters: FilterSet) -> List[int]:
        """
        Apply mandatory filters to tour database
        Returns list of tour indices that pass ALL filters
        """
        if filters.is_empty() or not tours_db:
            return list(tours_db.keys())
        
        passing_tours = []
        
        try:
            for tour_idx, tour in tours_db.items():
                passes_all = True
                
                # PRICE FILTERING
                if passes_all and (filters.price_max is not None or filters.price_min is not None):
                    tour_price_text = tour.price or ""
                    if not tour_price_text:
                        if filters.price_max is not None or filters.price_min is not None:
                            passes_all = False
                    else:
                        tour_prices = MandatoryFilterSystem._extract_tour_prices(tour_price_text)
                        if not tour_prices:
                            passes_all = False
                        else:
                            min_tour_price = min(tour_prices)
                            max_tour_price = max(tour_prices)
                            
                            if filters.price_max is not None and min_tour_price > filters.price_max:
                                passes_all = False
                            if filters.price_min is not None and max_tour_price < filters.price_min:
                                passes_all = False
                
                # DURATION FILTERING
                if passes_all and (filters.duration_min is not None or filters.duration_max is not None):
                    duration_text = (tour.duration or "").lower()
                    tour_duration = MandatoryFilterSystem._extract_duration_days(duration_text)
                    
                    if tour_duration is not None:
                        if filters.duration_min is not None and tour_duration < filters.duration_min:
                            passes_all = False
                        if filters.duration_max is not None and tour_duration > filters.duration_max:
                            passes_all = False
                    else:
                        if filters.duration_min is not None or filters.duration_max is not None:
                            passes_all = False
                
                # LOCATION FILTERING
                if passes_all and (filters.location is not None or filters.near_location is not None):
                    tour_location = (tour.location or "").lower()
                    if filters.location is not None:
                        filter_location = filters.location.lower()
                        if filter_location not in tour_location:
                            passes_all = False
                    if filters.near_location is not None:
                        near_location = filters.near_location.lower()
                        if near_location not in tour_location:
                            passes_all = False
                
                if passes_all:
                    passing_tours.append(tour_idx)
            
            logger.info(f"ðŸ” After mandatory filtering: {len(passing_tours)}/{len(tours_db)} tours pass")
        except Exception as e:
            logger.error(f"âŒ Error in apply_filters: {e}")
            passing_tours = list(tours_db.keys())
        
        return passing_tours
    
    @staticmethod
    def _extract_tour_prices(price_text: str) -> List[int]:
        """Extract price numbers from tour price text"""
        prices = []
        
        number_patterns = [
            r'(\d[\d,\.]+)\s*(?:triá»‡u|tr)',
            r'(\d[\d,\.]+)\s*(?:k|nghÃ¬n)',
            r'(\d[\d,\.]+)\s*(?:Ä‘á»“ng|vnÄ‘|vnd)',
            r'(\d[\d,\.]+)\s*-\s*(\d[\d,\.]+)',
        ]
        
        for pattern in number_patterns:
            matches = re.finditer(pattern, price_text, re.IGNORECASE)
            for match in matches:
                try:
                    for i in range(1, 3):
                        if match.group(i):
                            num_str = match.group(i).replace(',', '').replace('.', '')
                            if num_str.isdigit():
                                num = int(num_str)
                                
                                if 'triá»‡u' in match.group(0).lower() or 'tr' in match.group(0).lower():
                                    num = num * 1000000
                                elif 'k' in match.group(0).lower() or 'nghÃ¬n' in match.group(0).lower():
                                    num = num * 1000
                                
                                prices.append(num)
                except (ValueError, AttributeError):
                    continue
        
        if not prices:
            raw_numbers = re.findall(r'\d[\d,\.]+', price_text)
            for num_str in raw_numbers[:2]:
                try:
                    num_str = num_str.replace(',', '').replace('.', '')
                    if num_str.isdigit():
                        num = int(num_str)
                        if 100 <= num <= 10000:
                            num = num * 1000
                        prices.append(num)
                except ValueError:
                    continue
        
        return prices
    
    @staticmethod
    def _extract_duration_days(duration_text: str) -> Optional[int]:
        """Extract duration in days from text"""
        if not duration_text:
            return None
        
        patterns = [
            r'(\d+)\s*ngÃ y',
            r'(\d+)\s*ngÃ y\s*\d*\s*Ä‘Ãªm',
            r'(\d+)\s*Ä‘Ãªm',
        ]
        
        for pattern in patterns:
            match = re.search(pattern, duration_text)
            if match:
                try:
                    return int(match.group(1))
                except (ValueError, IndexError):
                    continue
        
        return None

# =========== UPGRADE 2: DEDUPLICATION ENGINE (DATACLASS COMPATIBLE) ===========
class DeduplicationEngine:
    """
    UPGRADE 2: Remove duplicate and highly similar results
    """
    
    SIMILARITY_THRESHOLD = 0.85
    MIN_TEXT_LENGTH = 20
    
    @staticmethod
    def calculate_similarity(text1: str, text2: str) -> float:
        """Calculate text similarity using multiple methods"""
        if not text1 or not text2:
            return 0.0
        
        text1_norm = DeduplicationEngine._normalize_text(text1)
        text2_norm = DeduplicationEngine._normalize_text(text2)
        
        if len(text1_norm) < DeduplicationEngine.MIN_TEXT_LENGTH or len(text2_norm) < DeduplicationEngine.MIN_TEXT_LENGTH:
            return 0.0
        
        seq_ratio = SequenceMatcher(None, text1_norm, text2_norm).ratio()
        
        words1 = set(text1_norm.split())
        words2 = set(text2_norm.split())
        
        if not words1 or not words2:
            jaccard = 0.0
        else:
            intersection = words1.intersection(words2)
            union = words1.union(words2)
            jaccard = len(intersection) / len(union)
        
        prefix_len = min(50, min(len(text1_norm), len(text2_norm)))
        prefix1 = text1_norm[:prefix_len]
        prefix2 = text2_norm[:prefix_len]
        prefix_sim = SequenceMatcher(None, prefix1, prefix2).ratio()
        
        similarity = (seq_ratio * 0.5) + (jaccard * 0.3) + (prefix_sim * 0.2)
        
        return similarity
    
    @staticmethod
    def _normalize_text(text: str) -> str:
        """Normalize text for comparison"""
        if not text:
            return ""
        
        text = text.lower()
        text = unicodedata.normalize('NFD', text)
        text = ''.join(c for c in text if unicodedata.category(c) != 'Mn')
        text = re.sub(r'[^\w\s]', ' ', text)
        text = re.sub(r'\s+', ' ', text).strip()
        
        stopwords = {'vÃ ', 'cá»§a', 'cho', 'vá»›i', 'táº¡i', 'á»Ÿ', 'nÃ y', 'Ä‘Ã³', 'kia', 'vá»', 'trong'}
        words = [word for word in text.split() if word not in stopwords]
        
        return ' '.join(words)
    
    @staticmethod
    def deduplicate_passages(passages: List[Tuple[float, Dict]], 
                            similarity_threshold: float = None) -> List[Tuple[float, Dict]]:
        """
        Remove duplicate passages from results
        """
        if len(passages) <= 1:
            return passages
        
        threshold = similarity_threshold or DeduplicationEngine.SIMILARITY_THRESHOLD
        unique_passages = []
        seen_passages = []
        
        sorted_passages = sorted(passages, key=lambda x: x[0], reverse=True)
        
        for score, passage in sorted_passages:
            text = passage.get('text', '').strip()
            path = passage.get('path', '')
            
            if not text or len(text) < DeduplicationEngine.MIN_TEXT_LENGTH:
                unique_passages.append((score, passage))
                continue
            
            is_duplicate = False
            for seen_text, seen_path in seen_passages:
                tour_match1 = re.search(r'tours\[(\d+)\]', path)
                tour_match2 = re.search(r'tours\[(\d+)\]', seen_path)
                
                if tour_match1 and tour_match2:
                    if tour_match1.group(1) == tour_match2.group(1):
                        field1 = path.split('.')[-1] if '.' in path else ''
                        field2 = seen_path.split('.')[-1] if '.' in seen_path else ''
                        if field1 == field2:
                            is_duplicate = True
                            break
                
                similarity = DeduplicationEngine.calculate_similarity(text, seen_text)
                if similarity > threshold:
                    is_duplicate = True
                    break
            
            if not is_duplicate:
                unique_passages.append((score, passage))
                seen_passages.append((text, path))
        
        logger.info(f"ðŸ”„ Deduplication: {len(passages)} â†’ {len(unique_passages)} passages")
        return unique_passages
    
    @staticmethod
    def merge_similar_tours(tour_indices: List[int], tours_db: Dict[int, Tour]) -> List[int]:
        """Merge tours that are essentially the same"""
        if len(tour_indices) <= 1:
            return tour_indices
        
        tour_groups = []
        processed = set()
        
        for i, idx1 in enumerate(tour_indices):
            if idx1 in processed:
                continue
            
            group = [idx1]
            tour1 = tours_db.get(idx1)
            name1 = (tour1.name if tour1 else "").strip()
            
            if not name1:
                processed.add(idx1)
                tour_groups.append(group)
                continue
            
            for j, idx2 in enumerate(tour_indices[i+1:], i+1):
                if idx2 in processed:
                    continue
                
                tour2 = tours_db.get(idx2)
                name2 = (tour2.name if tour2 else "").strip()
                
                if not name2:
                    continue
                
                similarity = DeduplicationEngine.calculate_similarity(name1, name2)
                if similarity > 0.9:
                    group.append(idx2)
                    processed.add(idx2)
            
            processed.add(idx1)
            tour_groups.append(group)
        
        best_tours = []
        for group in tour_groups:
            if not group:
                continue
            
            if len(group) == 1:
                best_tours.append(group[0])
                continue
            
            best_score = -1
            best_idx = group[0]
            
            for idx in group:
                tour = tours_db.get(idx)
                if not tour:
                    continue
                
                score = 0
                
                if tour.name:
                    score += 2
                if tour.duration:
                    score += 2
                if tour.location:
                    score += 2
                if tour.price:
                    score += 3
                if tour.includes:
                    score += 2
                if tour.summary:
                    score += 1
                
                for field in [tour.includes, tour.summary, tour.notes]:
                    if isinstance(field, str) and len(field) > 50:
                        score += 1
                    elif isinstance(field, list) and field:
                        score += len(field)
                
                if score > best_score:
                    best_score = score
                    best_idx = idx
            
            best_tours.append(best_idx)
        
        logger.info(f"ðŸ”„ Tour merging: {len(tour_indices)} â†’ {len(best_tours)} unique tours")
        return best_tours

# =========== UPGRADE 3: ENHANCED FIELD DETECTION (DATACLASS COMPATIBLE) ===========
class EnhancedFieldDetector:
    """
    UPGRADE 3: Better detection of what user is asking for
    """
    
    FIELD_DETECTION_RULES = [
        # TOUR LIST
        {
            "field": "tour_name",
            "patterns": [
                (r'liá»‡t kÃª.*tour|danh sÃ¡ch.*tour|cÃ¡c tour|cÃ³ nhá»¯ng tour nÃ o', 1.0),
                (r'tour nÃ o.*cÃ³|tour nÃ o.*hiá»‡n|tour nÃ o.*Ä‘ang', 0.9),
                (r'ká»ƒ tÃªn.*tour|nÃªu tÃªn.*tour|tÃªn cÃ¡c tour', 0.9),
                (r'cÃ³ máº¥y.*tour|bao nhiÃªu.*tour|sá»‘ lÆ°á»£ng.*tour', 0.8),
                (r'list tour|show tour|all tour|every tour', 0.8),
            ],
            "keywords": [
                ("liá»‡t kÃª", 0.9), ("danh sÃ¡ch", 0.9), ("cÃ¡c", 0.7),
                ("táº¥t cáº£", 0.8), ("má»i", 0.7), ("máº¥y", 0.6),
                ("bao nhiÃªu", 0.7), ("sá»‘ lÆ°á»£ng", 0.7),
            ]
        },
        
        # PRICE
        {
            "field": "price",
            "patterns": [
                (r'giÃ¡.*bao nhiÃªu|bao nhiÃªu tiá»n|chi phÃ­.*bao nhiÃªu', 1.0),
                (r'giÃ¡ tour|giÃ¡ cáº£|giÃ¡ thÃ nh|chi phÃ­ tour', 0.9),
                (r'tour.*giÃ¡.*bao nhiÃªu|tour.*bao nhiÃªu tiá»n', 0.95),
                (r'pháº£i tráº£.*bao nhiÃªu|tá»‘n.*bao nhiÃªu|máº¥t.*bao nhiÃªu', 0.8),
                (r'Ä‘Ã³ng.*bao nhiÃªu|thanh toÃ¡n.*bao nhiÃªu', 0.8),
            ],
            "keywords": [
                ("giÃ¡", 0.8), ("tiá»n", 0.7), ("chi phÃ­", 0.8),
                ("Ä‘Ã³ng", 0.6), ("tráº£", 0.6), ("tá»‘n", 0.6),
                ("phÃ­", 0.7), ("kinh phÃ­", 0.7), ("tá»•ng chi", 0.7),
            ]
        },
        
        # DURATION
        {
            "field": "duration",
            "patterns": [
                (r'thá»i gian.*bao lÃ¢u|máº¥y ngÃ y.*Ä‘i|bao lÃ¢u.*tour', 1.0),
                (r'tour.*bao nhiÃªu ngÃ y|máº¥y ngÃ y.*tour', 0.9),
                (r'Ä‘i trong.*bao lÃ¢u|kÃ©o dÃ i.*bao lÃ¢u', 0.9),
                (r'thá»i lÆ°á»£ng.*bao nhiÃªu|thá»i gian.*dÃ i bao lÃ¢u', 0.8),
            ],
            "keywords": [
                ("bao lÃ¢u", 0.9), ("máº¥y ngÃ y", 0.9), ("thá»i gian", 0.8),
                ("kÃ©o dÃ i", 0.7), ("thá»i lÆ°á»£ng", 0.8), ("ngÃ y", 0.6),
                ("Ä‘Ãªm", 0.6), ("thá»i háº¡n", 0.7),
            ]
        },
        
        # LOCATION
        {
            "field": "location",
            "patterns": [
                (r'á»Ÿ Ä‘Ã¢u|Ä‘i Ä‘Ã¢u|Ä‘áº¿n Ä‘Ã¢u|tá»›i Ä‘Ã¢u|thÄƒm quan Ä‘Ã¢u', 1.0),
                (r'Ä‘á»‹a Ä‘iá»ƒm.*nÃ o|nÆ¡i nÃ o|vÃ¹ng nÃ o|khu vá»±c nÃ o', 0.9),
                (r'tour.*á»Ÿ.*Ä‘Ã¢u|hÃ nh trÃ¬nh.*Ä‘i.*Ä‘Ã¢u', 0.9),
                (r'khÃ¡m phÃ¡.*Ä‘Ã¢u|thÄƒm.*Ä‘Ã¢u|ghÃ©.*Ä‘Ã¢u', 0.8),
            ],
            "keywords": [
                ("á»Ÿ Ä‘Ã¢u", 1.0), ("Ä‘i Ä‘Ã¢u", 1.0), ("Ä‘áº¿n Ä‘Ã¢u", 0.9),
                ("tá»›i Ä‘Ã¢u", 0.9), ("Ä‘á»‹a Ä‘iá»ƒm", 0.8), ("nÆ¡i", 0.7),
                ("vÃ¹ng", 0.7), ("khu vá»±c", 0.7),
            ]
        },
        
        # SUMMARY
        {
            "field": "summary",
            "patterns": [
                (r'cÃ³ gÃ¬ hay|cÃ³ gÃ¬ Ä‘áº·c biá»‡t|cÃ³ gÃ¬ thÃº vá»‹', 0.9),
                (r'tour nÃ y tháº¿ nÃ o|hÃ nh trÃ¬nh ra sao|chuyáº¿n Ä‘i nhÆ° nÃ o', 0.8),
                (r'giá»›i thiá»‡u.*tour|mÃ´ táº£.*tour|nÃ³i vá».*tour', 0.8),
                (r'tour.*cÃ³ gÃ¬|Ä‘i.*Ä‘Æ°á»£c gÃ¬|tráº£i nghiá»‡m.*gÃ¬', 0.7),
                (r'Ä‘iá»ƒm nháº¥n.*tour|ná»•i báº­t.*gÃ¬|Ä‘áº·c sáº¯c.*gÃ¬', 0.7),
            ],
            "keywords": [
                ("cÃ³ gÃ¬", 0.7), ("tháº¿ nÃ o", 0.6), ("ra sao", 0.6),
                ("giá»›i thiá»‡u", 0.7), ("mÃ´ táº£", 0.7), ("nÃ³i vá»", 0.6),
                ("Ä‘iá»ƒm nháº¥n", 0.7), ("ná»•i báº­t", 0.7), ("Ä‘áº·c sáº¯c", 0.7),
            ]
        },
        
        # INCLUDES
        {
            "field": "includes",
            "patterns": [
                (r'lá»‹ch trÃ¬nh.*chi tiáº¿t|chÆ°Æ¡ng trÃ¬nh.*chi tiáº¿t', 0.9),
                (r'lÃ m gÃ¬.*tour|hoáº¡t Ä‘á»™ng.*gÃ¬|sinh hoáº¡t.*gÃ¬', 0.8),
                (r'tour.*gá»“m.*gÃ¬|bao gá»“m.*gÃ¬|gá»“m nhá»¯ng gÃ¬', 0.8),
                (r'Ä‘i Ä‘Ã¢u.*lÃ m gÃ¬|thÄƒm quan.*gÃ¬|khÃ¡m phÃ¡.*gÃ¬', 0.7),
            ],
            "keywords": [
                ("lá»‹ch trÃ¬nh", 0.8), ("chÆ°Æ¡ng trÃ¬nh", 0.8), ("lÃ m gÃ¬", 0.7),
                ("hoáº¡t Ä‘á»™ng", 0.7), ("sinh hoáº¡t", 0.6), ("gá»“m", 0.6),
                ("bao gá»“m", 0.7), ("gá»“m nhá»¯ng", 0.7),
            ]
        },
    ]
    
    @staticmethod
    def detect_field_with_confidence(message: str) -> Tuple[Optional[str], float, Dict[str, float]]:
        """
        Detect which field user is asking about with confidence scores
        """
        if not message:
            return None, 0.0, {}
        
        message_lower = message.lower()
        scores = {}
        
        for rule in EnhancedFieldDetector.FIELD_DETECTION_RULES:
            field = rule["field"]
            field_score = 0.0
            
            for pattern, weight in rule["patterns"]:
                if re.search(pattern, message_lower):
                    field_score = max(field_score, weight)
            
            for keyword, weight in rule["keywords"]:
                if keyword in message_lower:
                    position = message_lower.find(keyword)
                    position_factor = 1.0 - (position / max(len(message_lower), 1))
                    adjusted_weight = weight * (0.7 + 0.3 * position_factor)
                    field_score = max(field_score, adjusted_weight)
            
            if field_score > 0:
                field_score = min(field_score * 1.1, 1.0)
            
            scores[field] = field_score
        
        best_field = None
        best_score = 0.0
        
        for field, score in scores.items():
            if score > best_score:
                best_score = score
                best_field = field
        
        if (best_score < 0.3 and 
            ("cÃ³ gÃ¬" in message_lower or "tháº¿ nÃ o" in message_lower) and
            "tour" in message_lower):
            best_field = "summary"
            best_score = 0.6
        
        logger.info(f"ðŸ” Field detection: '{message}' â†’ {best_field} (confidence: {best_score:.2f})")
        return best_field, best_score, scores

# =========== UPGRADE 4: QUESTION PIPELINE (DATACLASS COMPATIBLE) ===========
class QuestionPipeline:
    """
    UPGRADE 4: Process different types of questions differently
    """
    
    @staticmethod
    def classify_question(message: str) -> Tuple[QuestionType, float, Dict]:
        """
        Classify question type with confidence and metadata
        """
        message_lower = message.lower()
        type_scores = defaultdict(float)
        metadata = {}
        
        # LISTING detection - CHá»ˆ khi yÃªu cáº§u rÃµ rÃ ng liá»‡t kÃª DANH SÃCH
        listing_patterns = [
            (r'liá»‡t kÃª.*táº¥t cáº£.*tour|danh sÃ¡ch.*táº¥t cáº£.*tour|táº¥t cáº£.*tour', 0.95),
            (r'liá»‡t kÃª.*tour|danh sÃ¡ch.*tour|list.*tour', 0.9),
            (r'ká»ƒ tÃªn.*tour|nÃªu tÃªn.*tour', 0.9),
            (r'cÃ³ nhá»¯ng.*tour nÃ o|cÃ³ máº¥y.*tour|máº¥y.*tour', 0.7),
            (r'bÃªn báº¡n.*cÃ³.*tour|hiá»‡n cÃ³.*tour', 0.75),
        ]
        
        for pattern, weight in listing_patterns:
            if re.search(pattern, message_lower):
                type_scores[QuestionType.LISTING] = max(
                    type_scores[QuestionType.LISTING], weight
                )
        
        # COMPARISON detection
        comparison_patterns = [
            (r'so sÃ¡nh.*vÃ |Ä‘á»‘i chiáº¿u.*vÃ ', 0.95),
            (r'khÃ¡c nhau.*nÃ o|giá»‘ng nhau.*nÃ o', 0.9),
            (r'nÃªn chá»n.*nÃ o|tá»‘t hÆ¡n.*nÃ o|hÆ¡n kÃ©m.*nÃ o', 0.85),
            (r'tour.*vÃ .*tour', 0.8),
            (r'sÃ¡nh.*vá»›i|Ä‘á»‘i chiáº¿u.*vá»›i', 0.8),
        ]
        
        for pattern, weight in comparison_patterns:
            if re.search(pattern, message_lower):
                type_scores[QuestionType.COMPARISON] = max(
                    type_scores[QuestionType.COMPARISON], weight
                )
                metadata['comparison_type'] = 'direct'
        
        # RECOMMENDATION detection
        recommendation_patterns = [
            (r'phÃ¹ há»£p.*vá»›i|nÃªn Ä‘i.*nÃ o|gá»£i Ã½.*tour', 0.95),
            (r'tour nÃ o.*phÃ¹ há»£p|phÃ¹ há»£p.*tour nÃ o', 0.95),
            (r'tour.*tá»‘t.*nháº¥t|hÃ nh trÃ¬nh.*hay nháº¥t|tour.*lÃ½ tÆ°á»Ÿng', 0.9),
            (r'Ä‘á» xuáº¥t.*tour|tÆ° váº¥n.*tour|chá»n.*tour nÃ o', 0.9),
            (r'tour nÃ o.*cho.*gia Ä‘Ã¬nh|tour.*gia Ä‘Ã¬nh|gia Ä‘Ã¬nh.*tour', 0.9),
            (r'tour nÃ o.*cho|dÃ nh cho.*tour|tour.*dÃ nh cho', 0.85),
            (r'nÃªn.*tour nÃ o|nÃªn chá»n.*tour|tour.*nÃªn', 0.85),
            (r'tour.*nháº¹ nhÃ ng|tour.*dá»…|tour.*phÃ¹ há»£p.*ngÆ°á»i', 0.85),
            (r'tour.*tráº» em|tour.*con nÃ­t|tour.*bÃ©', 0.85),
            (r'tour.*ngÆ°á»i lá»›n tuá»•i|tour.*cao tuá»•i|tour.*nghá»‰ dÆ°á»¡ng', 0.85),
            (r'chi phÃ­.*vá»«a pháº£i|giÃ¡.*phÃ¹ há»£p|giÃ¡.*há»£p lÃ½', 0.8),
            (r'cho.*tÃ´i|dÃ nh cho.*tÃ´i|há»£p vá»›i.*tÃ´i', 0.75),
            (r'náº¿u.*thÃ¬.*nÃªn.*tour|nÃªn chá»n.*tour', 0.8),
        ]
        
        for pattern, weight in recommendation_patterns:
            if re.search(pattern, message_lower):
                type_scores[QuestionType.RECOMMENDATION] = max(
                    type_scores[QuestionType.RECOMMENDATION], weight
                )
        
        # GREETING detection
        greeting_words = ['xin chÃ o', 'chÃ o', 'hello', 'hi', 'helo', 'chao']
        greeting_score = 0.0
        for word in greeting_words:
            if word in message_lower:
                if message_lower.startswith(word) or f" {word} " in message_lower or message_lower.endswith(f" {word}"):
                    greeting_score += 0.3
        
        other_intent_score = max([score for qtype, score in type_scores.items() 
                                 if qtype != QuestionType.GREETING], default=0.0)
        
        if greeting_score > 0.8 and other_intent_score < 0.3:
            type_scores[QuestionType.GREETING] = min(greeting_score, 1.0)
        
        # FAREWELL detection
        farewell_words = ['táº¡m biá»‡t', 'cáº£m Æ¡n', 'thanks', 'thank you', 'bye', 'goodbye']
        if any(word in message_lower for word in farewell_words):
            type_scores[QuestionType.FAREWELL] = 0.95
        
        # CALCULATION detection
        calculation_patterns = [
            (r'tÃ­nh toÃ¡n|tÃ­nh.*bao nhiÃªu|tá»•ng.*bao nhiÃªu', 0.9),
            (r'cá»™ng.*láº¡i|nhÃ¢n.*lÃªn|chia.*ra', 0.8),
            (r'bao nhiÃªu.*ngÆ°á»i|máº¥y.*ngÆ°á»i|sá»‘ lÆ°á»£ng.*ngÆ°á»i', 0.7),
        ]
        
        for pattern, weight in calculation_patterns:
            if re.search(pattern, message_lower):
                type_scores[QuestionType.CALCULATION] = max(
                    type_scores[QuestionType.CALCULATION], weight
                )
        
        # COMPLEX question detection
        complex_indicators = [
            ('vÃ ', 0.3), ('rá»“i', 0.4), ('sau Ä‘Ã³', 0.5),
            ('tiáº¿p theo', 0.5), ('ngoÃ i ra', 0.4), ('thÃªm ná»¯a', 0.4),
        ]
        
        complex_score = 0.0
        for indicator, weight in complex_indicators:
            if indicator in message_lower:
                complex_score += weight
        
        if complex_score > 0.8:
            type_scores[QuestionType.COMPLEX] = min(complex_score / 2, 1.0)
            metadata['complex_parts'] = QuestionPipeline._split_complex_question(message)
        
        # DEFAULT: INFORMATION request
        if not type_scores:
            type_scores[QuestionType.INFORMATION] = 0.6
        else:
            info_keywords = ['lÃ  gÃ¬', 'bao nhiÃªu', 'á»Ÿ Ä‘Ã¢u', 'khi nÃ o', 'tháº¿ nÃ o', 'ai', 'táº¡i sao']
            if any(keyword in message_lower for keyword in info_keywords):
                type_scores[QuestionType.INFORMATION] = max(
                    type_scores.get(QuestionType.INFORMATION, 0),
                    0.5
                )
        
        # Determine best type
        best_type = QuestionType.INFORMATION
        best_score = 0.0
        
        for qtype, score in type_scores.items():
            if score > best_score:
                best_score = score
                best_type = qtype
        
        if best_score < 0.5:
            best_type = QuestionType.INFORMATION
            best_score = 0.5
        
        logger.info(f"ðŸŽ¯ Question classification: '{message}' â†’ {best_type.value} (score: {best_score:.2f})")
        return best_type, best_score, metadata
    
    @staticmethod
    def _split_complex_question(message: str) -> List[str]:
        """Split complex multi-part question into simpler parts"""
        split_patterns = [
            r'\s+vÃ \s+',
            r'\s+rá»“i\s+',
            r'\s+sau Ä‘Ã³\s+',
            r'\s+tiáº¿p theo\s+',
            r'\s+ngoÃ i ra\s+',
            r'\s+thÃªm ná»¯a\s+',
            r'\s+Ä‘á»“ng thá»i\s+',
            r'\s+cuá»‘i cÃ¹ng\s+',
        ]
        
        parts = [message]
        
        for pattern in split_patterns:
            new_parts = []
            for part in parts:
                split_result = re.split(pattern, part, flags=re.IGNORECASE)
                new_parts.extend([p.strip() for p in split_result if p.strip()])
            parts = new_parts
        
        return parts
    
    @staticmethod
    def process_comparison_question(tour_indices: List[int], tours_db: Dict[int, Tour], 
                                  aspect: str = "", context: Dict = None) -> str:
        """
        Process comparison question between tours
        """
        if len(tour_indices) < 2:
            return "Cáº§n Ã­t nháº¥t 2 tour Ä‘á»ƒ so sÃ¡nh."
        
        tours_to_compare = []
        for idx in tour_indices[:3]:
            tour = tours_db.get(idx)
            if tour:
                tours_to_compare.append((idx, tour))
        
        if len(tours_to_compare) < 2:
            return "KhÃ´ng tÃ¬m tháº¥y Ä‘á»§ thÃ´ng tin tour Ä‘á»ƒ so sÃ¡nh."
        
        if not aspect:
            aspect = 'price'
        
        result_lines = []
        
        headers = ["TIÃŠU CHÃ"]
        for idx, tour in tours_to_compare:
            tour_name = tour.name or f'Tour #{idx}'
            headers.append(tour_name[:25])
        
        result_lines.append(" | ".join(headers))
        result_lines.append("-" * (len(headers) * 30))
        
        comparison_fields = [
            ('duration', 'â±ï¸ Thá»i gian'),
            ('location', 'ðŸ“ Äá»‹a Ä‘iá»ƒm'),
            ('price', 'ðŸ’° GiÃ¡ tour'),
            ('accommodation', 'ðŸ¨ Chá»— á»Ÿ'),
            ('meals', 'ðŸ½ï¸ Ä‚n uá»‘ng'),
            ('transport', 'ðŸš— Di chuyá»ƒn'),
            ('summary', 'ðŸ“ MÃ´ táº£'),
        ]
        
        for field, display_name in comparison_fields:
            if aspect and field != aspect and aspect not in ['all', 'táº¥t cáº£']:
                continue
            
            row = [display_name]
            all_values = []
            
            for idx, tour in tours_to_compare:
                value = getattr(tour, field, 'N/A')
                if isinstance(value, list):
                    value = ', '.join(value[:2])
                row.append(str(value)[:30])
                all_values.append(str(value).lower())
            
            if len(set(all_values)) > 1 or aspect == field:
                result_lines.append(" | ".join(row))
        
        result_lines.append("\n" + "="*50)
        result_lines.append("**ÄÃNH GIÃ & Gá»¢I Ã:**")
        
        durations = [tour.duration for _, tour in tours_to_compare]
        if any('1 ngÃ y' in d for d in durations) and any('2 ngÃ y' in d for d in durations):
            result_lines.append("â€¢ Náº¿u báº¡n cÃ³ Ã­t thá»i gian: Chá»n tour 1 ngÃ y")
            result_lines.append("â€¢ Náº¿u muá»‘n tráº£i nghiá»‡m sÃ¢u: Chá»n tour 2 ngÃ y")
        
        prices = []
        for _, tour in tours_to_compare:
            price_text = tour.price or ''
            price_nums = re.findall(r'\d[\d,\.]+', price_text)
            if price_nums:
                try:
                    price = int(price_nums[0].replace(',', '').replace('.', ''))
                    prices.append(price)
                except:
                    pass
        
        if len(prices) >= 2:
            min_price_idx = prices.index(min(prices))
            max_price_idx = prices.index(max(prices))
            
            if prices[max_price_idx] > prices[min_price_idx] * 1.5:
                result_lines.append(f"â€¢ Tiáº¿t kiá»‡m chi phÃ­: {headers[min_price_idx + 1]}")
                result_lines.append(f"â€¢ Tráº£i nghiá»‡m cao cáº¥p: {headers[max_price_idx + 1]}")
        
        result_lines.append("\nðŸ’¡ *LiÃªn há»‡ hotline 0332510486 Ä‘á»ƒ Ä‘Æ°á»£c tÆ° váº¥n chi tiáº¿t*")
        
        return "\n".join(result_lines)

# =========== UPGRADE 5: COMPLEX QUERY SPLITTER (DATACLASS COMPATIBLE) ===========
class ComplexQueryProcessor:
    """
    UPGRADE 5: Handle complex multi-condition queries
    """
    
    @staticmethod
    def split_query(query: str) -> List[Dict[str, Any]]:
        """
        Split complex query into sub-queries with priorities
        """
        sub_queries = []
        
        complexity_score = ComplexQueryProcessor._calculate_complexity(query)
        if complexity_score < 1.5:
            return [{
                'query': query,
                'priority': 1.0,
                'filters': {},
                'focus': 'general'
            }]
        
        conditions = ComplexQueryProcessor._extract_conditions(query)
        
        if len(conditions) <= 1:
            return [{
                'query': query,
                'priority': 1.0,
                'filters': conditions[0] if conditions else {},
                'focus': 'general'
            }]
        
        sub_queries.append({
            'query': query,
            'priority': 1.0,
            'filters': ComplexQueryProcessor._merge_conditions(conditions),
            'focus': 'specific'
        })
        
        location_conds = [c for c in conditions if 'location' in c]
        other_conds = [c for c in conditions if 'location' not in c]
        
        if location_conds and other_conds:
            for other_cond in other_conds[:2]:
                merged = ComplexQueryProcessor._merge_conditions(location_conds + [other_cond])
                sub_queries.append({
                    'query': f"{query} (focus on location + {list(other_cond.keys())[0]})",
                    'priority': 0.8,
                    'filters': merged,
                    'focus': list(other_cond.keys())[0]
                })
        
        important_conds = ['price', 'duration', 'location']
        for cond_type in important_conds:
            conds_of_type = [c for c in conditions if cond_type in c]
            if conds_of_type:
                sub_queries.append({
                    'query': f"{query} (focus on {cond_type})",
                    'priority': 0.6,
                    'filters': conds_of_type[0],
                    'focus': cond_type
                })
        
        sub_queries.sort(key=lambda x: x['priority'], reverse=True)
        
        logger.info(f"ðŸ”€ Split query into {len(sub_queries)} sub-queries")
        return sub_queries[:3]
    
    @staticmethod
    def _calculate_complexity(query: str) -> float:
        """Calculate how complex a query is"""
        complexity = 0.0
        
        aspects = {
            'price': ['giÃ¡', 'tiá»n', 'chi phÃ­', 'Ä‘áº¯t', 'ráº»'],
            'duration': ['ngÃ y', 'Ä‘Ãªm', 'bao lÃ¢u', 'thá»i gian'],
            'location': ['á»Ÿ', 'táº¡i', 'Ä‘áº¿n', 'vá»', 'Ä‘á»‹a Ä‘iá»ƒm'],
            'quality': ['tá»‘t', 'hay', 'Ä‘áº¹p', 'háº¥p dáº«n', 'thÃº vá»‹'],
            'type': ['thiá»n', 'khÃ­ cÃ´ng', 'retreat', 'chá»¯a lÃ nh'],
        }
        
        query_lower = query.lower()
        
        distinct_aspects = 0
        for aspect, keywords in aspects.items():
            if any(keyword in query_lower for keyword in keywords):
                distinct_aspects += 1
        
        complexity += distinct_aspects * 0.5
        complexity += min(len(query.split()) / 10, 1.0)
        
        conjunctions = ['vÃ ', 'vá»›i', 'cÃ³', 'cho', 'mÃ ', 'nhÆ°ng']
        for conj in conjunctions:
            if conj in query_lower:
                complexity += 0.3
        
        return complexity
    
    @staticmethod
    def _extract_conditions(query: str) -> List[Dict[str, Any]]:
        """Extract individual conditions from query"""
        conditions = []
        
        filters = MandatoryFilterSystem.extract_filters(query)
        
        if filters.price_min is not None or filters.price_max is not None:
            price_cond = {'price': {}}
            if filters.price_min is not None:
                price_cond['price']['min'] = filters.price_min
            if filters.price_max is not None:
                price_cond['price']['max'] = filters.price_max
            conditions.append(price_cond)
        
        if filters.duration_min is not None or filters.duration_max is not None:
            duration_cond = {'duration': {}}
            if filters.duration_min is not None:
                duration_cond['duration']['min'] = filters.duration_min
            if filters.duration_max is not None:
                duration_cond['duration']['max'] = filters.duration_max
            conditions.append(duration_cond)
        
        if filters.location:
            conditions.append({'location': filters.location})
        if filters.near_location:
            conditions.append({'near_location': filters.near_location})
        
        query_lower = query.lower()
        
        if any(word in query_lower for word in ['ráº»', 'giÃ¡ ráº»', 'tiáº¿t kiá»‡m']):
            conditions.append({'price_quality': 'budget'})
        if any(word in query_lower for word in ['cao cáº¥p', 'sang', 'premium']):
            conditions.append({'price_quality': 'premium'})
        
        if 'thiá»n' in query_lower:
            conditions.append({'activity_type': 'meditation'})
        if 'khÃ­ cÃ´ng' in query_lower:
            conditions.append({'activity_type': 'qigong'})
        if 'retreat' in query_lower:
            conditions.append({'activity_type': 'retreat'})
        if 'chá»¯a lÃ nh' in query_lower:
            conditions.append({'activity_type': 'healing'})
        
        tour_name_patterns = [
            r'tour\s+([^vÃ \s,]+)\s+vÃ \s+tour\s+([^\s,]+)',
            r'tour\s+([^\s,]+)\s+vá»›i\s+tour\s+([^\s,]+)',
            r'tour\s+([^\s,]+)\s+.*tour\s+([^\s,]+)',
        ]
        
        for pattern in tour_name_patterns:
            matches = re.finditer(pattern, query_lower)
            for match in matches:
                for i in range(1, 3):
                    if match.group(i):
                        tour_name = match.group(i).strip()
                        normalized_name = FuzzyMatcher.normalize_vietnamese(tour_name)
                        for name, idx in TOUR_NAME_TO_INDEX.items():
                            if normalized_name in name or name in normalized_name:
                                conditions.append({'specific_tour': idx})
                                logger.info(f"ðŸ” Extracted tour name from complex query: {tour_name} â†’ index {idx}")
        
        return conditions
    
    @staticmethod
    def _merge_conditions(conditions: List[Dict]) -> Dict[str, Any]:
        """Merge multiple conditions into one filter dict"""
        merged = {}
        
        for condition in conditions:
            for key, value in condition.items():
                if key in merged:
                    if isinstance(merged[key], dict) and isinstance(value, dict):
                        merged[key].update(value)
                    elif isinstance(merged[key], list) and isinstance(value, list):
                        merged[key].extend(value)
                    else:
                        if isinstance(value, dict) or (isinstance(value, str) and len(value) > len(str(merged[key]))):
                            merged[key] = value
                else:
                    merged[key] = value
        
        return merged

# =========== UPGRADE 6: FUZZY MATCHING (DATACLASS COMPATIBLE) ===========
class FuzzyMatcher:
    """
    UPGRADE 6: Handle misspellings and variations in tour names
    """
    
    SIMILARITY_THRESHOLD = 0.75
    
    @staticmethod
    def normalize_vietnamese(text: str) -> str:
        """
        Normalize Vietnamese text for fuzzy matching
        """
        if not text:
            return ""
        
        text = text.lower()
        text = unicodedata.normalize('NFD', text)
        text = ''.join(c for c in text if unicodedata.category(c) != 'Mn')
        
        replacements = {
            'Ä‘': 'd',
            'khÃ´ng': 'ko',
            'khong': 'ko',
            'rá»“i': 'roi',
            'vá»›i': 'voi',
            'Ä‘Æ°á»£c': 'duoc',
            'má»™t': 'mot',
            'hai': '2',
            'ba': '3',
            'bá»‘n': '4',
            'nÄƒm': '5',
        }
        
        for old, new in replacements.items():
            text = text.replace(old, new)
        
        text = re.sub(r'[^\w\s]', ' ', text)
        text = re.sub(r'\s+', ' ', text).strip()
        
        return text
    
    @staticmethod
    def find_similar_tours(query: str, tour_names: Dict[str, int]) -> List[Tuple[int, float]]:
        """
        Find tours with names similar to query
        """
        if not query or not tour_names:
            return []
        
        query_norm = FuzzyMatcher.normalize_vietnamese(query)
        if not query_norm:
            return []
        
        matches = []
        
        for tour_name, tour_idx in tour_names.items():
            tour_norm = FuzzyMatcher.normalize_vietnamese(tour_name)
            if not tour_norm:
                continue
            
            similarity = SequenceMatcher(None, query_norm, tour_norm).ratio()
            
            if query_norm in tour_norm or tour_norm in query_norm:
                similarity = min(similarity + 0.2, 1.0)
            
            query_words = set(query_norm.split())
            tour_words = set(tour_norm.split())
            common_words = query_words.intersection(tour_words)
            
            if common_words:
                word_boost = len(common_words) * 0.1
                similarity = min(similarity + word_boost, 1.0)
            
            if similarity >= FuzzyMatcher.SIMILARITY_THRESHOLD:
                matches.append((tour_idx, similarity))
        
        matches.sort(key=lambda x: x[1], reverse=True)
        
        logger.info(f"ðŸ” Fuzzy matching: '{query}' â†’ {len(matches)} matches")
        return matches
    
    @staticmethod
    def find_tour_by_partial_name(partial_name: str, tours_db: Dict[int, Tour]) -> List[int]:
        """
        Find tours by partial name match
        """
        if not partial_name or not tours_db:
            return []
        
        partial_norm = FuzzyMatcher.normalize_vietnamese(partial_name)
        matches = []
        
        for tour_idx, tour in tours_db.items():
            tour_name = tour.name or ""
            if not tour_name:
                continue
            
            tour_norm = FuzzyMatcher.normalize_vietnamese(tour_name)
            
            if partial_norm in tour_norm:
                match_ratio = len(partial_norm) / len(tour_norm) if tour_norm else 0
                matches.append((tour_idx, match_ratio))
        
        matches.sort(key=lambda x: x[1], reverse=True)
        
        return [idx for idx, _ in matches[:3]]

# =========== UPGRADE 7: STATE MACHINE (DATACLASS COMPATIBLE) ===========
class ConversationStateMachine:
    """
    UPGRADE 7: Track conversation state for better context
    """
    
    def __init__(self, session_id: str):
        self.session_id = session_id
        self.state = ConversationState.INITIAL
        self.context = ConversationContext(session_id=session_id)
        self.transitions = []
        self.created_at = datetime.utcnow()
        self.last_updated = datetime.utcnow()
    
    def update(self, user_message: str, bot_response: str, tour_indices: List[int] = None):
        """Update state based on new interaction"""
        self.last_updated = datetime.utcnow()
        self.context.update(user_message, bot_response, tour_indices)
        
        new_state = self._determine_state(user_message, bot_response)
        
        self.transitions.append({
            'timestamp': datetime.utcnow().isoformat(),
            'from': self.state.value,
            'to': new_state.value,
            'message': user_message[:100]
        })
        
        self.state = new_state
        
        logger.info(f"ðŸ”„ State update: {self.state.value} for session {self.session_id}")
    
    def _determine_state(self, user_message: str, bot_response: str) -> ConversationState:
        """Determine new state based on current interaction"""
        message_lower = user_message.lower()
        
        farewell_words = ['táº¡m biá»‡t', 'cáº£m Æ¡n', 'thanks', 'bye', 'goodbye']
        if any(word in message_lower for word in farewell_words):
            return ConversationState.FAREWELL
        
        tour_ref_patterns = [
            r'tour nÃ y', r'tour Ä‘Ã³', r'tour Ä‘ang nÃ³i', r'cÃ¡i tour',
            r'nÃ³', r'cÃ¡i Ä‘Ã³', r'cÃ¡i nÃ y', r'Ä‘áº¥y'
        ]
        
        if any(re.search(pattern, message_lower) for pattern in tour_ref_patterns):
            if self.context.current_tours:
                return ConversationState.TOUR_SELECTED
            elif self.context.last_successful_tours:
                self.context.current_tours = self.context.last_successful_tours
                return ConversationState.TOUR_SELECTED
        
        if 'so sÃ¡nh' in message_lower or 'sÃ¡nh' in message_lower:
            return ConversationState.COMPARING
        
        if any(word in message_lower for word in ['phÃ¹ há»£p', 'gá»£i Ã½', 'Ä‘á» xuáº¥t', 'tÆ° váº¥n', 'nÃªn chá»n']):
            return ConversationState.RECOMMENDATION
        
        if any(word in message_lower for word in ['Ä‘áº·t', 'booking', 'Ä‘Äƒng kÃ½', 'giá»¯ chá»—']):
            return ConversationState.BOOKING
        
        if self.context.current_tours:
            return ConversationState.ASKING_DETAILS
        
        return ConversationState.INITIAL
    
    def get_context_hint(self) -> str:
        """Get hint about current context for LLM prompt"""
        hints = []
        
        if self.state == ConversationState.TOUR_SELECTED and self.context.current_tours:
            tour_indices = self.context.current_tours
            if len(tour_indices) == 1:
                hints.append(f"User is asking about tour index {tour_indices[0]}")
            else:
                hints.append(f"User is asking about tours {tour_indices}")
        
        if self.context.user_preferences:
            prefs = []
            for key, value in self.context.user_preferences.items():
                prefs.append(f"{key}: {value}")
            if prefs:
                hints.append(f"User preferences: {', '.join(prefs)}")
        
        return "; ".join(hints) if hints else "No specific context"
    
    def extract_reference(self, message: str) -> List[int]:
        """Extract tour reference from message using conversation context"""
        message_lower = message.lower()
        
        if self.context.current_tours:
            for tour_idx in self.context.current_tours:
                tour = TOURS_DB.get(tour_idx)
                if not tour:
                    continue
                tour_name = (tour.name or "").lower()
                if tour_name:
                    tour_words = set(tour_name.split())
                    msg_words = set(message_lower.split())
                    common = tour_words.intersection(msg_words)
                    if common and len(common) >= 1:
                        logger.info(f"ðŸ”„ State machine: Using current tour {tour_idx}")
                        return self.context.current_tours
        
        ref_patterns = [
            (r'tour nÃ y', 1.0),
            (r'tour Ä‘Ã³', 0.9),
            (r'tour Ä‘ang nÃ³i', 0.9),
            (r'cÃ¡i tour', 0.8),
            (r'nÃ³', 0.7),
            (r'Ä‘áº¥y', 0.7),
            (r'cÃ¡i Ä‘Ã³', 0.7),
        ]
        
        for pattern, confidence in ref_patterns:
            if re.search(pattern, message_lower):
                if self.context.current_tours:
                    logger.info(f"ðŸ”„ State machine: Resolved reference to {self.context.current_tours}")
                    return self.context.current_tours
                elif self.context.last_successful_tours:
                    logger.info(f"ðŸ”„ State machine: Using last successful tours {self.context.last_successful_tours}")
                    return self.context.last_successful_tours
        
        if self.context.mentioned_tours:
            recent_tours = list(self.context.mentioned_tours)
            for tour_idx in recent_tours[-3:]:
                tour = TOURS_DB.get(tour_idx)
                if not tour:
                    continue
                tour_name = (tour.name or "").lower()
                if tour_name:
                    tour_words = set(tour_name.split())
                    msg_words = set(message_lower.split())
                    common = tour_words.intersection(msg_words)
                    if common and len(common) >= 1:
                        logger.info(f"ðŸ”„ State machine: Matched to recently mentioned tour {tour_idx}")
                        return [tour_idx]
        
        return []

# =========== UPGRADE 8: DEEP SEMANTIC ANALYSIS (DATACLASS COMPATIBLE) ===========
class SemanticAnalyzer:
    """
    UPGRADE 8: Deep understanding of user intent beyond keywords
    """
    
    USER_PROFILE_PATTERNS = {
        'age_group': [
            (r'ngÆ°á»i giÃ |ngÆ°á»i lá»›n tuá»•i|cao tuá»•i', 'senior'),
            (r'thanh niÃªn|tráº»|sinh viÃªn|há»c sinh', 'young'),
            (r'trung niÃªn|trung tuá»•i', 'middle_aged'),
            (r'gia Ä‘Ã¬nh.*tráº» em|tráº» nhá»|con nÃ­t', 'family_with_kids'),
        ],
        
        'group_type': [
            (r'má»™t mÃ¬nh|Ä‘i láº»|solo', 'solo'),
            (r'cáº·p Ä‘Ã´i|Ä‘Ã´i lá»©a|ngÆ°á»i yÃªu', 'couple'),
            (r'gia Ä‘Ã¬nh|bá»‘ máº¹ con', 'family'),
            (r'báº¡n bÃ¨|nhÃ³m báº¡n|há»™i báº¡n', 'friends'),
            (r'cÃ´ng ty|doanh nghiá»‡p|Ä‘á»“ng nghiá»‡p', 'corporate'),
        ],
        
        'interest_type': [
            (r'thiÃªn nhiÃªn|rá»«ng|cÃ¢y|cáº£nh quan', 'nature'),
            (r'lá»‹ch sá»­|di tÃ­ch|chiáº¿n tranh|tri Ã¢n', 'history'),
            (r'vÄƒn hÃ³a|cá»™ng Ä‘á»“ng|dÃ¢n tá»™c|truyá»n thá»‘ng', 'culture'),
            (r'thiá»n|tÃ¢m linh|tÄ©nh tÃ¢m|yoga', 'spiritual'),
            (r'khÃ­ cÃ´ng|sá»©c khá»e|chá»¯a lÃ nh|wellness', 'wellness'),
            (r'áº©m thá»±c|Ä‘á»“ Äƒn|mÃ³n ngon|Ä‘áº·c sáº£n', 'food'),
            (r'phiÃªu lÆ°u|máº¡o hiá»ƒm|khÃ¡m phÃ¡|tráº£i nghiá»‡m', 'adventure'),
        ],
        
        'budget_level': [
            (r'kinh táº¿|tiáº¿t kiá»‡m|ráº»|giÃ¡ tháº¥p', 'budget'),
            (r'trung bÃ¬nh|vá»«a pháº£i|pháº£i chÄƒng', 'midrange'),
            (r'cao cáº¥p|sang trá»ng|premium|Ä‘áº¯t', 'premium'),
        ],
        
        'physical_level': [
            (r'nháº¹ nhÃ ng|dá»… dÃ ng|khÃ´ng má»‡t', 'easy'),
            (r'vá»«a pháº£i|trung bÃ¬nh|bÃ¬nh thÆ°á»ng', 'moderate'),
            (r'thá»­ thÃ¡ch|khÃ³|má»‡t|leo nÃºi', 'challenging'),
        ],
    }
    
    @staticmethod
    def analyze_user_profile(message: str, current_context: ConversationContext = None) -> UserProfile:
        """
        Analyze message to build user profile
        """
        if current_context and hasattr(current_context, 'user_profile') and current_context.user_profile:
            profile = current_context.user_profile
        else:
            profile = UserProfile()
        
        message_lower = message.lower()
        
        for category, patterns in SemanticAnalyzer.USER_PROFILE_PATTERNS.items():
            for pattern, value in patterns:
                if re.search(pattern, message_lower):
                    if category == 'interests':
                        if value not in profile.interests:
                            profile.interests.append(value)
                            profile.confidence_scores[f'interest_{value}'] = 0.8
                    else:
                        setattr(profile, category, value)
                        profile.confidence_scores[category] = 0.8
        
        SemanticAnalyzer._infer_attributes(profile, message_lower)
        profile.overall_confidence = SemanticAnalyzer._calculate_confidence(profile)
        
        logger.info(f"ðŸ‘¤ User profile analysis: {profile}")
        return profile
    
    @staticmethod
    def _infer_attributes(profile: UserProfile, message_lower: str):
        """Infer additional attributes from context"""
        if not profile.age_group:
            if profile.group_type and 'family_with_kids' in profile.group_type:
                profile.age_group = 'middle_aged'
                profile.confidence_scores['age_group'] = 0.6
            elif 'senior' in message_lower or 'giÃ ' in message_lower:
                profile.age_group = 'senior'
                profile.confidence_scores['age_group'] = 0.7
        
        if not profile.physical_level:
            if 'adventure' in profile.interests:
                profile.physical_level = 'challenging'
                profile.confidence_scores['physical_level'] = 0.6
            elif 'spiritual' in profile.interests or 'wellness' in profile.interests:
                profile.physical_level = 'easy'
                profile.confidence_scores['physical_level'] = 0.6
        
        if not profile.budget_level:
            budget_keywords = {
                'budget': ['ráº»', 'tiáº¿t kiá»‡m', 'Ã­t tiá»n', 'kinh táº¿'],
                'premium': ['cao cáº¥p', 'sang', 'Ä‘áº¯t', 'premium']
            }
            
            for level, keywords in budget_keywords.items():
                if any(keyword in message_lower for keyword in keywords):
                    profile.budget_level = level
                    profile.confidence_scores['budget_level'] = 0.7
                    break
    
    @staticmethod
    def _calculate_confidence(profile: UserProfile) -> float:
        """Calculate overall confidence in user profile"""
        if not profile.confidence_scores:
            return 0.0
        
        total = 0.0
        count = 0
        
        for key, score in profile.confidence_scores.items():
            total += score
            count += 1
        
        return total / max(count, 1)
    
    @staticmethod
    def match_tours_to_profile(profile: UserProfile, tours_db: Dict[int, Tour], 
                              max_results: int = 5) -> List[Tuple[int, float, List[str]]]:
        """
        Match tours to user profile with explanation
        """
        matches = []
        
        for tour_idx, tour in tours_db.items():
            score = 0.0
            reasons = []
            
            tour_tags = tour.tags or []
            
            if profile.age_group:
                if profile.age_group == 'senior':
                    if any('easy' in tag for tag in tour_tags):
                        score += 0.3
                        reasons.append("phÃ¹ há»£p ngÆ°á»i lá»›n tuá»•i")
                    if any('nature' in tag for tag in tour_tags):
                        score += 0.2
                        reasons.append("thiÃªn nhiÃªn nháº¹ nhÃ ng")
            
            if profile.interests:
                for interest in profile.interests:
                    tour_summary = (tour.summary or "").lower()
                    if (interest in tour_summary or 
                        any(interest in tag for tag in tour_tags)):
                        score += 0.4
                        reasons.append(f"cÃ³ yáº¿u tá»‘ {interest}")
            
            if profile.budget_level:
                tour_price = tour.price or ""
                price_nums = re.findall(r'\d[\d,\.]+', tour_price)
                
                if price_nums:
                    try:
                        first_price = int(price_nums[0].replace(',', '').replace('.', ''))
                        
                        if profile.budget_level == 'budget' and first_price < 2000000:
                            score += 0.3
                            reasons.append("giÃ¡ há»£p lÃ½")
                        elif profile.budget_level == 'premium' and first_price > 2500000:
                            score += 0.3
                            reasons.append("cao cáº¥p")
                        elif profile.budget_level == 'midrange' and 1500000 <= first_price <= 3000000:
                            score += 0.3
                            reasons.append("giÃ¡ vá»«a pháº£i")
                    except:
                        pass
            
            if profile.physical_level:
                if profile.physical_level == 'easy':
                    if any('easy' in tag or 'meditation' in tag for tag in tour_tags):
                        score += 0.2
                        reasons.append("hoáº¡t Ä‘á»™ng nháº¹ nhÃ ng")
            
            if score > 0:
                matches.append((tour_idx, score, reasons))
        
        matches.sort(key=lambda x: x[1], reverse=True)
        
        return matches[:max_results]

# =========== UPGRADE 9: AUTO-VALIDATION SYSTEM (DATACLASS COMPATIBLE) ===========
class AutoValidator:
    """
    UPGRADE 9: Validate and correct information before returning
    """
    
    VALIDATION_RULES = {
        'duration': {
            'patterns': [
                r'(\d+)\s*ngÃ y\s*(\d+)\s*Ä‘Ãªm',
                r'(\d+)\s*ngÃ y',
                r'(\d+)\s*Ä‘Ãªm',
            ],
            'constraints': {
                'max_days': 7,
                'max_nights': 7,
                'valid_day_night_combos': [(1,0), (1,1), (2,1), (2,2), (3,2), (3,3)],
                'common_durations': ['1 ngÃ y', '2 ngÃ y 1 Ä‘Ãªm', '3 ngÃ y 2 Ä‘Ãªm']
            }
        },
        
        'price': {
            'patterns': [
                r'(\d[\d,\.]*)\s*(triá»‡u|tr|k|nghÃ¬n)',
                r'(\d[\d,\.]*)\s*-\s*(\d[\d,\.]*)\s*(triá»‡u|tr|k|nghÃ¬n)?',
                r'(\d[\d,\.]*)\s*(Ä‘á»“ng|vnÄ‘|vnd)',
            ],
            'constraints': {
                'min_tour_price': 500000,
                'max_tour_price': 10000000,
                'common_ranges': [
                    (800000, 1500000),
                    (1500000, 2500000),
                    (2500000, 4000000),
                ]
            }
        },
        
        'location': {
            'patterns': [
                r'á»Ÿ\s+([^.,!?]+)',
                r'táº¡i\s+([^.,!?]+)',
                r'Ä‘áº¿n\s+([^.,!?]+)',
            ],
            'constraints': {
                'valid_locations': ['Huáº¿', 'Quáº£ng Trá»‹', 'Báº¡ch MÃ£', 'TrÆ°á»ng SÆ¡n', 'ÄÃ´ng HÃ ', 'Khe Sanh'],
                'max_length': 100
            }
        },
    }
    
    @staticmethod
    def validate_response(response: str) -> str:
        """
        Validate and correct response content
        """
        if not response:
            return response
        
        validated = response
        
        validated = AutoValidator._validate_duration(validated)
        validated = AutoValidator._validate_price(validated)
        validated = AutoValidator._validate_locations(validated)
        validated = AutoValidator._check_unrealistic_info(validated)
        
        if validated != response:
            validated = AutoValidator._add_validation_note(validated)
        
        return validated
    
    @staticmethod
    def _validate_duration(text: str) -> str:
        """Validate and correct duration information"""
        for pattern in AutoValidator.VALIDATION_RULES['duration']['patterns']:
            matches = list(re.finditer(pattern, text))
            for match in matches:
                try:
                    if match.lastindex == 2:
                        days = int(match.group(1))
                        nights = int(match.group(2))
                        
                        constraints = AutoValidator.VALIDATION_RULES['duration']['constraints']
                        
                        valid_combos = constraints['valid_day_night_combos']
                        is_valid_combo = any(d == d2 and n == n2 for d2, n2 in valid_combos)
                        
                        if days > constraints['max_days'] or nights > constraints['max_nights']:
                            replacement = random.choice(constraints['common_durations'])
                            text = text.replace(match.group(0), replacement)
                            logger.warning(f"âš ï¸ Corrected unrealistic duration: {days} ngÃ y {nights} Ä‘Ãªm â†’ {replacement}")
                        
                        elif not is_valid_combo:
                            valid_days = min(days, constraints['max_days'])
                            valid_nights = min(nights, constraints['max_nights'])
                            if abs(valid_days - valid_nights) > 1:
                                valid_nights = valid_days
                            
                            replacement = f"{valid_days} ngÃ y {valid_nights} Ä‘Ãªm"
                            text = text.replace(match.group(0), replacement)
                            logger.info(f"ðŸ”„ Fixed duration combo: {replacement}")
                    
                    elif match.lastindex == 1:
                        num = int(match.group(1))
                        constraints = AutoValidator.VALIDATION_RULES['duration']['constraints']
                        
                        if num > constraints['max_days']:
                            replacement = f"{constraints['max_days']} ngÃ y"
                            text = text.replace(match.group(0), replacement)
                            logger.warning(f"âš ï¸ Capped long duration: {num} â†’ {constraints['max_days']}")
                
                except (ValueError, IndexError):
                    continue
        
        return text
    
    @staticmethod
    def _validate_price(text: str) -> str:
        """Validate and correct price information"""
        for pattern in AutoValidator.VALIDATION_RULES['price']['patterns']:
            matches = list(re.finditer(pattern, text, re.IGNORECASE))
            for match in matches:
                try:
                    amount_str = match.group(1).replace(',', '').replace('.', '')
                    if not amount_str.isdigit():
                        continue
                    
                    amount = int(amount_str)
                    
                    unit = match.group(2).lower() if match.lastindex >= 2 else ''
                    
                    if unit in ['triá»‡u', 'tr']:
                        amount = amount * 1000000
                    elif unit in ['k', 'nghÃ¬n']:
                        amount = amount * 1000
                    
                    constraints = AutoValidator.VALIDATION_RULES['price']['constraints']
                    
                    if amount < constraints['min_tour_price']:
                        replacement = "giÃ¡ há»£p lÃ½"
                        text = text.replace(match.group(0), replacement)
                        logger.warning(f"âš ï¸ Corrected too-low price: {amount} â†’ {replacement}")
                    
                    elif amount > constraints['max_tour_price']:
                        replacement = "giÃ¡ cao cáº¥p"
                        text = text.replace(match.group(0), replacement)
                        logger.warning(f"âš ï¸ Corrected too-high price: {amount} â†’ {replacement}")
                
                except (ValueError, IndexError, AttributeError):
                    continue
        
        return text
    
    @staticmethod
    def _validate_locations(text: str) -> str:
        """Validate location names"""
        wrong_locations = {
            'hÃ  ná»™i': 'Huáº¿',
            'há»“ chÃ­ minh': 'Quáº£ng Trá»‹',
            'Ä‘Ã  náºµng': 'Báº¡ch MÃ£',
            'nha trang': 'TrÆ°á»ng SÆ¡n',
        }
        
        for wrong, correct in wrong_locations.items():
            if wrong in text.lower():
                text = text.replace(wrong, correct)
                text = text.replace(wrong.capitalize(), correct)
                logger.info(f"ðŸ”„ Corrected location: {wrong} â†’ {correct}")
        
        return text
    
    @staticmethod
    def _check_unrealistic_info(text: str) -> str:
        """Check for other unrealistic information"""
        unrealistic_patterns = [
            (r'\d+\s*giá»\s*bay', "thá»i gian di chuyá»ƒn"),
            (r'\d+\s*sao', "cháº¥t lÆ°á»£ng dá»‹ch vá»¥"),
            (r'\d+\s*táº§ng', "chá»— á»Ÿ"),
            (r'\d+\s*m\s*cao', "Ä‘á»‹a hÃ¬nh"),
        ]
        
        for pattern, replacement in unrealistic_patterns:
            if re.search(pattern, text, re.IGNORECASE):
                text = re.sub(pattern, replacement, text, flags=re.IGNORECASE)
                logger.info(f"ðŸ”„ Replaced unrealistic info with: {replacement}")
        
        return text
    
    @staticmethod
    def _add_validation_note(text: str) -> str:
        """Add note about information validation"""
        note = "\n\n*ThÃ´ng tin Ä‘Æ°á»£c cung cáº¥p dá»±a trÃªn dá»¯ liá»‡u hiá»‡n cÃ³. " \
               "Vui lÃ²ng liÃªn há»‡ hotline 0332510486 Ä‘á»ƒ xÃ¡c nháº­n chi tiáº¿t chÃ­nh xÃ¡c nháº¥t.*"
        
        if note not in text:
            text += note
        
        return text

# =========== UPGRADE 10: TEMPLATE SYSTEM (DATACLASS COMPATIBLE) ===========
class TemplateSystem:
    """
    UPGRADE 10: Beautiful, structured responses for different question types
    """
    
    TEMPLATES = {
        'tour_list': {
            'header': "âœ¨ **DANH SÃCH TOUR RUBY WINGS** âœ¨\n\n",
            'item': "**{index}. {tour_name}** {emoji}\n"
                   "   ðŸ“… {duration}\n"
                   "   ðŸ“ {location}\n"
                   "   ðŸ’° {price}\n"
                   "   {summary}\n",
            'footer': "\nðŸ“ž **LiÃªn há»‡ Ä‘áº·t tour:** 0332510486\n"
                     "ðŸ“ **Ruby Wings Travel** - HÃ nh trÃ¬nh tráº£i nghiá»‡m Ä‘áº·c sáº¯c\n"
                     "ðŸ’¡ *Há»i chi tiáº¿t vá» báº¥t ká»³ tour nÃ o báº±ng cÃ¡ch nháº­p tÃªn tour*",
            'emoji_map': {
                '1 ngÃ y': 'ðŸŒ…',
                '2 ngÃ y': 'ðŸŒ„',
                '3 ngÃ y': 'ðŸ”ï¸',
                'default': 'âœ¨'
            }
        },
        
        'tour_detail': {
            'header': "ðŸŽ¯ **{tour_name}**\n\n",
            'sections': {
                'overview': "ðŸ“‹ **THÃ”NG TIN CHÃNH:**\n"
                          "   â±ï¸ Thá»i gian: {duration}\n"
                          "   ðŸ“ Äá»‹a Ä‘iá»ƒm: {location}\n"
                          "   ðŸ’° GiÃ¡ tour: {price}\n\n",
                'description': "ðŸ“– **MÃ” Táº¢ TOUR:**\n{summary}\n\n",
                'includes': "ðŸŽª **Lá»ŠCH TRÃŒNH & Dá»ŠCH Vá»¤:**\n{includes}\n\n",
                'accommodation': "ðŸ¨ **CHá»– á»ž:**\n{accommodation}\n\n",
                'meals': "ðŸ½ï¸ **Ä‚N Uá»NG:**\n{meals}\n\n",
                'transport': "ðŸš— **DI CHUYá»‚N:**\n{transport}\n\n",
                'notes': "ðŸ“ **GHI CHÃš:**\n{notes}\n\n",
            },
            'footer': "ðŸ“ž **Äáº¶T TOUR & TÆ¯ Váº¾N:** 0332510486\n"
                     "â­ *Tour phÃ¹ há»£p cho: {suitable_for}*",
            'default_values': {
                'duration': 'Äang cáº­p nháº­t',
                'location': 'Äang cáº­p nháº­t',
                'price': 'LiÃªn há»‡ Ä‘á»ƒ biáº¿t giÃ¡',
                'summary': 'HÃ nh trÃ¬nh tráº£i nghiá»‡m Ä‘áº·c sáº¯c cá»§a Ruby Wings',
                'includes': 'Chi tiáº¿t lá»‹ch trÃ¬nh liÃªn há»‡ tÆ° váº¥n',
                'accommodation': 'Äang cáº­p nháº­t',
                'meals': 'Äang cáº­p nháº­t',
                'transport': 'Äang cáº­p nháº­t',
                'notes': 'Vui lÃ²ng liÃªn há»‡ Ä‘á»ƒ biáº¿t thÃªm chi tiáº¿t',
                'suitable_for': 'má»i Ä‘á»‘i tÆ°á»£ng',
            }
        },
        
        'comparison': {
            'header': "ðŸ“Š **SO SÃNH TOUR**\n\n",
            'table_header': "| TiÃªu chÃ­ | {tour1} | {tour2} |\n|----------|----------|----------|\n",
            'table_row': "| {criterion} | {value1} | {value2} |\n",
            'recommendation': "\nðŸ’¡ **Gá»¢I Ã Lá»°A CHá»ŒN:**\n{recommendations}\n",
            'footer': "\nðŸ“ž **TÆ° váº¥n chi tiáº¿t:** 0332510486\n"
                     "ðŸ¤” *Cáº§n so sÃ¡nh thÃªm tiÃªu chÃ­ nÃ o?*",
        },
        
        'recommendation': {
            'header': "ðŸŽ¯ **Äá»€ XUáº¤T TOUR PHÃ™ Há»¢P**\n\n",
            'top_recommendation': "ðŸ† **PHÃ™ Há»¢P NHáº¤T ({score}%)**\n"
                                "**{tour_name}**\n"
                                "   âœ… {reasons}\n"
                                "   ðŸ“… {duration} | ðŸ“ {location} | ðŸ’° {price}\n\n",
            'other_recommendations': "ðŸ“‹ **Lá»°A CHá»ŒN KHÃC:**\n",
            'other_item': "   â€¢ **{tour_name}** ({score}%)\n"
                         "     ðŸ“… {duration} | ðŸ“ {location}\n",
            'criteria': "\nðŸ” **TIÃŠU CHÃ Äá»€ XUáº¤T:**\n{criteria}\n",
            'footer': "\nðŸ“ž **LiÃªn há»‡ tÆ° váº¥n cÃ¡ nhÃ¢n hÃ³a:** 0332510486\n"
                     "ðŸ’¬ *Cho tÃ´i biáº¿t thÃªm sá»Ÿ thÃ­ch cá»§a báº¡n Ä‘á»ƒ Ä‘á» xuáº¥t chÃ­nh xÃ¡c hÆ¡n*",
        },
        
        'information': {
            'header': "â„¹ï¸ **THÃ”NG TIN:**\n\n",
            'content': "{content}\n",
            'sources': "\nðŸ“š *Nguá»“n thÃ´ng tin tá»« dá»¯ liá»‡u Ruby Wings*",
            'footer': "\nðŸ“ž **Hotline há»— trá»£:** 0332510486",
        },
        
        'greeting': {
            'template': "ðŸ‘‹ **Xin chÃ o! TÃ´i lÃ  trá»£ lÃ½ AI cá»§a Ruby Wings**\n\n"
                       "TÃ´i cÃ³ thá»ƒ giÃºp báº¡n:\n"
                       "â€¢ TÃ¬m hiá»ƒu vá» cÃ¡c tour tráº£i nghiá»‡m\n"
                       "â€¢ So sÃ¡nh cÃ¡c hÃ nh trÃ¬nh\n"
                       "â€¢ Äá» xuáº¥t tour phÃ¹ há»£p vá»›i báº¡n\n"
                       "â€¢ Cung cáº¥p thÃ´ng tin chi tiáº¿t vá» tour\n\n"
                       "ðŸ’¡ **VÃ­ dá»¥ báº¡n cÃ³ thá»ƒ há»i:**\n"
                       "- 'CÃ³ nhá»¯ng tour nÃ o?'\n"
                       "- 'Tour Báº¡ch MÃ£ giÃ¡ bao nhiÃªu?'\n"
                       "- 'Tour nÃ o phÃ¹ há»£p cho gia Ä‘Ã¬nh?'\n\n"
                       "HÃ£y cho tÃ´i biáº¿t báº¡n cáº§n gÃ¬ nhÃ©! ðŸ˜Š",
        },
        
        'farewell': {
            'template': "ðŸ™ **Cáº£m Æ¡n báº¡n Ä‘Ã£ trÃ² chuyá»‡n cÃ¹ng Ruby Wings!**\n\n"
                       "ChÃºc báº¡n má»™t ngÃ y trÃ n Ä‘áº§y nÄƒng lÆ°á»£ng vÃ  bÃ¬nh an.\n"
                       "Hy vá»ng sá»›m Ä‘Æ°á»£c Ä‘á»“ng hÃ nh cÃ¹ng báº¡n trong hÃ nh trÃ¬nh tráº£i nghiá»‡m sáº¯p tá»›i!\n\n"
                       "ðŸ“ž **LiÃªn há»‡ Ä‘áº·t tour:** 0332510486\n"
                       "ðŸŒ **Website:** rubywings.vn\n\n"
                       "Háº¹n gáº·p láº¡i! âœ¨",
        },
    }
    
    @staticmethod
    def render(template_name: str, **kwargs) -> str:
        """Render template with provided variables"""
        template_data = TemplateSystem.TEMPLATES.get(template_name)
        if not template_data:
            return kwargs.get('content', '')
        
        if template_name in ['greeting', 'farewell']:
            return template_data['template']
        
        response_parts = []
        
        if 'header' in template_data:
            header = template_data['header']
            for key, value in kwargs.items():
                header = header.replace(f'{{{key}}}', str(value))
            response_parts.append(header)
        
        if template_name == 'tour_list':
            response_parts.append(TemplateSystem._render_tour_list(template_data, kwargs))
        
        elif template_name == 'tour_detail':
            response_parts.append(TemplateSystem._render_tour_detail(template_data, kwargs))
        
        elif template_name == 'comparison':
            response_parts.append(TemplateSystem._render_comparison(template_data, kwargs))
        
        elif template_name == 'recommendation':
            response_parts.append(TemplateSystem._render_recommendation(template_data, kwargs))
        
        elif template_name == 'information':
            response_parts.append(TemplateSystem._render_information(template_data, kwargs))
        
        if 'footer' in template_data:
            footer = template_data['footer']
            for key, value in kwargs.items():
                footer = footer.replace(f'{{{key}}}', str(value))
            response_parts.append(footer)
        
        return '\n'.join(response_parts)
    
    @staticmethod
    def _render_tour_list(template_data: Dict, kwargs: Dict) -> str:
        """Render tour list template"""
        tours = kwargs.get('tours', [])
        if not tours:
            return "Hiá»‡n chÆ°a cÃ³ thÃ´ng tin tour."
        
        items = []
        for i, tour in enumerate(tours[:10], 1):
            duration = tour.duration or ''
            emoji = template_data['emoji_map'].get('default')
            for dur_pattern, dur_emoji in template_data['emoji_map'].items():
                if dur_pattern in duration.lower():
                    emoji = dur_emoji
                    break
            
            item_template = template_data['item']
            item = item_template.format(
                index=i,
                tour_name=tour.name or f'Tour #{i}',
                emoji=emoji or 'âœ¨',
                duration=duration or 'Äang cáº­p nháº­t',
                location=tour.location or 'Äang cáº­p nháº­t',
                price=tour.price or 'LiÃªn há»‡ Ä‘á»ƒ biáº¿t giÃ¡',
                summary=(tour.summary or 'Tour tráº£i nghiá»‡m Ä‘áº·c sáº¯c')[:100] + '...'
            )
            items.append(item)
        
        return '\n'.join(items)
    
    @staticmethod
    def _render_tour_detail(template_data: Dict, kwargs: Dict) -> str:
        """Render tour detail template"""
        sections = []
        
        for section_name, section_template in template_data['sections'].items():
            value = kwargs.get(section_name, template_data['default_values'].get(section_name, ''))
            
            if value and value != template_data['default_values'].get(section_name):
                if isinstance(value, list):
                    if section_name == 'includes':
                        value = '\n'.join([f'   â€¢ {item}' for item in value[:5]])
                    else:
                        value = ', '.join(value[:3])
                
                section = section_template.format(**{section_name: value})
                sections.append(section)
        
        return '\n'.join(sections)
    
    @staticmethod
    def _render_comparison(template_data: Dict, kwargs: Dict) -> str:
        """Render comparison template"""
        comparison_table = []
        
        tour1_name = kwargs.get('tour1_name', 'Tour 1')[:20]
        tour2_name = kwargs.get('tour2_name', 'Tour 2')[:20]
        table_header = template_data['table_header'].format(tour1=tour1_name, tour2=tour2_name)
        comparison_table.append(table_header)
        
        criteria = kwargs.get('criteria', [])
        for criterion in criteria[:8]:
            row = template_data['table_row'].format(
                criterion=criterion.get('name', ''),
                value1=criterion.get('value1', 'N/A')[:20],
                value2=criterion.get('value2', 'N/A')[:20]
            )
            comparison_table.append(row)
        
        return '\n'.join(comparison_table)
    
    @staticmethod
    def _render_recommendation(template_data: Dict, kwargs: Dict) -> str:
        """Render recommendation template"""
        recommendation_text = []
        
        top_tour = kwargs.get('top_tour')
        if top_tour:
            top_text = template_data['top_recommendation'].format(
                score=int(top_tour.get('score', 0) * 100),
                tour_name=top_tour.get('name', ''),
                reasons=', '.join(top_tour.get('reasons', ['phÃ¹ há»£p'])[:3]),
                duration=top_tour.get('duration', ''),
                location=top_tour.get('location', ''),
                price=top_tour.get('price', 'LiÃªn há»‡ Ä‘á»ƒ biáº¿t giÃ¡')
            )
            recommendation_text.append(top_text)
        
        other_tours = kwargs.get('other_tours', [])
        if other_tours:
            recommendation_text.append(template_data['other_recommendations'])
            
            for tour in other_tours[:2]:
                other_item = template_data['other_item'].format(
                    tour_name=tour.get('name', ''),
                    score=int(tour.get('score', 0) * 100),
                    duration=tour.get('duration', ''),
                    location=tour.get('location', '')
                )
                recommendation_text.append(other_item)
        
        return '\n'.join(recommendation_text)
    
    @staticmethod
    def _render_information(template_data: Dict, kwargs: Dict) -> str:
        """Render information template"""
        content = kwargs.get('content', '')
        if not content:
            return ""
        
        info_text = template_data['content'].format(content=content)
        
        if kwargs.get('has_sources'):
            info_text += template_data['sources']
        
        return info_text

# =========== TOUR DATABASE BUILDER (USING Tour DATACLASS) ===========
def load_knowledge(path: str = KNOWLEDGE_PATH):
    """Load knowledge base from JSON file"""
    global KNOW, FLAT_TEXTS, MAPPING
    
    try:
        with open(path, "r", encoding="utf-8") as f:
            KNOW = json.load(f)
        logger.info(f"âœ… Loaded knowledge from {path}")
    except Exception as e:
        logger.error(f"âŒ Could not open {path}: {e}")
        KNOW = {}
    
    FLAT_TEXTS = []
    MAPPING = []
    
    def scan(obj, prefix="root"):
        if isinstance(obj, dict):
            for k, v in obj.items():
                scan(v, f"{prefix}.{k}")
        elif isinstance(obj, list):
            for i, v in enumerate(obj):
                scan(v, f"{prefix}[{i}]")
        elif isinstance(obj, str):
            t = obj.strip()
            if t:
                FLAT_TEXTS.append(t)
                MAPPING.append({"path": prefix, "text": t})
        else:
            try:
                s = str(obj).strip()
                if s:
                    FLAT_TEXTS.append(s)
                    MAPPING.append({"path": prefix, "text": s})
            except Exception:
                pass
    
    scan(KNOW)
    logger.info(f"ðŸ“Š Knowledge scanned: {len(FLAT_TEXTS)} passages")

def index_tour_names():
    """Build tour name to index mapping"""
    global TOUR_NAME_TO_INDEX
    TOUR_NAME_TO_INDEX = {}
    
    for m in MAPPING:
        path = m.get("path", "")
        if path.endswith(".tour_name"):
            txt = m.get("text", "") or ""
            norm = normalize_text_simple(txt)
            if not norm:
                continue
            
            match = re.search(r"\[(\d+)\]", path)
            if match:
                idx = int(match.group(1))
                prev = TOUR_NAME_TO_INDEX.get(norm)
                if prev is None:
                    TOUR_NAME_TO_INDEX[norm] = idx
                else:
                    existing_txt = MAPPING[next(
                        i for i, m2 in enumerate(MAPPING) 
                        if re.search(rf"\[{prev}\]", m2.get('path','')) and ".tour_name" in m2.get('path','')
                    )].get("text","")
                    if len(txt) > len(existing_txt):
                        TOUR_NAME_TO_INDEX[norm] = idx
    
    logger.info(f"ðŸ“ Indexed {len(TOUR_NAME_TO_INDEX)} tour names")

def build_tours_db():
    """Build structured tour database from MAPPING using Tour dataclass"""
    global TOURS_DB, TOUR_TAGS
    
    TOURS_DB.clear()
    TOUR_TAGS.clear()
    
    # First pass: collect all fields for each tour
    for m in MAPPING:
        path = m.get("path", "")
        text = m.get("text", "")
        
        if not path or not text:
            continue
        
        tour_match = re.search(r'tours\[(\d+)\]', path)
        if not tour_match:
            continue
        
        tour_idx = int(tour_match.group(1))
        
        field_match = re.search(r'tours\[\d+\]\.(\w+)(?:\[\d+\])?', path)
        if not field_match:
            continue
        
        field_name = field_match.group(1)
        
        # Initialize tour entry
        if tour_idx not in TOURS_DB:
            TOURS_DB[tour_idx] = Tour(index=tour_idx)
        
        # Update field in Tour object
        tour_obj = TOURS_DB[tour_idx]
        if field_name == 'tour_name':
            tour_obj.name = text
        elif field_name == 'duration':
            tour_obj.duration = text
        elif field_name == 'location':
            tour_obj.location = text
        elif field_name == 'price':
            tour_obj.price = text
        elif field_name == 'summary':
            tour_obj.summary = text
        elif field_name == 'includes':
            if isinstance(tour_obj.includes, list):
                tour_obj.includes.append(text)
            else:
                tour_obj.includes = [text]
        elif field_name == 'accommodation':
            tour_obj.accommodation = text
        elif field_name == 'meals':
            tour_obj.meals = text
        elif field_name == 'transport':
            tour_obj.transport = text
        elif field_name == 'notes':
            tour_obj.notes = text
        elif field_name == 'style':
            tour_obj.style = text
    
    # Second pass: generate tags and metadata
    for tour_idx, tour_obj in TOURS_DB.items():
        tags = []
        
        # Location tags
        if tour_obj.location:
            locations = [loc.strip() for loc in tour_obj.location.split(",") if loc.strip()]
            tags.extend([f"location:{loc}" for loc in locations[:2]])
        
        # Duration tags
        if tour_obj.duration:
            duration_lower = tour_obj.duration.lower()
            if "1 ngÃ y" in duration_lower:
                tags.append("duration:1day")
            elif "2 ngÃ y" in duration_lower:
                tags.append("duration:2day")
            elif "3 ngÃ y" in duration_lower:
                tags.append("duration:3day")
            else:
                day_match = re.search(r'(\d+)\s*ngÃ y', duration_lower)
                if day_match:
                    days = int(day_match.group(1))
                    tags.append(f"duration:{days}day")
        
        # Price tags
        if tour_obj.price:
            price_nums = re.findall(r'[\d,\.]+', tour_obj.price)
            if price_nums:
                try:
                    clean_nums = []
                    for p in price_nums[:2]:
                        p_clean = p.replace(',', '').replace('.', '')
                        if p_clean.isdigit():
                            clean_nums.append(int(p_clean))
                    
                    if clean_nums:
                        avg_price = sum(clean_nums) / len(clean_nums)
                        if avg_price < 1000000:
                            tags.append("price:budget")
                        elif avg_price < 2000000:
                            tags.append("price:midrange")
                        else:
                            tags.append("price:premium")
                except:
                    pass
        
        # Style/theme tags
        text_to_check = (tour_obj.style + " " + (tour_obj.summary or '')).lower()
        
        theme_keywords = {
            'meditation': ['thiá»n', 'chÃ¡nh niá»‡m', 'tÃ¢m linh'],
            'history': ['lá»‹ch sá»­', 'di tÃ­ch', 'chiáº¿n tranh', 'tri Ã¢n'],
            'nature': ['thiÃªn nhiÃªn', 'rá»«ng', 'nÃºi', 'cÃ¢y'],
            'culture': ['vÄƒn hÃ³a', 'cá»™ng Ä‘á»“ng', 'dÃ¢n tá»™c'],
            'wellness': ['khÃ­ cÃ´ng', 'sá»©c khá»e', 'chá»¯a lÃ nh'],
            'adventure': ['phiÃªu lÆ°u', 'máº¡o hiá»ƒm', 'khÃ¡m phÃ¡'],
        }
        
        for theme, keywords in theme_keywords.items():
            if any(keyword in text_to_check for keyword in keywords):
                tags.append(f"theme:{theme}")
        
        # Destination tags from tour name
        if tour_obj.name:
            name_lower = tour_obj.name.lower()
            if "báº¡ch mÃ£" in name_lower:
                tags.append("destination:bachma")
            if "trÆ°á»ng sÆ¡n" in name_lower:
                tags.append("destination:truongson")
            if "quáº£ng trá»‹" in name_lower:
                tags.append("destination:quangtri")
            if "huáº¿" in name_lower:
                tags.append("destination:hue")
        
        # Update Tour object tags
        tour_obj.tags = list(set(tags))
        TOUR_TAGS[tour_idx] = tour_obj.tags
        
        # Calculate completeness score
        completeness = 0
        important_fields = ['name', 'duration', 'location', 'price', 'summary']
        for field in important_fields:
            if getattr(tour_obj, field, None):
                completeness += 1
        
        tour_obj.completeness_score = completeness / len(important_fields)
    
    logger.info(f"âœ… Built tours database: {len(TOURS_DB)} tours with tags")

def get_passages_by_field(field_name: str, limit: int = 50, 
                         tour_indices: Optional[List[int]] = None) -> List[Tuple[float, Dict]]:
    """
    Get passages for a specific field
    """
    exact_matches = []
    global_matches = []
    
    for m in MAPPING:
        path = m.get("path", "")
        if path.endswith(f".{field_name}") or f".{field_name}" in path:
            is_exact_match = False
            if tour_indices:
                for ti in tour_indices:
                    if f"[{ti}]" in path:
                        is_exact_match = True
                        break
            
            if is_exact_match:
                exact_matches.append((2.0, m))
            elif not tour_indices:
                global_matches.append((1.0, m))
    
    all_results = exact_matches + global_matches
    all_results.sort(key=lambda x: x[0], reverse=True)
    return all_results[:limit]

# =========== CACHE SYSTEM (DATACLASS COMPATIBLE) ===========
class CacheSystem:
    """Simple caching system for responses"""
    
    @staticmethod
    def get_cache_key(query: str, context_hash: str = "") -> str:
        """Generate cache key"""
        key_parts = [query]
        if context_hash:
            key_parts.append(context_hash)
        return hashlib.md5("|".join(key_parts).encode()).hexdigest()
    
    @staticmethod
    def get(key: str, ttl_seconds: int = 300):
        """Get item from cache"""
        with _cache_lock:
            if key in _response_cache:
                cache_entry = _response_cache[key]
                if not cache_entry.is_expired():
                    logger.info(f"ðŸ’¾ Cache hit for key: {key[:20]}...")
                    return cache_entry.value
                else:
                    del _response_cache[key]
            return None
    
    @staticmethod
    def set(key: str, value: Any):
        """Set item in cache"""
        with _cache_lock:
            cache_entry = CacheEntry(
                key=key,
                value=value,
                created_at=datetime.utcnow(),
                ttl_seconds=UpgradeFlags.get_all_flags().get("CACHE_TTL_SECONDS", 300)
            )
            _response_cache[key] = cache_entry
            
            if len(_response_cache) > 1000:
                sorted_items = sorted(_response_cache.items(), 
                                     key=lambda x: x[1].created_at)
                for old_key in [k for k, _ in sorted_items[:200]]:
                    if old_key in _response_cache:
                        del _response_cache[old_key]

# =========== EMBEDDING FUNCTIONS (MEMORY OPTIMIZED) ===========
@lru_cache(maxsize=128 if IS_LOW_RAM else 1000)
def embed_text(text: str) -> Tuple[List[float], int]:
    """Embed text using OpenAI or fallback (with memory optimization)"""
    if not text:
        return [], 0
    
    text = text[:2000]
    
    if client:
        try:
            response = client.embeddings.create(
                model=EMBEDDING_MODEL,
                input=text
            )
            if response.data:
                embedding = response.data[0].embedding
                return embedding, len(embedding)
        except Exception as e:
            logger.error(f"OpenAI embedding error: {e}")
    
    # Fallback: deterministic hash-based embedding
    h = hash(text) % (10 ** 12)
    dim = 1536
    embedding = [(float((h >> (i % 32)) & 0xFF) + (i % 7)) / 255.0 
                 for i in range(dim)]
    
    return embedding, dim

def query_index(query: str, top_k: int = TOP_K) -> List[Tuple[float, Dict]]:
    """Query the index"""
    if not query or INDEX is None:
        return []
    
    emb, _ = embed_text(query)
    if not emb:
        return []
    
    vec = np.array(emb, dtype="float32").reshape(1, -1)
    vec = vec / (np.linalg.norm(vec) + 1e-12)
    
    try:
        if HAS_FAISS and isinstance(INDEX, faiss.Index):
            D, I = INDEX.search(vec, top_k)
        else:
            D, I = INDEX.search(vec, top_k)
        
        results = []
        for score, idx in zip(D[0], I[0]):
            if 0 <= idx < len(MAPPING):
                results.append((float(score), MAPPING[idx]))
        
        return results
    except Exception as e:
        logger.error(f"Index search error: {e}")
        return []

class NumpyIndex:
    """Simple numpy-based index with safe numpy handling"""

    def __init__(self, mat=None):
        if NUMPY_AVAILABLE:
            if mat is None:
                self.mat = np.empty((0, 0), dtype="float32")
            else:
                # Force numpy float32 2D
                self.mat = np.asarray(mat, dtype="float32")
                if self.mat.ndim == 1:
                    self.mat = self.mat.reshape(1, -1)
        else:
            self.mat = mat if mat is not None else []

        # SAFE dimension detection (no numpy truth check)
        if NUMPY_AVAILABLE:
            if self.mat.shape[0] > 0 and self.mat.ndim == 2:
                self.dim = int(self.mat.shape[1])
            else:
                self.dim = 0
            self.size = int(self.mat.shape[0])
        else:
            self.size = len(self.mat)
            self.dim = len(self.mat[0]) if self.size > 0 else 0

    def is_empty(self):
        if NUMPY_AVAILABLE:
            return self.mat.shape[0] == 0
        return len(self.mat) == 0

    def search(self, query_vec, k=5):
        if self.is_empty():
            return [], []

        if NUMPY_AVAILABLE:
            q = np.asarray(query_vec, dtype="float32").reshape(1, -1)
            sims = np.dot(self.mat, q.T).reshape(-1)
            topk = np.argsort(-sims)[:k]
            return sims[topk].tolist(), topk.tolist()
        else:
            return [], []

    
    def search(self, qvec, k):
        if not self.mat or (NUMPY_AVAILABLE and self.mat.shape[0] == 0) or (not NUMPY_AVAILABLE and len(self.mat) == 0):
            # Return empty results
            return np.array([[]]), np.array([[]], dtype=np.int64)
        
        q = np.array(qvec).flatten()
        
        if NUMPY_AVAILABLE:
            # Use numpy if available
            q = q / (np.linalg.norm(q) + 1e-12)
            m = self.mat / (np.linalg.norm(self.mat, axis=1, keepdims=True) + 1e-12)
            sims = np.dot(q, m.T)
            idx = np.argsort(-sims)[:k]
            scores = sims[idx]
        else:
            # Fallback calculation
            q_norm = q / (sum(x*x for x in q)**0.5 + 1e-12)
            scores = []
            for i, row in enumerate(self.mat):
                row_norm = row / (sum(x*x for x in row)**0.5 + 1e-12)
                sim = sum(q_norm[j] * row_norm[j] for j in range(min(len(q_norm), len(row_norm))))
                scores.append((sim, i))
            
            scores.sort(key=lambda x: x[0], reverse=True)
            top_k = scores[:k]
            if top_k:
                scores_arr = np.array([s[0] for s in top_k])
                idx_arr = np.array([s[1] for s in top_k])
            else:
                scores_arr = np.array([])
                idx_arr = np.array([], dtype=np.int64)
            
            return scores_arr.reshape(1, -1), idx_arr.reshape(1, -1)
        
        return scores.reshape(1, -1), idx.reshape(1, -1)
    
    def save(self, path):
        if NUMPY_AVAILABLE:
            np.savez_compressed(path, mat=self.mat)
        else:
            logger.warning(f"âš ï¸ Cannot save index without NumPy: {path}")
    
    @classmethod
    def load(cls, path):
        if NUMPY_AVAILABLE:
            try:
                arr = np.load(path)
                return cls(arr['mat'])
            except Exception as e:
                logger.error(f"Failed to load numpy index: {e}")
                return cls()
        else:
            logger.warning(f"âš ï¸ Cannot load index without NumPy: {path}")
            return cls()

def build_index(force_rebuild: bool = False) -> bool:
    """Build or load FAISS/numpy index"""
    global INDEX, EMBEDDING_MODEL
    
    with INDEX_LOCK:
        # Try to load existing index
        if not force_rebuild:
            if FAISS_ENABLED and HAS_FAISS and os.path.exists(FAISS_INDEX_PATH):
                try:
                    INDEX = faiss.read_index(FAISS_INDEX_PATH)
                    logger.info(f"âœ… Loaded FAISS index from {FAISS_INDEX_PATH}")
                    return True
                except Exception as e:
                    logger.warning(f"Failed to load FAISS index: {e}")
            
            # Try numpy fallback
            if os.path.exists(FALLBACK_VECTORS_PATH):
                try:
                    arr = np.load(FALLBACK_VECTORS_PATH)
                    INDEX = NumpyIndex(arr['mat'])
                    logger.info("âœ… Loaded numpy index")
                    return True
                except Exception as e:
                    logger.warning(f"Failed to load numpy index: {e}")
        
        # Build new index
        if not FLAT_TEXTS:
            logger.warning("No texts to index")
            return False
        
        logger.info(f"ðŸ”¨ Building index for {len(FLAT_TEXTS)} passages...")
        
        # Generate embeddings
        vectors = []
        dims = None
        
        for text in FLAT_TEXTS:
            emb, d = embed_text(text)
            if emb:
                if dims is None:
                    dims = len(emb)
                vectors.append(np.array(emb, dtype="float32"))
        
        if not vectors:
            logger.error("No embeddings generated")
            return False
        
        # Create index
        mat = np.vstack(vectors)
        mat = mat / (np.linalg.norm(mat, axis=1, keepdims=True) + 1e-12)
        
        if FAISS_ENABLED and HAS_FAISS:
            INDEX = faiss.IndexFlatIP(dims)
            INDEX.add(mat)
            try:
                faiss.write_index(INDEX, FAISS_INDEX_PATH)
                logger.info(f"âœ… Saved FAISS index to {FAISS_INDEX_PATH}")
            except Exception as e:
                logger.error(f"Failed to save FAISS index: {e}")
        else:
            INDEX = NumpyIndex(mat)
            try:
                INDEX.save(FALLBACK_VECTORS_PATH)
                logger.info(f"âœ… Saved numpy index to {FALLBACK_VECTORS_PATH}")
            except Exception as e:
                logger.error(f"Failed to save numpy index: {e}")
        
        logger.info(f"âœ… Index built: {len(vectors)} vectors, {dims} dimensions")
        return True

# =========== HELPER FUNCTIONS ===========
def normalize_text_simple(s: str) -> str:
    """Basic text normalization"""
    if not s:
        return ""
    s = s.lower()
    s = unicodedata.normalize("NFD", s)
    s = "".join(ch for ch in s if unicodedata.category(ch) != "Mn")
    s = re.sub(r"[^\w\s]", " ", s)
    s = re.sub(r"\s+", " ", s).strip()
    return s

def get_session_context(session_id: str) -> ConversationContext:
    """Get or create context for session using ConversationContext dataclass with auto-repair"""

    ctx = SESSION_CONTEXTS.get(session_id)

    if ctx is None:
        ctx = ConversationContext(session_id=session_id)
        SESSION_CONTEXTS[session_id] = ctx
        return ctx

    # ===== AUTO REPAIR FOR OLD CONTEXT OBJECTS =====
    if not hasattr(ctx, "last_tour_indices"):
        ctx.last_tour_indices = []

    if not hasattr(ctx, "current_tours"):
        ctx.current_tours = []

    if not hasattr(ctx, "mentioned_tours"):
        ctx.mentioned_tours = set()

    if not hasattr(ctx, "last_successful_tours"):
        ctx.last_successful_tours = []

    if not hasattr(ctx, "conversation_history"):
        ctx.conversation_history = []

    if not hasattr(ctx, "user_preferences"):
        ctx.user_preferences = {}

    return ctx


def extract_session_id(request_data: Dict, remote_addr: str) -> str:
    """Extract or create session ID"""
    session_id = request_data.get("session_id")
    if not session_id:
        ip = remote_addr or "0.0.0.0"
        current_hour = datetime.utcnow().strftime("%Y%m%d%H")
        unique_str = f"{ip}_{current_hour}"
        session_id = hashlib.md5(unique_str.encode()).hexdigest()[:12]
    return f"session_{session_id}"

def _prepare_llm_prompt(user_message: str, search_results: List, context: Dict) -> str:
    """Prepare prompt for LLM - THÃ”NG MINH vá»›i context & cÃ¢u há»i chung"""
    
    message_lower = user_message.lower()
    
    # PhÃ¢n loáº¡i cÃ¢u há»i
    is_general_question = any(keyword in message_lower for keyword in [
        'cÃ³ bao gá»“m', 'Ä‘Ã£ bao gá»“m', 'bao gá»“m gÃ¬', 'bao gá»“m nhá»¯ng gÃ¬',
        'cÃ³ gÃ¬', 'nhÆ° tháº¿ nÃ o', 'ra sao', 'tháº¿ nÃ o', 'giÃ¡ tour'
    ])
    
    has_specific_tour = context.get('current_tours') and len(context.get('current_tours', [])) > 0
    tour_count = len(context.get('current_tours', []))
    
    # PhÃ¡t hiá»‡n cÃ¢u há»i tiáº¿p theo (followup)
    is_followup = (
        context.get('last_action') == 'chat_response' and 
        (has_specific_tour or context.get('last_tour_name'))
    )
    
    # PhÃ¡t hiá»‡n rÃ ng buá»™c Ä‘á»‹a lÃ½
    has_location_constraint = False
    location_constraint = None
    filters = context.get('filters', {})
    if filters:
        if filters.get('location'):
            has_location_constraint = True
            location_constraint = filters.get('location')
        elif filters.get('near_location'):
            has_location_constraint = True
            location_constraint = filters.get('near_location')
    
    prompt_parts = [
        "Báº¡n lÃ  trá»£ lÃ½ tÆ° váº¥n du lá»‹ch Ruby Wings - CHUYÃŠN NGHIá»†P, THÃ”NG MINH, NHIá»†T TÃŒNH.",
        "",
        "âš ï¸ QUY Táº®C NGHIÃŠM NGáº¶T:",
    ]
    
    # RULE 1: CÃ¢u há»i CHUNG (khÃ´ng cÃ³ tour cá»¥ thá»ƒ)
    if is_general_question and not has_specific_tour:
        prompt_parts.extend([
            "",
            "ðŸŽ¯ ÄÃ‚Y LÃ€ CÃ‚U Há»ŽI CHUNG - KHÃ”NG CÃ“ TOUR Cá»¤ THá»‚:",
            "â€¢ TRáº¢ Lá»œI NGáº®N Gá»ŒN (2-4 cÃ¢u) dá»±a trÃªn kiáº¿n thá»©c chung vá» tour du lá»‹ch",
            "â€¢ Sá»¬ Dá»¤NG OPENAI Ä‘á»ƒ tráº£ lá»i tá»± nhiÃªn, khÃ´ng nÃ³i 'khÃ´ng cÃ³ dá»¯ liá»‡u'",
            "â€¢ Káº¾T THÃšC báº±ng cÃ¢u há»i: 'Báº¡n quan tÃ¢m tour nÃ o Ä‘á»ƒ tÃ´i tÆ° váº¥n chi tiáº¿t?'",
            "â€¢ KHÃ”NG liá»‡t kÃª tour, KHÃ”NG dump dá»¯ liá»‡u",
            "",
            "VÃ Dá»¤ ÄÃšNG:",
            "Q: 'GiÃ¡ tour bao gá»“m gÃ¬?'",
            "A: 'GiÃ¡ tour Ruby Wings thÆ°á»ng bao gá»“m: xe Ä‘Æ°a Ä‘Ã³n, Äƒn uá»‘ng theo chÆ°Æ¡ng trÃ¬nh, khÃ¡ch sáº¡n, hÆ°á»›ng dáº«n viÃªn vÃ  báº£o hiá»ƒm. TÃ¹y tour cá»¥ thá»ƒ cÃ³ thá»ƒ cÃ³ thÃªm vÃ© tham quan hoáº·c hoáº¡t Ä‘á»™ng Ä‘áº·c biá»‡t. Báº¡n quan tÃ¢m tour nÃ o Ä‘á»ƒ tÃ´i tÆ° váº¥n chi tiáº¿t? ðŸ˜Š'",
            "",
            "Q: 'Tour cÃ³ phÃ¹ há»£p gia Ä‘Ã¬nh khÃ´ng?'",
            "A: 'Ruby Wings cÃ³ nhiá»u tour phÃ¹ há»£p gia Ä‘Ã¬nh vá»›i hoáº¡t Ä‘á»™ng nháº¹ nhÃ ng, an toÃ n cho tráº» em vÃ  ngÆ°á»i lá»›n tuá»•i. Gia Ä‘Ã¬nh báº¡n cÃ³ bao nhiÃªu ngÆ°á»i vÃ  thÃ­ch loáº¡i hÃ¬nh nÃ o (thiÃªn nhiÃªn, lá»‹ch sá»­, nghá»‰ dÆ°á»¡ng) Ä‘á»ƒ tÃ´i tÆ° váº¥n tour phÃ¹ há»£p nháº¥t?'",
        ])
    
    # RULE 2: CÃ¢u há»i TIáº¾P THEO (followup)
    elif is_followup:
        prompt_parts.extend([
            "",
            "ðŸ’­ ÄÃ‚Y LÃ€ CÃ‚U Há»ŽI TIáº¾P THEO - Sá»¬ Dá»¤NG CONTEXT:",
            f"â€¢ ÄÃ£ bÃ n vá» {tour_count} tour: {context.get('last_tour_name', '')}",
            "â€¢ PHáº¢I dá»±a vÃ o context cÅ© - KHÃ”NG reset",
            "â€¢ TRáº¢ Lá»œI TIáº¾P theo ngá»¯ cáº£nh Ä‘Ã£ cÃ³",
            "â€¢ KHÃ”NG liá»‡t kÃª láº¡i toÃ n bá»™ tour",
            "â€¢ Náº¿u há»i vá» giÃ¡/thá»i gian â†’ Chá»‰ nÃ³i vá» tour Ä‘ang bÃ n",
            "â€¢ Náº¿u há»i thÃªm Ä‘iá»u kiá»‡n â†’ Gá»£i Ã½ tour tá»« context hoáº·c há»i láº¡i",
            "",
            "VÃ Dá»¤ ÄÃšNG:",
            "Context: ÄÃ£ nÃ³i vá» 'Tour Báº¡ch MÃ£'",
            "Q: 'Tour nÃ y cÃ³ phÃ¹ há»£p nhÃ³m 10 ngÆ°á»i khÃ´ng?'",
            "A: 'Tour Báº¡ch MÃ£ ráº¥t phÃ¹ há»£p cho nhÃ³m 10 ngÆ°á»i! ChÃºng tÃ´i cÃ³ thá»ƒ tá»• chá»©c riÃªng vá»›i giÃ¡ Æ°u Ä‘Ã£i. NhÃ³m báº¡n thÃ­ch hoáº¡t Ä‘á»™ng nÃ o: trekking, thiá»n tÄ©nh tÃ¢m hay cáº£ hai? TÃ´i sáº½ tÆ° váº¥n lá»‹ch trÃ¬nh chi tiáº¿t.'",
        ])
    
    # RULE 3: Location constraint
    if has_location_constraint:
        prompt_parts.extend([
            "",
            "ðŸš¨ RÃ€NG BUá»˜C Äá»ŠA LÃ - NGHIÃŠM NGáº¶T:",
            f"â€¢ YÃªu cáº§u tour gáº§n/táº¡i: {location_constraint or 'khu vá»±c cá»¥ thá»ƒ'}",
            "â€¢ CHá»ˆ Ä‘á» xuáº¥t tour trong khu vá»±c nÃ y",
            "â€¢ Náº¾U khÃ´ng cÃ³ tour phÃ¹ há»£p:",
            "  â†’ 'Hiá»‡n Ruby Wings chÆ°a cÃ³ tour táº¡i [Ä‘á»‹a Ä‘iá»ƒm]. Tuy nhiÃªn, chÃºng tÃ´i cÃ³ tour gáº§n nháº¥t táº¡i [X].'",
            "  â†’ Há»i: 'Báº¡n cÃ³ muá»‘n xem tour á»Ÿ khu vá»±c lÃ¢n cáº­n khÃ´ng?'",
        ])
    
    # RULE 4: Giá»›i háº¡n tour
    prompt_parts.extend([
        "",
        "ðŸ“Š GIá»šI Háº N TOUR (Báº®T BUá»˜C):",
        "â€¢ Tá»‘i Ä‘a 2-3 tour/cÃ¢u tráº£ lá»i",
        "â€¢ Má»–I tour pháº£i cÃ³ LÃ DO rÃµ rÃ ng",
        "â€¢ KHÃ”NG liá»‡t kÃª >3 tour",
        "â€¢ Náº¿u cÃ³ nhiá»u tour phÃ¹ há»£p:",
        "  â†’ Chá»n 2-3 TIÃŠU BIá»‚U nháº¥t",
        "  â†’ TÃ³m táº¯t: 'CÃ²n X tour khÃ¡c...'",
        "  â†’ Há»i: 'Báº¡n muá»‘n xem thÃªm loáº¡i nÃ o?'",
    ])
    
    # CONTEXT INFO
    prompt_parts.extend([
        "",
        "ðŸ“š THÃ”NG TIN NGá»® Cáº¢NH:",
    ])
    
    if context.get('user_preferences'):
        prefs = []
        for k, v in context['user_preferences'].items():
            prefs.append(f"{k}: {v}")
        if prefs:
            prompt_parts.append(f"- Sá»Ÿ thÃ­ch: {'; '.join(prefs)}")
    
    if context.get('current_tours'):
        tours_info = [f"{t['name']}" for t in context['current_tours'][:3]]
        if tours_info:
            prompt_parts.append(f"- Tour Ä‘Ã£ bÃ n: {', '.join(tours_info)}")
    
    if filters:
        filter_strs = []
        if filters.get('price_max'):
            filter_strs.append(f"giÃ¡ <{filters['price_max']:,}Ä‘")
        if filters.get('location'):
            filter_strs.append(f"Vá»Š TRÃ: {filters['location']}")
        if filter_strs:
            prompt_parts.append(f"- RÃ ng buá»™c: {'; '.join(filter_strs)}")
    
    # SEARCH RESULTS
    prompt_parts.append("")
    prompt_parts.append("ðŸ“ Dá»® LIá»†U Tá»ª Há»† THá»NG:")
    
    if search_results:
        for i, (score, passage) in enumerate(search_results[:5], 1):
            text = passage.get('text', '')[:250]
            prompt_parts.append(f"[{i}] {text}")
    else:
        prompt_parts.append("(KhÃ´ng cÃ³ dá»¯ liá»‡u cá»¥ thá»ƒ - sá»­ dá»¥ng kiáº¿n thá»©c chung)")
    
    # YÃŠU Cáº¦U TRáº¢ Lá»œI
    prompt_parts.append("")
    prompt_parts.append("ðŸ’¬ YÃŠU Cáº¦U TRáº¢ Lá»œI:")
    
    if is_general_question and not has_specific_tour:
        prompt_parts.extend([
            "1. Tráº£ lá»i NGáº®N Gá»ŒN (2-4 cÃ¢u) dá»±a OpenAI",
            "2. KHÃ”NG nÃ³i 'khÃ´ng cÃ³ dá»¯ liá»‡u'",
            "3. Káº¿t thÃºc: Há»i láº¡i Ä‘á»ƒ xÃ¡c Ä‘á»‹nh tour",
        ])
    elif is_followup:
        prompt_parts.extend([
            "1. Dá»±a vÃ o CONTEXT (tour Ä‘Ã£ bÃ n)",
            "2. Tráº£ lá»i TIáº¾P, KHÃ”NG reset",
            "3. Tá»‘i Ä‘a nháº¯c 1-2 tour tá»« context",
        ])
    else:
        prompt_parts.extend([
            "1. Chá»n 2-3 tour vá»›i LÃ DO rÃµ",
            "2. KHÃ”NG >3 tour",
            "3. Náº¿u nhiá»u: tÃ³m táº¯t + há»i tiáº¿p",
        ])
    
    prompt_parts.append("4. LuÃ´n káº¿t thÃºc: CÃ¢u há»i dáº«n dáº¯t hoáº·c 'ðŸ“ž Gá»i 0332510486'")
    
    return "\n".join(prompt_parts)

def _generate_fallback_response(user_message: str, search_results: List, tour_indices: List[int] = None) -> str:
    """Generate SMART fallback response - DÃ¹ng OpenAI khi cÃ³, context-aware"""
    message_lower = user_message.lower()
    
    # ===== Sá»¬ Dá»¤NG OPENAI Náº¾U CÃ“ =====
    if client and HAS_OPENAI:
        try:
            # Chuáº©n bá»‹ context
            context_parts = []
            
            # ThÃ´ng tin tour náº¿u cÃ³
            if tour_indices and TOURS_DB:
                for idx in tour_indices[:2]:
                    tour = TOURS_DB.get(idx)
                    if tour:
                        context_parts.append(f"Tour: {tour.name}")
                        if tour.duration:
                            context_parts.append(f"Thá»i gian: {tour.duration}")
                        if tour.price:
                            context_parts.append(f"GiÃ¡: {tour.price}")
                        if tour.summary:
                            context_parts.append(f"MÃ´ táº£: {tour.summary[:150]}")
            
            # Dá»¯ liá»‡u search
            if search_results:
                for i, (score, passage) in enumerate(search_results[:3], 1):
                    text = passage.get('text', '')[:200]
                    if text:
                        context_parts.append(f"ThÃ´ng tin {i}: {text}")
            
            # Táº¡o prompt thÃ´ng minh
            context_str = "\n".join(context_parts) if context_parts else "KhÃ´ng cÃ³ dá»¯ liá»‡u cá»¥ thá»ƒ"
            
            prompt = f"""Báº¡n lÃ  tÆ° váº¥n viÃªn Ruby Wings chuyÃªn nghiá»‡p.

THÃ”NG TIN CÃ“ Sáº´N:
{context_str}

YÃŠU Cáº¦U TRáº¢ Lá»œI:
1. Náº¿u cÃ³ thÃ´ng tin tour cá»¥ thá»ƒ â†’ TÆ° váº¥n dá»±a trÃªn Ä‘Ã³
2. Náº¿u khÃ´ng cÃ³ dá»¯ liá»‡u â†’ Tráº£ lá»i dá»±a kiáº¿n thá»©c chung vá» tour du lá»‹ch
3. LUÃ”N káº¿t thÃºc báº±ng cÃ¢u há»i dáº«n dáº¯t hoáº·c "Gá»i 0332510486"
4. Ngáº¯n gá»n 2-4 cÃ¢u, nhiá»‡t tÃ¬nh, tá»± nhiÃªn
5. KHÃ”NG nÃ³i "khÃ´ng cÃ³ dá»¯ liá»‡u", "xin lá»—i khÃ´ng tÃ¬m tháº¥y"

CÃ¢u há»i cá»§a khÃ¡ch: {user_message}"""

            response = client.chat.completions.create(
                model=CHAT_MODEL,
                messages=[
                    {"role": "system", "content": prompt},
                    {"role": "user", "content": user_message}
                ],
                temperature=0.6,
                max_tokens=300
            )
            
            if response.choices:
                reply = response.choices[0].message.content or ""
                # Äáº£m báº£o cÃ³ hotline
                if "0332510486" not in reply:
                    reply += "\n\nðŸ“ž LiÃªn há»‡ 0332510486 Ä‘á»ƒ Ä‘Æ°á»£c tÆ° váº¥n chi tiáº¿t!"
                return reply
        
        except Exception as e:
            logger.error(f"OpenAI fallback error: {e}")
            # RÆ¡i xuá»‘ng logic template bÃªn dÆ°á»›i
    
    # ===== FALLBACK KHI KHÃ”NG CÃ“ OPENAI =====
    
    # CÃ³ tour cá»¥ thá»ƒ â†’ Tráº£ thÃ´ng tin tour
    if tour_indices and TOURS_DB:
        response_parts = []
        for idx in tour_indices[:2]:
            tour = TOURS_DB.get(idx)
            if tour:
                response_parts.append(f"**{tour.name}**")
                if tour.duration:
                    response_parts.append(f"â±ï¸ {tour.duration}")
                if tour.location:
                    response_parts.append(f"ðŸ“ {tour.location}")
                if tour.price:
                    response_parts.append(f"ðŸ’° {tour.price}")
                if tour.summary:
                    response_parts.append(f"ðŸ“ {tour.summary[:150]}...")
        
        if response_parts:
            return "\n".join(response_parts) + "\n\nðŸ“ž Gá»i 0332510486 Ä‘á»ƒ biáº¿t thÃªm!"
    
    # CÃ³ search results â†’ TÃ³m táº¯t
    if search_results:
        top_results = search_results[:2]
        response_parts = ["ThÃ´ng tin liÃªn quan:"]
        
        for i, (score, passage) in enumerate(top_results, 1):
            text = passage.get('text', '')[:150]
            if text:
                response_parts.append(f"\n{i}. {text}...")
        
        response_parts.append("\n\nðŸ“ž LiÃªn há»‡ 0332510486 Ä‘á»ƒ biáº¿t chi tiáº¿t!")
        return "".join(response_parts)
    
    # CÃ¢u há»i chung â†’ Template thÃ´ng minh theo keyword
    general_qa = {
        'bao gá»“m': "GiÃ¡ tour Ruby Wings thÆ°á»ng bao gá»“m: xe Ä‘Æ°a Ä‘Ã³n, Äƒn uá»‘ng theo chÆ°Æ¡ng trÃ¬nh, khÃ¡ch sáº¡n, hÆ°á»›ng dáº«n viÃªn vÃ  báº£o hiá»ƒm. TÃ¹y tour cá»¥ thá»ƒ cÃ³ thÃªm hoáº¡t Ä‘á»™ng Ä‘áº·c biá»‡t. Báº¡n quan tÃ¢m tour nÃ o Ä‘á»ƒ tÃ´i tÆ° váº¥n chi tiáº¿t? ðŸ˜Š",
        
        'phÃ¹ há»£p gia Ä‘Ã¬nh': "Ruby Wings cÃ³ nhiá»u tour phÃ¹ há»£p gia Ä‘Ã¬nh vá»›i hoáº¡t Ä‘á»™ng nháº¹ nhÃ ng, an toÃ n cho tráº» em vÃ  ngÆ°á»i lá»›n tuá»•i. Gia Ä‘Ã¬nh báº¡n bao nhiÃªu ngÆ°á»i vÃ  thÃ­ch loáº¡i tour nÃ o (thiÃªn nhiÃªn, lá»‹ch sá»­, nghá»‰ dÆ°á»¡ng)?",
        
        'phÃ¹ há»£p': "Ruby Wings cÃ³ tour cho má»i Ä‘á»‘i tÆ°á»£ng! Báº¡n Ä‘i nhÃ³m bao nhiÃªu ngÆ°á»i vÃ  cÃ³ sá»Ÿ thÃ­ch gÃ¬ Ä‘áº·c biá»‡t khÃ´ng?",
        
        'giÃ¡': "GiÃ¡ tour Ruby Wings tá»« 800.000Ä‘ - 3.000.000Ä‘ tÃ¹y loáº¡i. Báº¡n cÃ³ ngÃ¢n sÃ¡ch khoáº£ng bao nhiÃªu vÃ  muá»‘n Ä‘i máº¥y ngÃ y Ä‘á»ƒ tÃ´i tÆ° váº¥n phÃ¹ há»£p?",
        
        'thá»i gian': "Ruby Wings cÃ³ tour 1 ngÃ y, 2 ngÃ y 1 Ä‘Ãªm, 3 ngÃ y 2 Ä‘Ãªm. Báº¡n cÃ³ khoáº£ng bao nhiÃªu thá»i gian ráº£nh?",
        
        'Ä‘á»‹a Ä‘iá»ƒm': "Ruby Wings tá»• chá»©c tour táº¡i Huáº¿, Quáº£ng Trá»‹, Báº¡ch MÃ£, TrÆ°á»ng SÆ¡n vÃ  nhiá»u nÆ¡i khÃ¡c. Báº¡n muá»‘n khÃ¡m phÃ¡ khu vá»±c nÃ o?",
        
        'nhÃ³m': "Tour nhÃ³m cá»§a Ruby Wings ráº¥t phÃ¹ há»£p! NhÃ³m báº¡n bao nhiÃªu ngÆ°á»i vÃ  thÃ­ch hoáº¡t Ä‘á»™ng gÃ¬ (teambuilding, nghá»‰ dÆ°á»¡ng, khÃ¡m phÃ¡)?",
        
        'retreat': "Ruby Wings chuyÃªn tour retreat káº¿t há»£p thiá»n, khÃ­ cÃ´ng vÃ  thiÃªn nhiÃªn. Báº¡n muá»‘n tour bao nhiÃªu ngÃ y vÃ  má»©c Ä‘á»™ hoáº¡t Ä‘á»™ng nhÆ° nÃ o?",
    }
    
    # TÃ¬m keyword match
    for keyword, response in general_qa.items():
        if keyword in message_lower:
            return response
    
    # Default - Dáº«n dáº¯t há»i láº¡i
    return "TÃ´i cÃ³ thá»ƒ giÃºp báº¡n tÃ¬m tour phÃ¹ há»£p! Báº¡n cÃ³ thá»ƒ cho tÃ´i biáº¿t:\n" \
           "â€¢ Muá»‘n Ä‘i Ä‘Ã¢u?\n" \
           "â€¢ Thá»i gian bao lÃ¢u?\n" \
           "â€¢ NgÃ¢n sÃ¡ch khoáº£ng bao nhiÃªu?\n" \
           "â€¢ Äi bao nhiÃªu ngÆ°á»i?\n\n" \
           "Hoáº·c gá»i ngay 0332510486 Ä‘á»ƒ Ä‘Æ°á»£c tÆ° váº¥n chi tiáº¿t! ðŸ˜Š"

# =========== MAIN CHAT ENDPOINT - Äá»ˆNH CAO THÃ”NG MINH ===========
@app.route("/chat", methods=["POST"])
def chat_endpoint_ultimate():
    """
    Main chat endpoint vá»›i xá»­ lÃ½ AI thÃ´ng minh, context-aware máº¡nh máº½
    Xá»­ lÃ½ má»i loáº¡i cÃ¢u há»i tá»« Ä‘Æ¡n giáº£n Ä‘áº¿n phá»©c táº¡p
    """
    start_time = time.time()
    
    try:
        # ================== INITIALIZATION ==================
        data = request.get_json() or {}
        user_message = (data.get("message") or "").strip()
        session_id = extract_session_id(data, request.remote_addr)
        
        if not user_message:
            return jsonify({
                "reply": "ðŸ‘‹ **Xin chÃ o! TÃ´i lÃ  trá»£ lÃ½ AI cá»§a Ruby Wings Travel**\n\n"
                        "TÃ´i cÃ³ thá»ƒ giÃºp báº¡n:\n"
                        "â€¢ TÃ¬m hiá»ƒu vá» 32 tour tráº£i nghiá»‡m Ä‘áº·c sáº¯c\n"
                        "â€¢ So sÃ¡nh cÃ¡c tour Ä‘á»ƒ chá»n phÃ¹ há»£p nháº¥t\n"
                        "â€¢ TÆ° váº¥n tour theo nhu cáº§u gia Ä‘Ã¬nh, nhÃ³m, cÃ¡ nhÃ¢n\n"
                        "â€¢ Cung cáº¥p thÃ´ng tin chi tiáº¿t vá» giÃ¡, lá»‹ch trÃ¬nh, Ä‘á»‹a Ä‘iá»ƒm\n\n"
                        "ðŸ“ž **Hotline tÆ° váº¥n 24/7:** 0332510486\n"
                        "ðŸ’¡ **Há»i ngay:** 'Tour nÃ o phÃ¹ há»£p cho gia Ä‘Ã¬nh?', 'Tour Báº¡ch MÃ£ giÃ¡ bao nhiÃªu?'",
                "sources": [],
                "context": {},
                "processing_time": 0
            })
        
        # ================== CONTEXT MANAGEMENT SYSTEM ==================
        context = get_session_context(session_id)
        
        # Khá»Ÿi táº¡o context náº¿u chÆ°a cÃ³
        if not hasattr(context, 'conversation_history'):
            context.conversation_history = []
        if not hasattr(context, 'current_tour'):
            context.current_tour = None
        if not hasattr(context, 'user_profile'):
            context.user_profile = {}
        
        # LÆ°u user message vÃ o history
        context.conversation_history.append({
            'role': 'user',
            'message': user_message,
            'timestamp': datetime.utcnow().isoformat()
        })
        
        # Giá»›i háº¡n history (giá»¯ 10 tin nháº¯n gáº§n nháº¥t)
        if len(context.conversation_history) > 20:
            context.conversation_history = context.conversation_history[-10:]
        
        # ================== AI-POWERED CONTEXT ANALYSIS ==================
        message_lower = user_message.lower()
        
        # PhÃ¢n tÃ­ch cáº¥p Ä‘á»™ phá»©c táº¡p
        complexity_score = 0
        complexity_indicators = {
            'vÃ ': 1, 'cho': 1, 'vá»›i': 1, 'nhÆ°ng': 2, 'tuy nhiÃªn': 2,
            'náº¿u': 2, 'khi': 1, 'Ä‘á»ƒ': 1, 'mÃ ': 1, 'hoáº·c': 1
        }
        
        for indicator, weight in complexity_indicators.items():
            if indicator in message_lower:
                complexity_score += weight
        
        # ================== SMART INTENT DETECTION ==================
        intent_categories = {
            'tour_listing': ['cÃ³ nhá»¯ng tour nÃ o', 'danh sÃ¡ch tour', 'liá»‡t kÃª tour', 'tour nÃ o cÃ³'],
            'price_inquiry': ['giÃ¡ bao nhiÃªu', 'bao nhiÃªu tiá»n', 'chi phÃ­', 'giÃ¡ tour'],
            'tour_detail': ['chi tiáº¿t tour', 'lá»‹ch trÃ¬nh', 'cÃ³ gÃ¬', 'bao gá»“m gÃ¬'],
            'comparison': ['so sÃ¡nh', 'khÃ¡c nhau', 'nÃªn chá»n', 'tá»‘t hÆ¡n'],
            'recommendation': ['phÃ¹ há»£p', 'gá»£i Ã½', 'Ä‘á» xuáº¥t', 'tÆ° váº¥n', 'nÃªn Ä‘i'],
            'booking_info': ['Ä‘áº·t tour', 'Ä‘Äƒng kÃ½', 'booking', 'giá»¯ chá»—'],
            'policy': ['chÃ­nh sÃ¡ch', 'giáº£m giÃ¡', 'Æ°u Ä‘Ã£i', 'khuyáº¿n mÃ£i'],
            'general_info': ['giá»›i thiá»‡u', 'lÃ  gÃ¬', 'tháº¿ nÃ o', 'ra sao'],
            'location_info': ['á»Ÿ Ä‘Ã¢u', 'Ä‘á»‹a Ä‘iá»ƒm', 'Ä‘áº¿n Ä‘Ã¢u', 'vá»‹ trÃ­'],
            'time_info': ['khi nÃ o', 'thá»i gian', 'bao lÃ¢u', 'máº¥y ngÃ y'],
            'weather_info': ['thá»i tiáº¿t', 'khÃ­ háº­u', 'náº¯ng mÆ°a', 'mÃ¹a nÃ o'],
            'food_info': ['áº©m thá»±c', 'mÃ³n Äƒn', 'Ä‘áº·c sáº£n', 'Ä‘á»“ Äƒn'],
            'culture_info': ['vÄƒn hÃ³a', 'lá»‹ch sá»­', 'truyá»n thá»‘ng', 'di tÃ­ch'],
            'wellness_info': ['thiá»n', 'yoga', 'chá»¯a lÃ nh', 'sá»©c khá»e'],
            'group_info': ['nhÃ³m', 'Ä‘oÃ n', 'cÃ´ng ty', 'gia Ä‘Ã¬nh'],
            'custom_request': ['tÃ¹y chá»‰nh', 'riÃªng', 'cÃ¡ nhÃ¢n hÃ³a', 'theo yÃªu cáº§u']
        }
        
        detected_intents = []
        for intent, keywords in intent_categories.items():
            for keyword in keywords:
                if keyword in message_lower:
                    detected_intents.append(intent)
                    break
        
        # ================== TOUR RESOLUTION ENGINE ==================
        tour_indices = []
        
        # Strategy 1: Direct tour name matching
        direct_tour_matches = []
        for norm_name, idx in TOUR_NAME_TO_INDEX.items():
            # Kiá»ƒm tra tÃªn tour cÃ³ trong message khÃ´ng
            tour_words = set(norm_name.split())
            msg_words = set(message_lower.split())
            common_words = tour_words.intersection(msg_words)
            
            if len(common_words) >= 2:  # Ãt nháº¥t 2 tá»« trÃ¹ng
                direct_tour_matches.append(idx)
        
        if direct_tour_matches:
            tour_indices = direct_tour_matches[:3]  # Chá»‰ láº¥y 3 tour Ä‘áº§u
            logger.info(f"ðŸŽ¯ Direct tour matches found: {tour_indices}")
        
        # Strategy 2: Fuzzy matching for partial names
        if not tour_indices and UpgradeFlags.is_enabled("6_FUZZY_MATCHING"):
            fuzzy_matches = FuzzyMatcher.find_similar_tours(user_message, TOUR_NAME_TO_INDEX)
            if fuzzy_matches:
                tour_indices = [idx for idx, score in fuzzy_matches[:2] if score > 0.7]
                logger.info(f"ðŸ” Fuzzy matches found: {tour_indices}")
        
        # Strategy 3: Filter-based search
        mandatory_filters = FilterSet()
        if UpgradeFlags.is_enabled("1_MANDATORY_FILTER"):
            mandatory_filters = MandatoryFilterSystem.extract_filters(user_message)
            
            if not mandatory_filters.is_empty():
                filtered_indices = MandatoryFilterSystem.apply_filters(TOURS_DB, mandatory_filters)
                if filtered_indices:
                    if tour_indices:
                        # Káº¿t há»£p káº¿t quáº£
                        combined = list(set(tour_indices) & set(filtered_indices))
                        tour_indices = combined if combined else filtered_indices[:3]
                    else:
                        tour_indices = filtered_indices[:5]  # Giá»›i háº¡n 5 tour
                    logger.info(f"ðŸŽ¯ Filter-based search: {len(tour_indices)} tours")
        
        # ================== INTELLIGENT RESPONSE GENERATION ==================
        reply = ""
        sources = []
        
        # ðŸ”¹ CASE 1: LISTING TOURS
        if 'tour_listing' in detected_intents or any(keyword in message_lower for keyword in ['cÃ³ nhá»¯ng tour nÃ o', 'danh sÃ¡ch tour']):
            logger.info("ðŸ“‹ Processing tour listing request")
            
            all_tours = list(TOURS_DB.values())
            
            # Apply deduplication
            if UpgradeFlags.is_enabled("2_DEDUPLICATION") and all_tours:
                seen_names = set()
                unique_tours = []
                for tour in all_tours:
                    name = tour.name
                    if name and name not in seen_names:
                        seen_names.add(name)
                        unique_tours.append(tour)
                all_tours = unique_tours
            
            # Apply additional filters
            if not mandatory_filters.is_empty():
                filtered_indices = MandatoryFilterSystem.apply_filters(TOURS_DB, mandatory_filters)
                all_tours = [TOURS_DB[idx] for idx in filtered_indices if idx in TOURS_DB]
            
            total_tours = len(all_tours)
            
            # GIá»šI Háº N: Chá»‰ hiá»ƒn thá»‹ 5 tour + thÃ´ng bÃ¡o cÃ²n láº¡i
            display_tours = all_tours[:5]
            
            if display_tours:
                # Format response vá»›i emoji theo loáº¡i tour
                reply = "âœ¨ **DANH SÃCH TOUR RUBY WINGS** âœ¨\n\n"
                
                for i, tour in enumerate(display_tours, 1):
                    # XÃ¡c Ä‘á»‹nh emoji phÃ¹ há»£p
                    emoji = "âœ¨"
                    if tour.tags:
                        if any('nature' in tag for tag in tour.tags):
                            emoji = "ðŸŒ¿"
                        elif any('history' in tag for tag in tour.tags):
                            emoji = "ðŸ›ï¸"
                        elif any('meditation' in tag for tag in tour.tags):
                            emoji = "ðŸ•‰ï¸"
                        elif any('family' in tag for tag in tour.tags):
                            emoji = "ðŸ‘¨â€ðŸ‘©â€ðŸ‘§â€ðŸ‘¦"
                    
                    reply += f"{emoji} **{tour.name}**\n"
                    if tour.duration:
                        reply += f"   â±ï¸ {tour.duration}\n"
                    if tour.location:
                        reply += f"   ðŸ“ {tour.location}\n"
                    if tour.price and i <= 3:  # Chá»‰ hiá»‡n giÃ¡ 3 tour Ä‘áº§u
                        price_text = tour.price[:50] + "..." if len(tour.price) > 50 else tour.price
                        reply += f"   ðŸ’° {price_text}\n"
                    reply += "\n"
                
                if total_tours > 5:
                    reply += f"ðŸ“Š **CÃ²n {total_tours - 5} tour khÃ¡c!**\n\n"
                
                reply += "ðŸ’¡ **Báº¡n muá»‘n tÃ¬m hiá»ƒu chi tiáº¿t tour nÃ o?**\n"
                reply += "â€¢ Gá»i tÃªn tour cá»¥ thá»ƒ (vÃ­ dá»¥: 'Tour Báº¡ch MÃ£')\n"
                reply += "â€¢ Hoáº·c mÃ´ táº£ nhu cáº§u Ä‘á»ƒ tÃ´i tÆ° váº¥n phÃ¹ há»£p\n\n"
                reply += "ðŸ“ž **Hotline tÆ° váº¥n nhanh:** 0332510486"
            else:
                reply = "Hiá»‡n chÆ°a cÃ³ tour nÃ o phÃ¹ há»£p vá»›i yÃªu cáº§u cá»§a báº¡n. Vui lÃ²ng thá»­ vá»›i tiÃªu chÃ­ khÃ¡c hoáº·c liÃªn há»‡ hotline 0332510486 Ä‘á»ƒ Ä‘Æ°á»£c tÆ° váº¥n tour riÃªng."
        
        # ðŸ”¹ CASE 2: PRICE INQUIRY
        elif 'price_inquiry' in detected_intents or any(keyword in message_lower for keyword in ['giÃ¡ bao nhiÃªu', 'bao nhiÃªu tiá»n']):
            logger.info("ðŸ’° Processing price inquiry")
            
            if tour_indices:
                # CÃ³ tour cá»¥ thá»ƒ
                price_responses = []
                for idx in tour_indices[:2]:  # Chá»‰ 2 tour Ä‘áº§u
                    tour = TOURS_DB.get(idx)
                    if tour and tour.price:
                        price_text = tour.price
                        # LÃ m Ä‘áº¹p price text
                        if 'nghÃ¬n' in price_text.lower():
                            price_text = price_text.replace('nghÃ¬n', 'k').replace('NghÃ¬n', 'k')
                        
                        price_responses.append(f"**{tour.name}:** {price_text}")
                
                if price_responses:
                    reply = "ðŸ’° **THÃ”NG TIN GIÃ TOUR** ðŸ’°\n\n"
                    reply += "\n".join(price_responses)
                    reply += "\n\nðŸ“ž **GiÃ¡ Æ°u Ä‘Ã£i cho nhÃ³m & Ä‘áº·t sá»›m:** 0332510486"
                else:
                    # DÃ¹ng AI Ä‘á»ƒ tráº£ lá»i thÃ´ng minh
                    if client and HAS_OPENAI:
                        try:
                            prompt = f"""Báº¡n lÃ  tÆ° váº¥n viÃªn Ruby Wings. KhÃ¡ch há»i vá» giÃ¡ tour nhÆ°ng chÆ°a chá»‰ Ä‘á»‹nh tour cá»¥ thá»ƒ.

THÃ”NG TIN CHUNG Vá»€ GIÃ TOUR RUBY WINGS:
- Tour 1 ngÃ y: tá»« 500.000Ä‘ - 1.500.000Ä‘
- Tour 2 ngÃ y 1 Ä‘Ãªm: tá»« 1.500.000Ä‘ - 3.000.000Ä‘  
- Tour 3 ngÃ y 2 Ä‘Ãªm: tá»« 2.500.000Ä‘ - 5.000.000Ä‘
- Tour nhÃ³m: cÃ³ chÃ­nh sÃ¡ch giáº£m giÃ¡ theo sá»‘ lÆ°á»£ng
- Tour cao cáº¥p: giÃ¡ theo yÃªu cáº§u

YÃŠU Cáº¦U:
1. Giáº£i thÃ­ch pháº¡m vi giÃ¡ tour cá»§a Ruby Wings
2. Há»i láº¡i khÃ¡ch vá» loáº¡i tour cá»¥ thá»ƒ
3. Äá» nghá»‹ liÃªn há»‡ hotline Ä‘á»ƒ bÃ¡o giÃ¡ chi tiáº¿t

Tráº£ lá»i ngáº¯n gá»n, chuyÃªn nghiá»‡p."""

                            response = client.chat.completions.create(
                                model=CHAT_MODEL,
                                messages=[
                                    {"role": "system", "content": prompt},
                                    {"role": "user", "content": user_message}
                                ],
                                temperature=0.5,
                                max_tokens=250
                            )
                            
                            if response.choices:
                                reply = response.choices[0].message.content or ""
                            else:
                                reply = "GiÃ¡ tour Ruby Wings dao Ä‘á»™ng tá»« 500.000Ä‘ - 5.000.000Ä‘ tÃ¹y loáº¡i tour vÃ  dá»‹ch vá»¥. Báº¡n quan tÃ¢m tour nÃ o cá»¥ thá»ƒ Ä‘á»ƒ tÃ´i bÃ¡o giÃ¡ chi tiáº¿t?"
                        
                        except Exception as e:
                            logger.error(f"OpenAI price inquiry error: {e}")
                            reply = "GiÃ¡ tour tÃ¹y thuá»™c vÃ o loáº¡i tour, thá»i gian vÃ  sá»‘ lÆ°á»£ng ngÆ°á»i. Vui lÃ²ng cho biáº¿t báº¡n quan tÃ¢m tour nÃ o Ä‘á»ƒ tÃ´i bÃ¡o giÃ¡ cá»¥ thá»ƒ."
                    else:
                        reply = "GiÃ¡ tour Ruby Wings ráº¥t Ä‘a dáº¡ng, tá»« tour 1 ngÃ y giÃ¡ 500.000Ä‘ Ä‘áº¿n tour cao cáº¥p 5.000.000Ä‘. Báº¡n muá»‘n biáº¿t giÃ¡ tour cá»¥ thá»ƒ nÃ o?"
            else:
                # KhÃ´ng cÃ³ tour cá»¥ thá»ƒ
                reply = "ðŸ’° **Báº¢NG GIÃ THAM KHáº¢O RUBY WINGS** ðŸ’°\n\n"
                reply += "ðŸ·ï¸ **Tour 1 ngÃ y:** 500.000Ä‘ - 1.500.000Ä‘\n"
                reply += "   â€¢ ThiÃªn nhiÃªn, vÄƒn hÃ³a, áº©m thá»±c\n\n"
                reply += "ðŸ·ï¸ **Tour 2 ngÃ y 1 Ä‘Ãªm:** 1.500.000Ä‘ - 3.000.000Ä‘\n"
                reply += "   â€¢ Tráº£i nghiá»‡m sÃ¢u, retreat, lá»‹ch sá»­\n\n"
                reply += "ðŸ·ï¸ **Tour 3+ ngÃ y:** 2.500.000Ä‘ - 5.000.000Ä‘\n"
                reply += "   â€¢ Cao cáº¥p, cÃ¡ nhÃ¢n hÃ³a, nhÃ³m Ä‘áº·c biá»‡t\n\n"
                reply += "ðŸŽ¯ **Æ¯u Ä‘Ã£i Ä‘áº·c biá»‡t:**\n"
                reply += "â€¢ NhÃ³m 10+ ngÆ°á»i: Giáº£m 10-20%\n"
                reply += "â€¢ Äáº·t trÆ°á»›c 30 ngÃ y: Giáº£m 5%\n"
                reply += "â€¢ Cá»±u chiáº¿n binh: Æ¯u Ä‘Ã£i Ä‘áº·c biá»‡t\n\n"
                reply += "ðŸ“ž **LiÃªn há»‡ ngay 0332510486 Ä‘á»ƒ nháº­n bÃ¡o giÃ¡ chi tiáº¿t!**"
        
        # ðŸ”¹ CASE 3: TOUR COMPARISON
        elif 'comparison' in detected_intents:
            logger.info("âš–ï¸ Processing tour comparison request")
            
            # TÃ¬m cÃ¡c tour Ä‘á»ƒ so sÃ¡nh
            comparison_tours = []
            
            # Extract tour names tá»« cÃ¢u há»i
            import re
            tour_patterns = [
                r'tour\s+["\']?(.+?)["\']?\s+vÃ \s+tour\s+["\']?(.+?)["\']?',
                r'tour\s+["\']?(.+?)["\']?\s+vá»›i\s+tour\s+["\']?(.+?)["\']?',
                r'tour\s+["\']?(.+?)["\']?\s+so\s+sÃ¡nh\s+vá»›i\s+tour\s+["\']?(.+?)["\']?',
            ]
            
            for pattern in tour_patterns:
                matches = re.findall(pattern, message_lower, re.IGNORECASE)
                for match in matches:
                    for tour_name in match:
                        if tour_name.strip():
                            # TÃ¬m tour index
                            for norm_name, idx in TOUR_NAME_TO_INDEX.items():
                                if tour_name.lower() in norm_name.lower():
                                    comparison_tours.append(idx)
                                    break
            
            # Náº¿u khÃ´ng extract Ä‘Æ°á»£c, dÃ¹ng tour_indices
            if not comparison_tours and tour_indices:
                comparison_tours = tour_indices[:3]  # Tá»‘i Ä‘a 3 tour
            
            if len(comparison_tours) >= 2:
                # Táº¡o báº£ng so sÃ¡nh chi tiáº¿t
                reply = "ðŸ“Š **SO SÃNH CHI TIáº¾T TOUR** ðŸ“Š\n\n"
                
                # Header
                headers = ["TIÃŠU CHÃ"]
                tour_data = []
                
                for idx in comparison_tours[:3]:  # Tá»‘i Ä‘a 3 tour
                    tour = TOURS_DB.get(idx)
                    if tour:
                        headers.append(tour.name[:20])
                        tour_data.append(tour)
                
                # CÃ¡c tiÃªu chÃ­ so sÃ¡nh
                comparison_criteria = [
                    ('â±ï¸ Thá»i gian', lambda t: t.duration or 'N/A'),
                    ('ðŸ“ Äá»‹a Ä‘iá»ƒm', lambda t: t.location or 'N/A'),
                    ('ðŸ’° GiÃ¡', lambda t: t.price[:30] + '...' if t.price and len(t.price) > 30 else t.price or 'LiÃªn há»‡'),
                    ('ðŸŽ¯ Loáº¡i hÃ¬nh', lambda t: ', '.join([tag.split(':')[1] for tag in (t.tags or []) if ':' in tag][:2]) or 'Äa dáº¡ng'),
                    ('ðŸ“ Äá»™ phÃ¹ há»£p', lambda t: 'Gia Ä‘Ã¬nh' if any('family' in tag for tag in (t.tags or [])) else 'NhÃ³m/NgÆ°á»i lá»›n'),
                ]
                
                for criterion_name, get_value in comparison_criteria:
                    row = [criterion_name]
                    for tour in tour_data:
                        value = get_value(tour)
                        row.append(value[:20] if value else 'N/A')
                    
                    # Format row
                    row_formatted = " | ".join([cell.ljust(20) for cell in row])
                    reply += f"{row_formatted}\n"
                    reply += "-" * (len(row) * 22) + "\n"
                
                # Gá»£i Ã½ lá»±a chá»n
                reply += "\nðŸ’¡ **Gá»¢I Ã Lá»°A CHá»ŒN:**\n"
                
                if tour_data:
                    # PhÃ¢n tÃ­ch giÃ¡
                    prices = []
                    for tour in tour_data:
                        if tour.price:
                            # Extract sá»‘ tá»« price
                            nums = re.findall(r'\d[\d,\.]+', tour.price)
                            if nums:
                                try:
                                    price_num = int(nums[0].replace(',', '').replace('.', ''))
                                    prices.append(price_num)
                                except:
                                    pass
                    
                    if len(prices) >= 2:
                        min_price = min(prices)
                        max_price = max(prices)
                        if max_price > min_price * 1.5:
                            reply += "â€¢ Tiáº¿t kiá»‡m: Chá»n tour giÃ¡ tháº¥p hÆ¡n\n"
                            reply += "â€¢ Tráº£i nghiá»‡m Ä‘áº§y Ä‘á»§: Chá»n tour giÃ¡ cao hÆ¡n\n"
                    
                    # PhÃ¢n tÃ­ch thá»i gian
                    durations = [tour.duration.lower() if tour.duration else '' for tour in tour_data]
                    if any('1 ngÃ y' in d for d in durations) and any('2 ngÃ y' in d for d in durations):
                        reply += "â€¢ Ãt thá»i gian: Tour 1 ngÃ y\n"
                        reply += "â€¢ Tráº£i nghiá»‡m sÃ¢u: Tour 2 ngÃ y\n"
                
                reply += "\nðŸ“ž **TÆ° váº¥n chá»n tour phÃ¹ há»£p:** 0332510486"
            
            else:
                reply = "Äá»ƒ so sÃ¡nh tour, vui lÃ²ng cho biáº¿t tÃªn 2-3 tour cá»¥ thá»ƒ. VÃ­ dá»¥: 'So sÃ¡nh tour Báº¡ch MÃ£ vÃ  tour TrÆ°á»ng SÆ¡n'"
        
        # ðŸ”¹ CASE 4: TOUR RECOMMENDATION
        elif 'recommendation' in detected_intents or any(keyword in message_lower for keyword in ['phÃ¹ há»£p', 'gá»£i Ã½', 'Ä‘á» xuáº¥t']):
            logger.info("ðŸŽ¯ Processing recommendation request")
            
            # PhÃ¢n tÃ­ch yÃªu cáº§u chi tiáº¿t
            requirements = {
                'family': any(word in message_lower for word in ['gia Ä‘Ã¬nh', 'tráº» em', 'con nhá»', 'bá»‘ máº¹']),
                'senior': any(word in message_lower for word in ['ngÆ°á»i lá»›n tuá»•i', 'cao tuá»•i', 'Ã´ng bÃ ']),
                'group': any(word in message_lower for word in ['nhÃ³m', 'Ä‘oÃ n', 'cÃ´ng ty', 'báº¡n bÃ¨']),
                'couple': any(word in message_lower for word in ['cáº·p Ä‘Ã´i', 'Ä‘Ã´i lá»©a', 'ngÆ°á»i yÃªu']),
                'solo': any(word in message_lower for word in ['má»™t mÃ¬nh', 'Ä‘i láº»', 'solo']),
                'nature': any(word in message_lower for word in ['thiÃªn nhiÃªn', 'rá»«ng', 'nÃºi', 'cÃ¢y']),
                'history': any(word in message_lower for word in ['lá»‹ch sá»­', 'di tÃ­ch', 'chiáº¿n tranh']),
                'meditation': any(word in message_lower for word in ['thiá»n', 'tÄ©nh tÃ¢m', 'yoga']),
                'relax': any(word in message_lower for word in ['nghá»‰ ngÆ¡i', 'thÆ° giÃ£n', 'nháº¹ nhÃ ng']),
                'adventure': any(word in message_lower for word in ['phiÃªu lÆ°u', 'máº¡o hiá»ƒm', 'khÃ¡m phÃ¡']),
                'budget': any(word in message_lower for word in ['giÃ¡ ráº»', 'tiáº¿t kiá»‡m', 'kinh táº¿']),
                'premium': any(word in message_lower for word in ['cao cáº¥p', 'sang trá»ng', 'premium']),
            }
            
            # TÃ¬m tour phÃ¹ há»£p
            matching_tours = []
            
            for idx, tour in TOURS_DB.items():
                score = 0
                reasons = []
                
                # Kiá»ƒm tra tags
                tour_tags = [tag.lower() for tag in (tour.tags or [])]
                
                # PhÃ¹ há»£p gia Ä‘Ã¬nh
                if requirements['family']:
                    if any('family' in tag for tag in tour_tags):
                        score += 3
                        reasons.append("phÃ¹ há»£p gia Ä‘Ã¬nh")
                    elif 'history' in tour_tags and not requirements['history']:
                        score -= 1  # Trá»« Ä‘iá»ƒm náº¿u tour lá»‹ch sá»­ nhÆ°ng khÃ´ng yÃªu cáº§u
                
                # NgÆ°á»i lá»›n tuá»•i
                if requirements['senior']:
                    if any('nature' in tag for tag in tour_tags) or any('meditation' in tag for tag in tour_tags):
                        score += 2
                        reasons.append("nháº¹ nhÃ ng cho ngÆ°á»i lá»›n tuá»•i")
                
                # ThiÃªn nhiÃªn
                if requirements['nature']:
                    if any('nature' in tag for tag in tour_tags):
                        score += 2
                        reasons.append("tráº£i nghiá»‡m thiÃªn nhiÃªn")
                
                # Thiá»n/tÄ©nh tÃ¢m
                if requirements['meditation']:
                    if any('meditation' in tag for tag in tour_tags):
                        score += 3
                        reasons.append("cÃ³ hoáº¡t Ä‘á»™ng thiá»n")
                
                # Nghá»‰ ngÆ¡i
                if requirements['relax']:
                    if any('nature' in tag for tag in tour_tags) or any('meditation' in tag for tag in tour_tags):
                        score += 2
                        reasons.append("táº­p trung nghá»‰ ngÆ¡i")
                
                # Budget
                if requirements['budget']:
                    if tour.price:
                        # TÃ¬m sá»‘ trong price
                        nums = re.findall(r'\d[\d,\.]+', tour.price)
                        if nums:
                            try:
                                price_num = int(nums[0].replace(',', '').replace('.', ''))
                                if price_num < 2000000:
                                    score += 2
                                    reasons.append("giÃ¡ há»£p lÃ½")
                            except:
                                pass
                
                if score > 0:
                    matching_tours.append((idx, score, reasons))
            
            # Sáº¯p xáº¿p theo Ä‘iá»ƒm
            matching_tours.sort(key=lambda x: x[1], reverse=True)
            
            if matching_tours:
                reply = "ðŸŽ¯ **Äá»€ XUáº¤T TOUR PHÃ™ Há»¢P** ðŸŽ¯\n\n"
                
                # Top recommendation
                top_idx, top_score, top_reasons = matching_tours[0]
                top_tour = TOURS_DB.get(top_idx)
                
                if top_tour:
                    reply += f"ðŸ† **PHÃ™ Há»¢P NHáº¤T ({int(top_score/10*100)}%)**\n"
                    reply += f"**{top_tour.name}**\n"
                    reply += f"âœ… LÃ½ do: {', '.join(top_reasons[:3])}\n"
                    if top_tour.duration:
                        reply += f"â±ï¸ Thá»i gian: {top_tour.duration}\n"
                    if top_tour.location:
                        reply += f"ðŸ“ Äá»‹a Ä‘iá»ƒm: {top_tour.location}\n"
                    if top_tour.price:
                        reply += f"ðŸ’° GiÃ¡: {top_tour.price[:80]}\n"
                    reply += "\n"
                
                # Other recommendations (tá»‘i Ä‘a 2 tour)
                other_tours = matching_tours[1:3]
                if other_tours:
                    reply += "ðŸ“‹ **Lá»°A CHá»ŒN KHÃC:**\n"
                    for idx, score, reasons in other_tours:
                        tour = TOURS_DB.get(idx)
                        if tour:
                            reply += f"â€¢ **{tour.name}** ({int(score/10*100)}%)\n"
                            if tour.duration:
                                reply += f"  â±ï¸ {tour.duration}"
                            if tour.location:
                                reply += f" | ðŸ“ {tour.location[:30]}"
                            reply += "\n"
                
                reply += "\nðŸ’¡ **Cáº¦N TÆ¯ Váº¤N CHI TIáº¾T?**\n"
                reply += "ðŸ“ž Gá»i ngay 0332510486 Ä‘á»ƒ:\n"
                reply += "â€¢ Nháº­n lá»‹ch trÃ¬nh chi tiáº¿t\n"
                reply += "â€¢ BÃ¡o giÃ¡ chÃ­nh xÃ¡c\n"
                reply += "â€¢ Äáº·t tour Æ°u Ä‘Ã£i\n"
            
            else:
                # DÃ¹ng AI Ä‘á»ƒ Ä‘á» xuáº¥t thÃ´ng minh
                if client and HAS_OPENAI:
                    try:
                        prompt = f"""Báº¡n lÃ  tÆ° váº¥n viÃªn Ruby Wings chuyÃªn nghiá»‡p. KhÃ¡ch hÃ ng cáº§n tÆ° váº¥n tour nhÆ°ng chÆ°a tÃ¬m tháº¥y tour phÃ¹ há»£p.

YÃŠU Cáº¦U KHÃCH: {user_message}

THÃ”NG TIN RUBY WINGS:
- ChuyÃªn tour tráº£i nghiá»‡m: lá»‹ch sá»­, thiÃªn nhiÃªn, retreat
- Äa dáº¡ng tour tá»« 1 ngÃ y Ä‘áº¿n 4 ngÃ y
- PhÃ¹ há»£p má»i Ä‘á»‘i tÆ°á»£ng: gia Ä‘Ã¬nh, nhÃ³m, cÃ¡ nhÃ¢n

YÃŠU Cáº¦U:
1. Thá»«a nháº­n chÆ°a tÃ¬m tháº¥y tour phÃ¹ há»£p ngay
2. Äá» nghá»‹ cung cáº¥p thÃªm thÃ´ng tin Ä‘á»ƒ tÆ° váº¥n tá»‘t hÆ¡n
3. Gá»£i Ã½ má»™t sá»‘ loáº¡i tour phá»• biáº¿n
4. Khuyáº¿n khÃ­ch liÃªn há»‡ hotline

Tráº£ lá»i thÃ¢n thiá»‡n, chuyÃªn nghiá»‡p."""

                        response = client.chat.completions.create(
                            model=CHAT_MODEL,
                            messages=[
                                {"role": "system", "content": prompt},
                                {"role": "user", "content": user_message}
                            ],
                            temperature=0.6,
                            max_tokens=300
                        )
                        
                        if response.choices:
                            reply = response.choices[0].message.content or ""
                        else:
                            reply = "Äá»ƒ tÃ´i tÆ° váº¥n tour phÃ¹ há»£p nháº¥t, báº¡n cÃ³ thá»ƒ cho biáº¿t thÃªm:\nâ€¢ Sá»‘ ngÆ°á»i tham gia\nâ€¢ Äá»™ tuá»•i cÃ¡c thÃ nh viÃªn\nâ€¢ Sá»Ÿ thÃ­ch chÃ­nh (thiÃªn nhiÃªn, lá»‹ch sá»­, nghá»‰ dÆ°á»¡ng)\nâ€¢ NgÃ¢n sÃ¡ch dá»± kiáº¿n\nâ€¢ Thá»i gian cÃ³ thá»ƒ Ä‘i"
                    
                    except Exception as e:
                        logger.error(f"OpenAI recommendation error: {e}")
                        reply = "Ruby Wings cÃ³ nhiá»u tour Ä‘a dáº¡ng phÃ¹ há»£p vá»›i nhu cáº§u cá»§a báº¡n. Vui lÃ²ng liÃªn há»‡ hotline 0332510486 Ä‘á»ƒ Ä‘Æ°á»£c tÆ° váº¥n chi tiáº¿t vÃ  Ä‘á» xuáº¥t tour riÃªng."
                else:
                    reply = "Äá»ƒ tÆ° váº¥n tour phÃ¹ há»£p nháº¥t, vui lÃ²ng cung cáº¥p thÃªm thÃ´ng tin hoáº·c liÃªn há»‡ trá»±c tiáº¿p hotline 0332510486."
        
        # ðŸ”¹ CASE 5: GENERAL INFORMATION (giá»›i thiá»‡u, triáº¿t lÃ½, vÄƒn hÃ³a)
        elif 'general_info' in detected_intents or any(keyword in message_lower for keyword in ['giá»›i thiá»‡u', 'lÃ  gÃ¬', 'tháº¿ nÃ o', 'triáº¿t lÃ½']):
            logger.info("ðŸ›ï¸ Processing general information request")
            
            # XÃ¡c Ä‘á»‹nh loáº¡i thÃ´ng tin cáº§n
            if 'ruby wings' in message_lower or 'cÃ´ng ty' in message_lower:
                reply = "ðŸ›ï¸ **GIá»šI THIá»†U RUBY WINGS TRAVEL** ðŸ›ï¸\n\n"
                reply += "Ruby Wings lÃ  Ä‘Æ¡n vá»‹ tá»• chá»©c tour du lá»‹ch tráº£i nghiá»‡m Ä‘áº·c sáº¯c, chuyÃªn sÃ¢u vá»:\n\n"
                reply += "ðŸŽ¯ **3 TRá»¤ Cá»˜T CHÃNH:**\n"
                reply += "1. **Tour Lá»‹ch Sá»­ - Tri Ã‚n:** HÃ nh trÃ¬nh vá» nguá»“n, káº¿t ná»‘i quÃ¡ khá»©\n"
                reply += "2. **Tour Retreat - Chá»¯a LÃ nh:** Thiá»n, khÃ­ cÃ´ng, tÄ©nh tÃ¢m giá»¯a thiÃªn nhiÃªn\n"
                reply += "3. **Tour Tráº£i Nghiá»‡m - KhÃ¡m PhÃ¡:** VÄƒn hÃ³a, áº©m thá»±c, Ä‘á»i sá»‘ng Ä‘á»‹a phÆ°Æ¡ng\n\n"
                reply += "âœ¨ **TRIáº¾T LÃ HOáº T Äá»˜NG:**\n"
                reply += "â€¢ Chuáº©n má»±c trong dá»‹ch vá»¥\n"
                reply += "â€¢ ChÃ¢n thÃ nh trong káº¿t ná»‘i\n"
                reply += "â€¢ Chiá»u sÃ¢u trong tráº£i nghiá»‡m\n\n"
                reply += "ðŸŒ¿ **GIÃ TRá»Š Cá»T LÃ•I:**\n"
                reply += "â€¢ TÃ´n vinh lá»‹ch sá»­ dÃ¢n tá»™c\n"
                reply += "â€¢ Báº£o tá»“n vÄƒn hÃ³a báº£n Ä‘á»‹a\n"
                reply += "â€¢ Lan tá»a nÄƒng lÆ°á»£ng tÃ­ch cá»±c\n\n"
                reply += "ðŸ“ž **Káº¿t ná»‘i vá»›i chÃºng tÃ´i:** 0332510486"
            
            elif 'triáº¿t lÃ½' in message_lower or 'chuáº©n má»±c' in message_lower:
                reply = "âœ¨ **TRIáº¾T LÃ 'CHUáº¨N Má»°C - CHÃ‚N THÃ€NH - CÃ“ CHIá»€U SÃ‚U'** âœ¨\n\n"
                reply += "Triáº¿t lÃ½ nÃ y Ä‘Æ°á»£c thá»ƒ hiá»‡n trong má»i tour cá»§a Ruby Wings:\n\n"
                reply += "ðŸ† **CHUáº¨N Má»°C:**\n"
                reply += "â€¢ TiÃªu chuáº©n dá»‹ch vá»¥ cao nháº¥t\n"
                reply += "â€¢ An toÃ n tuyá»‡t Ä‘á»‘i cho khÃ¡ch hÃ ng\n"
                reply += "â€¢ ChuyÃªn nghiá»‡p trong tá»«ng chi tiáº¿t\n\n"
                reply += "â¤ï¸ **CHÃ‚N THÃ€NH:**\n"
                reply += "â€¢ Káº¿t ná»‘i tháº­t vá»›i con ngÆ°á»i, vÄƒn hÃ³a\n"
                reply += "â€¢ Äá»“ng hÃ nh chÃ¢n thÃ nh cÃ¹ng khÃ¡ch hÃ ng\n"
                reply += "â€¢ TÆ° váº¥n trung thá»±c, minh báº¡ch\n\n"
                reply += "ðŸŒŒ **CÃ“ CHIá»€U SÃ‚U:**\n"
                reply += "â€¢ Tráº£i nghiá»‡m cÃ³ Ã½ nghÄ©a, giÃ¡ trá»‹\n"
                reply += "â€¢ KhÃ¡m phÃ¡ báº£n cháº¥t, khÃ´ng chá»‰ bá» ná»•i\n"
                reply += "â€¢ Äá»ng láº¡i bÃ i há»c, cáº£m xÃºc sÃ¢u sáº¯c\n\n"
                reply += "ðŸ“ž **Tráº£i nghiá»‡m triáº¿t lÃ½ nÃ y trong tour:** 0332510486"
            
            else:
                # DÃ¹ng AI cho cÃ¡c cÃ¢u há»i chung khÃ¡c
                if client and HAS_OPENAI:
                    try:
                        prompt = f"""Báº¡n lÃ  Ä‘áº¡i diá»‡n Ruby Wings Travel. Tráº£ lá»i cÃ¢u há»i chung vá» cÃ´ng ty.

CÃ‚U Há»ŽI: {user_message}

THÃ”NG TIN CÃ”NG TY:
- TÃªn: Ruby Wings Travel
- ChuyÃªn: Tour tráº£i nghiá»‡m lá»‹ch sá»­, retreat, vÄƒn hÃ³a
- Triáº¿t lÃ½: Chuáº©n má»±c - ChÃ¢n thÃ nh - CÃ³ chiá»u sÃ¢u
- Hotline: 0332510486

YÃŠU Cáº¦U:
1. Tráº£ lá»i Ä‘Ãºng trá»ng tÃ¢m cÃ¢u há»i
2. Giá»›i thiá»‡u ngáº¯n gá»n vá» Ruby Wings náº¿u phÃ¹ há»£p
3. Káº¿t thÃºc báº±ng lá»i má»i tÃ¬m hiá»ƒu tour cá»¥ thá»ƒ
4. Giá»ng vÄƒn chuyÃªn nghiá»‡p, thÃ¢n thiá»‡n

Tráº£ lá»i trong 150-200 tá»«."""

                        response = client.chat.completions.create(
                            model=CHAT_MODEL,
                            messages=[
                                {"role": "system", "content": prompt},
                                {"role": "user", "content": user_message}
                            ],
                            temperature=0.5,
                            max_tokens=300
                        )
                        
                        if response.choices:
                            reply = response.choices[0].message.content or ""
                            if "0332510486" not in reply:
                                reply += "\n\nðŸ“ž **LiÃªn há»‡ tÆ° váº¥n tour:** 0332510486"
                        else:
                            reply = "Ruby Wings lÃ  cÃ´ng ty tá»• chá»©c tour tráº£i nghiá»‡m Ä‘áº·c sáº¯c vá»›i triáº¿t lÃ½ 'Chuáº©n má»±c - ChÃ¢n thÃ nh - CÃ³ chiá»u sÃ¢u'. ChÃºng tÃ´i chuyÃªn vá» cÃ¡c tour lá»‹ch sá»­, retreat thiá»n Ä‘á»‹nh, vÃ  khÃ¡m phÃ¡ vÄƒn hÃ³a."
                    
                    except Exception as e:
                        logger.error(f"OpenAI general info error: {e}")
                        reply = "Ruby Wings Travel chuyÃªn tá»• chá»©c cÃ¡c tour tráº£i nghiá»‡m Ã½ nghÄ©a. Äá»ƒ biáº¿t thÃªm chi tiáº¿t, vui lÃ²ng liÃªn há»‡ hotline 0332510486."
                else:
                    reply = "Ruby Wings Travel - Äá»“ng hÃ nh cÃ¹ng báº¡n trong nhá»¯ng hÃ nh trÃ¬nh Ã½ nghÄ©a. ðŸ“ž Hotline: 0332510486"
        
        # ðŸ”¹ CASE 6: LOCATION & WEATHER INFO
        elif 'location_info' in detected_intents or 'weather_info' in detected_intents:
            logger.info("ðŸŒ¤ï¸ Processing location/weather inquiry")
            
            # XÃ¡c Ä‘á»‹nh Ä‘á»‹a Ä‘iá»ƒm Ä‘Æ°á»£c há»i
            locations = ['huáº¿', 'quáº£ng trá»‹', 'báº¡ch mÃ£', 'trÆ°á»ng sÆ¡n', 'Ä‘Ã´ng hÃ ']
            mentioned_location = None
            
            for loc in locations:
                if loc in message_lower:
                    mentioned_location = loc
                    break
            
            if mentioned_location:
                if 'weather' in message_lower or 'thá»i tiáº¿t' in message_lower:
                    # Xá»­ lÃ½ cÃ¢u há»i thá»i tiáº¿t
                    reply = f"ðŸŒ¤ï¸ **THÃ”NG TIN THá»œI TIáº¾T {mentioned_location.upper()}** ðŸŒ¤ï¸\n\n"
                    
                    if mentioned_location == 'huáº¿':
                        reply += "**ThÃ¡ng 12 táº¡i Huáº¿:**\n"
                        reply += "â€¢ Nhiá»‡t Ä‘á»™: 18-24Â°C (mÃ¡t máº»)\n"
                        reply += "â€¢ Thá»i tiáº¿t: Ãt mÆ°a, nhiá»u náº¯ng nháº¹\n"
                        reply += "â€¢ Äáº·c Ä‘iá»ƒm: Se láº¡nh vá» Ä‘Ãªm vÃ  sÃ¡ng\n"
                        reply += "â€¢ LÆ°u Ã½: Mang theo Ã¡o khoÃ¡c nháº¹\n\n"
                    elif mentioned_location == 'báº¡ch mÃ£':
                        reply += "**Thá»i tiáº¿t Báº¡ch MÃ£:**\n"
                        reply += "â€¢ Nhiá»‡t Ä‘á»™: 15-22Â°C (mÃ¡t láº¡nh)\n"
                        reply += "â€¢ Äáº·c Ä‘iá»ƒm: SÆ°Æ¡ng mÃ¹ buá»•i sÃ¡ng\n"
                        reply += "â€¢ LÆ°u Ã½: Mang giÃ y trekking, Ã¡o áº¥m\n\n"
                    else:
                        reply += f"**Thá»i tiáº¿t {mentioned_location.title()}:**\n"
                        reply += "â€¢ Miá»n Trung: KhÃ­ háº­u nhiá»‡t Ä‘á»›i giÃ³ mÃ¹a\n"
                        reply += "â€¢ MÃ¹a khÃ´: Tá»« thÃ¡ng 1-8 (Ã­t mÆ°a)\n"
                        reply += "â€¢ MÃ¹a mÆ°a: Tá»« thÃ¡ng 9-12 (mÆ°a nhiá»u)\n\n"
                    
                    reply += "ðŸ“… **Thá»i Ä‘iá»ƒm lÃ½ tÆ°á»Ÿng Ä‘á»ƒ Ä‘i tour:**\n"
                    reply += "â€¢ ThÃ¡ng 1-4: Thá»i tiáº¿t Ä‘áº¹p nháº¥t\n"
                    reply += "â€¢ ThÃ¡ng 5-8: Náº¯ng Ä‘áº¹p, phÃ¹ há»£p trekking\n"
                    reply += "â€¢ ThÃ¡ng 9-12: MÆ°a nhiá»u, check ká»¹ dá»± bÃ¡o\n\n"
                    reply += "ðŸ“ž **TÆ° váº¥n tour phÃ¹ há»£p thá»i tiáº¿t:** 0332510486"
                
                else:
                    # Xá»­ lÃ½ cÃ¢u há»i Ä‘á»‹a Ä‘iá»ƒm chung
                    reply = f"ðŸ“ **THÃ”NG TIN {mentioned_location.upper()}** ðŸ“\n\n"
                    
                    if mentioned_location == 'huáº¿':
                        reply += "**Huáº¿ - Kinh Ä‘Ã´ cá»• cá»§a Viá»‡t Nam:**\n"
                        reply += "â€¢ Di sáº£n vÄƒn hÃ³a UNESCO\n"
                        reply += "â€¢ Ná»•i tiáº¿ng: Äáº¡i Ná»™i, LÄƒng táº©m, SÃ´ng HÆ°Æ¡ng\n"
                        reply += "â€¢ áº¨m thá»±c: BÃºn bÃ² Huáº¿, bÃ¡nh bÃ¨o, cÆ¡m háº¿n\n"
                        reply += "â€¢ Tour phá»• biáº¿n: Di sáº£n Huáº¿, áº©m thá»±c Huáº¿\n\n"
                    elif mentioned_location == 'báº¡ch mÃ£':
                        reply += "**Báº¡ch MÃ£ - VÆ°á»n quá»‘c gia:**\n"
                        reply += "â€¢ Äá»™ cao: 1.450m so vá»›i má»±c nÆ°á»›c biá»ƒn\n"
                        reply += "â€¢ Há»‡ sinh thÃ¡i: Rá»«ng nguyÃªn sinh Ä‘a dáº¡ng\n"
                        reply += "â€¢ Hoáº¡t Ä‘á»™ng: Trekking, thiá»n, ngáº¯m cáº£nh\n"
                        reply += "â€¢ Tour phá»• biáº¿n: Retreat Báº¡ch MÃ£ 1 ngÃ y\n\n"
                    elif mentioned_location == 'trÆ°á»ng sÆ¡n':
                        reply += "**TrÆ°á»ng SÆ¡n - DÃ£y nÃºi hÃ¹ng vÄ©:**\n"
                        "â€¢ Ã nghÄ©a lá»‹ch sá»­: ÄÆ°á»ng Há»“ ChÃ­ Minh huyá»n thoáº¡i\n"
                        reply += "â€¢ VÄƒn hÃ³a: Cá»™ng Ä‘á»“ng VÃ¢n Kiá»u - Pa KÃ´\n"
                        reply += "â€¢ Hoáº¡t Ä‘á»™ng: TÃ¬m hiá»ƒu lá»‹ch sá»­, vÄƒn hÃ³a\n"
                        reply += "â€¢ Tour phá»• biáº¿n: MÆ°a Äá» vÃ  TrÆ°á»ng SÆ¡n\n\n"
                    
                    reply += "ðŸŽ¯ **TOUR PHÃ™ Há»¢P Táº I ÄÃ‚Y:**\n"
                    # TÃ¬m tour táº¡i Ä‘á»‹a Ä‘iá»ƒm nÃ y
                    location_tours = []
                    for idx, tour in TOURS_DB.items():
                        if tour.location and mentioned_location in tour.location.lower():
                            location_tours.append(tour)
                    
                    if location_tours:
                        for tour in location_tours[:3]:
                            reply += f"â€¢ **{tour.name}**"
                            if tour.duration:
                                reply += f" ({tour.duration})"
                            reply += "\n"
                    else:
                        reply += "â€¢ Tour thiÃªn nhiÃªn Báº¡ch MÃ£\n"
                        reply += "â€¢ Tour lá»‹ch sá»­ TrÆ°á»ng SÆ¡n\n"
                        reply += "â€¢ Tour di sáº£n Huáº¿\n"
                    
                    reply += "\nðŸ“ž **Äáº·t tour khÃ¡m phÃ¡:** 0332510486"
            
            else:
                reply = "Ruby Wings tá»• chá»©c tour táº¡i nhiá»u Ä‘á»‹a Ä‘iá»ƒm: Huáº¿, Quáº£ng Trá»‹, Báº¡ch MÃ£, TrÆ°á»ng SÆ¡n. Báº¡n quan tÃ¢m tour táº¡i khu vá»±c nÃ o?"
        
        # ðŸ”¹ CASE 7: FOOD & CULTURE INFO
        elif 'food_info' in detected_intents or 'culture_info' in detected_intents:
            logger.info("ðŸœ Processing food/culture inquiry")
            
            if 'bÃ¡nh bÃ¨o' in message_lower or 'áº©m thá»±c huáº¿' in message_lower:
                reply = "ðŸœ **BÃNH BÃˆO HUáº¾ - Äáº¶C Sáº¢N Ná»”I TIáº¾NG** ðŸœ\n\n"
                reply += "**Äáº·c Ä‘iá»ƒm:**\n"
                reply += "â€¢ LÃ m tá»« bá»™t gáº¡o, háº¥p trong chÃ©n nhá»\n"
                reply += "â€¢ NhÃ¢n: TÃ´m chÃ¡y, thá»‹t xay, má»¡ hÃ nh\n"
                reply += "â€¢ NÆ°á»›c cháº¥m: Máº¯m nÃªm Huáº¿ Ä‘áº·c trÆ°ng\n"
                reply += "â€¢ Ä‚n kÃ¨m: Rau sá»‘ng, á»›t xanh\n\n"
                reply += "ðŸŽ¯ **TRáº¢I NGHIá»†M TRONG TOUR:**\n"
                reply += "â€¢ Tour áº¨m thá»±c Huáº¿: Há»c lÃ m bÃ¡nh bÃ¨o\n"
                reply += "â€¢ Tour VÄƒn hÃ³a: ThÄƒm lÃ ng nghá» truyá»n thá»‘ng\n"
                reply += "â€¢ Tour ÄÃªm Huáº¿: ThÆ°á»Ÿng thá»©c Ä‘áº·c sáº£n\n\n"
                reply += "ðŸ“ž **Äáº·t tour áº©m thá»±c Huáº¿:** 0332510486"
            
            elif 'vÄƒn hÃ³a' in message_lower or 'lá»‹ch sá»­' in message_lower:
                reply = "ðŸ›ï¸ **VÄ‚N HÃ“A & Lá»ŠCH Sá»¬ MIá»€N TRUNG** ðŸ›ï¸\n\n"
                reply += "**Äiá»ƒm ná»•i báº­t:**\n"
                reply += "â€¢ Di sáº£n Huáº¿: Cá»‘ Ä‘Ã´ triá»u Nguyá»…n\n"
                reply += "â€¢ Chiáº¿n tranh: Äá»‹a Ä‘áº¡o Vá»‹nh Má»‘c, ThÃ nh cá»• Quáº£ng Trá»‹\n"
                reply += "â€¢ VÄƒn hÃ³a báº£n Ä‘á»‹a: DÃ¢n tá»™c VÃ¢n Kiá»u, Pa KÃ´\n"
                reply += "â€¢ Kiáº¿n trÃºc: NhÃ  rÆ°á»ng, Ä‘Ã¬nh lÃ ng\n\n"
                reply += "ðŸŽ¯ **TOUR VÄ‚N HÃ“A Ná»”I Báº¬T:**\n"
                
                # TÃ¬m tour vÄƒn hÃ³a
                culture_tours = []
                for idx, tour in TOURS_DB.items():
                    if tour.tags and any('history' in tag or 'culture' in tag for tag in tour.tags):
                        culture_tours.append(tour)
                
                if culture_tours:
                    for tour in culture_tours[:3]:
                        reply += f"â€¢ **{tour.name}**\n"
                        if tour.summary:
                            reply += f"  {tour.summary[:80]}...\n"
                else:
                    reply += "â€¢ MÆ°a Äá» vÃ  TrÆ°á»ng SÆ¡n\n"
                    reply += "â€¢ KÃ½ á»©c - Lá»‹ch Sá»­ vÃ  Äáº¡i NgÃ n\n"
                    reply += "â€¢ Di sáº£n Huáº¿ & Äáº§m Chuá»“n\n\n"
                
                reply += "\nðŸ“ž **TÆ° váº¥n tour vÄƒn hÃ³a:** 0332510486"
            
            else:
                reply = "Miá»n Trung Viá»‡t Nam ná»•i tiáº¿ng vá»›i áº©m thá»±c phong phÃº vÃ  vÄƒn hÃ³a Ä‘a dáº¡ng. Ruby Wings cÃ³ nhiá»u tour khÃ¡m phÃ¡ áº©m thá»±c vÃ  vÄƒn hÃ³a Ä‘áº·c sáº¯c."
        
        # ðŸ”¹ CASE 8: WELLNESS & MEDITATION INFO
        elif 'wellness_info' in detected_intents:
            logger.info("ðŸ•‰ï¸ Processing wellness/meditation inquiry")
            
            if 'thiá»n' in message_lower or 'meditation' in message_lower:
                reply = "ðŸ•‰ï¸ **THIá»€N & Lá»¢I ÃCH Sá»¨C KHá»ŽE** ðŸ•‰ï¸\n\n"
                reply += "**Lá»£i Ã­ch chÃ­nh:**\n"
                reply += "1. **Giáº£m cÄƒng tháº³ng:** Giáº£m cortisol, tÄƒng serotonin\n"
                reply += "2. **Cáº£i thiá»‡n táº­p trung:** TÄƒng kháº£ nÄƒng chÃº Ã½\n"
                reply += "3. **TÄƒng cÆ°á»ng sá»©c khá»e:** Háº¡ huyáº¿t Ã¡p, cáº£i thiá»‡n tim máº¡ch\n"
                reply += "4. **CÃ¢n báº±ng cáº£m xÃºc:** Kiá»ƒm soÃ¡t lo Ã¢u, tráº§m cáº£m\n"
                reply += "5. **NÃ¢ng cao nháº­n thá»©c:** Hiá»ƒu rÃµ báº£n thÃ¢n hÆ¡n\n\n"
                reply += "ðŸŽ¯ **TOUR THIá»€N & RETREAT RUBY WINGS:**\n"
                
                # TÃ¬m tour thiá»n
                meditation_tours = []
                for idx, tour in TOURS_DB.items():
                    if tour.tags and any('meditation' in tag or 'retreat' in tag for tag in tour.tags):
                        meditation_tours.append(tour)
                
                if meditation_tours:
                    for tour in meditation_tours[:3]:
                        reply += f"â€¢ **{tour.name}**\n"
                        if tour.duration:
                            reply += f"  â±ï¸ {tour.duration}"
                        if tour.location:
                            reply += f" | ðŸ“ {tour.location[:30]}"
                        reply += "\n"
                else:
                    reply += "â€¢ Non nÆ°á»›c Báº¡ch MÃ£ - 1 ngÃ y thiá»n\n"
                    reply += "â€¢ Retreat TrÆ°á»ng SÆ¡n - 2 ngÃ y 1 Ä‘Ãªm\n"
                    reply += "â€¢ KhÃ­ cÃ´ng giá»¯a Ä‘áº¡i ngÃ n\n\n"
                
                reply += "\nðŸ’¡ **PhÃ¹ há»£p cho:** NgÆ°á»i stress, cáº§n cÃ¢n báº±ng, muá»‘n tÄ©nh tÃ¢m\n"
                reply += "ðŸ“ž **Äáº·t retreat thiá»n:** 0332510486"
            
            else:
                reply = "Ruby Wings chuyÃªn tá»• chá»©c cÃ¡c tour retreat káº¿t há»£p thiá»n, khÃ­ cÃ´ng vÃ  trá»‹ liá»‡u thiÃªn nhiÃªn. LiÃªn há»‡ 0332510486 Ä‘á»ƒ Ä‘Æ°á»£c tÆ° váº¥n."
        
        # ðŸ”¹ CASE 9: GROUP & CUSTOM REQUEST
        elif 'group_info' in detected_intents or 'custom_request' in detected_intents:
            logger.info("ðŸ‘¥ Processing group/custom request")
            
            if 'nhÃ³m' in message_lower or 'Ä‘oÃ n' in message_lower:
                reply = "ðŸ‘¥ **TOUR NHÃ“M & Æ¯U ÄÃƒI Äáº¶C BIá»†T** ðŸ‘¥\n\n"
                reply += "**ChÃ­nh sÃ¡ch Æ°u Ä‘Ã£i nhÃ³m:**\n"
                reply += "â€¢ NhÃ³m 10-15 ngÆ°á»i: Giáº£m 10%\n"
                reply += "â€¢ NhÃ³m 16-20 ngÆ°á»i: Giáº£m 15%\n"
                reply += "â€¢ NhÃ³m 21+ ngÆ°á»i: Giáº£m 20% + quÃ  táº·ng\n"
                reply += "â€¢ Cá»±u chiáº¿n binh: Æ¯u Ä‘Ã£i thÃªm 5%\n\n"
                reply += "ðŸŽ¯ **TOUR PHÃ™ Há»¢P NHÃ“M:**\n"
                reply += "1. **Teambuilding cÃ´ng ty:** Tour káº¿t há»£p hoáº¡t Ä‘á»™ng nhÃ³m\n"
                reply += "2. **Gia Ä‘Ã¬nh Ä‘a tháº¿ há»‡:** Tour nháº¹ nhÃ ng, Ä‘a dáº¡ng hoáº¡t Ä‘á»™ng\n"
                reply += "3. **NhÃ³m báº¡n:** Tour khÃ¡m phÃ¡, phiÃªu lÆ°u\n"
                reply += "4. **NhÃ³m há»c sinh/sinh viÃªn:** Tour giÃ¡o dá»¥c, tráº£i nghiá»‡m\n\n"
                reply += "âœ¨ **Dá»ŠCH Vá»¤ Äáº¶C BIá»†T CHO NHÃ“M:**\n"
                reply += "â€¢ Thiáº¿t káº¿ tour riÃªng theo yÃªu cáº§u\n"
                reply += "â€¢ HÆ°á»›ng dáº«n viÃªn chuyÃªn biá»‡t\n"
                reply += "â€¢ PhÆ°Æ¡ng tiá»‡n riÃªng, linh hoáº¡t lá»‹ch trÃ¬nh\n"
                reply += "â€¢ Há»— trá»£ quay phim, chá»¥p áº£nh\n\n"
                reply += "ðŸ“ž **TÆ° váº¥n tour nhÃ³m:** 0332510486"
            
            elif 'cÃ¡ nhÃ¢n hÃ³a' in message_lower or 'riÃªng' in message_lower or 'theo yÃªu cáº§u' in message_lower:
                reply = "âœ¨ **TOUR CÃ NHÃ‚N HÃ“A - THEO YÃŠU Cáº¦U** âœ¨\n\n"
                reply += "Ruby Wings chuyÃªn thiáº¿t káº¿ tour riÃªng biá»‡t:\n\n"
                reply += "ðŸŽ¯ **QUY TRÃŒNH THIáº¾T Káº¾ TOUR RIÃŠNG:**\n"
                reply += "1. **Tiáº¿p nháº­n yÃªu cáº§u:** Hiá»ƒu rÃµ nhu cáº§u, sá»Ÿ thÃ­ch\n"
                reply += "2. **Thiáº¿t káº¿ lá»‹ch trÃ¬nh:** PhÃ¹ há»£p thá»i gian, ngÃ¢n sÃ¡ch\n"
                reply += "3. **BÃ¡o giÃ¡ chi tiáº¿t:** Minh báº¡ch, cáº¡nh tranh\n"
                reply += "4. **Chá»‰nh sá»­a & hoÃ n thiá»‡n:** Theo feedback cá»§a báº¡n\n"
                reply += "5. **Triá»ƒn khai tour:** ChuyÃªn nghiá»‡p, táº­n tÃ¢m\n\n"
                reply += "ðŸ† **TOUR RIÃŠNG Ná»”I Báº¬T ÄÃƒ THá»°C HIá»†N:**\n"
                reply += "â€¢ Tour gia Ä‘Ã¬nh 3 tháº¿ há»‡ (tá»« 6-70 tuá»•i)\n"
                reply += "â€¢ Tour teambuilding cÃ´ng ty (50 ngÆ°á»i)\n"
                reply += "â€¢ Tour retreat thiá»n 7 ngÃ y\n"
                reply += "â€¢ Tour nhiáº¿p áº£nh chuyÃªn nghiá»‡p\n\n"
                reply += "ðŸ’¡ **YÃŠU Cáº¦U TOUR RIÃŠNG Cáº¦N CÃ“:**\n"
                reply += "â€¢ Sá»‘ lÆ°á»£ng ngÆ°á»i tham gia\n"
                reply += "â€¢ Thá»i gian dá»± kiáº¿n\n"
                reply += "â€¢ NgÃ¢n sÃ¡ch Æ°á»›c tÃ­nh\n"
                reply += "â€¢ Sá»Ÿ thÃ­ch, yÃªu cáº§u Ä‘áº·c biá»‡t\n\n"
                reply += "ðŸ“ž **LiÃªn há»‡ thiáº¿t káº¿ tour riÃªng:** 0332510486"
            
            else:
                reply = "Ruby Wings cÃ³ chÃ­nh sÃ¡ch Æ°u Ä‘Ã£i Ä‘áº·c biá»‡t cho nhÃ³m vÃ  dá»‹ch vá»¥ thiáº¿t káº¿ tour theo yÃªu cáº§u. LiÃªn há»‡ hotline Ä‘á»ƒ biáº¿t thÃªm chi tiáº¿t."
        
        # ðŸ”¹ CASE 10: BOOKING & POLICY INFO
        elif 'booking_info' in detected_intents or 'policy' in detected_intents:
            logger.info("ðŸ“ Processing booking/policy inquiry")
            
            if 'Ä‘áº·t tour' in message_lower or 'booking' in message_lower:
                reply = "ðŸ“ **QUY TRÃŒNH Äáº¶T TOUR RUBY WINGS** ðŸ“\n\n"
                reply += "**BÆ°á»›c 1: TÆ° váº¥n & chá»n tour**\n"
                reply += "â€¢ LiÃªn há»‡ hotline 0332510486\n"
                reply += "â€¢ Nháº­n tÆ° váº¥n tour phÃ¹ há»£p\n"
                reply += "â€¢ XÃ¡c nháº­n lá»‹ch trÃ¬nh, giÃ¡ cáº£\n\n"
                reply += "**BÆ°á»›c 2: Äáº·t cá»c & xÃ¡c nháº­n**\n"
                reply += "â€¢ Äáº·t cá»c 30% giÃ¡ trá»‹ tour\n"
                reply += "â€¢ KÃ½ há»£p Ä‘á»“ng dá»‹ch vá»¥\n"
                reply += "â€¢ Nháº­n xÃ¡c nháº­n booking\n\n"
                reply += "**BÆ°á»›c 3: Chuáº©n bá»‹ & thanh toÃ¡n**\n"
                reply += "â€¢ Thanh toÃ¡n 70% cÃ²n láº¡i trÆ°á»›c 7 ngÃ y\n"
                reply += "â€¢ Nháº­n thÃ´ng tin chi tiáº¿t tour\n"
                reply += "â€¢ Chuáº©n bá»‹ hÃ nh lÃ½, giáº¥y tá»\n\n"
                reply += "**BÆ°á»›c 4: Khá»Ÿi hÃ nh & tráº£i nghiá»‡m**\n"
                reply += "â€¢ ÄÃ³n khÃ¡ch táº¡i Ä‘iá»ƒm háº¹n\n"
                reply += "â€¢ Tráº£i nghiá»‡m tour tuyá»‡t vá»i\n"
                reply += "â€¢ Feedback sau tour\n\n"
                reply += "ðŸ“ž **Äáº·t tour ngay:** 0332510486"
            
            elif 'giáº£m giÃ¡' in message_lower or 'Æ°u Ä‘Ã£i' in message_lower:
                reply = "ðŸŽ **CHÃNH SÃCH Æ¯U ÄÃƒI & KHUYáº¾N MÃƒI** ðŸŽ\n\n"
                reply += "**1. Æ¯u Ä‘Ã£i nhÃ³m:**\n"
                reply += "â€¢ 10-15 ngÆ°á»i: Giáº£m 10%\n"
                reply += "â€¢ 16-20 ngÆ°á»i: Giáº£m 15%\n"
                reply += "â€¢ 21+ ngÆ°á»i: Giáº£m 20%\n\n"
                reply += "**2. Æ¯u Ä‘Ã£i Ä‘áº·t sá»›m:**\n"
                reply += "â€¢ Äáº·t trÆ°á»›c 30 ngÃ y: Giáº£m 5%\n"
                reply += "â€¢ Äáº·t trÆ°á»›c 60 ngÃ y: Giáº£m 8%\n\n"
                reply += "**3. Æ¯u Ä‘Ã£i Ä‘áº·c biá»‡t:**\n"
                reply += "â€¢ Cá»±u chiáº¿n binh: ThÃªm 5%\n"
                reply += "â€¢ Há»c sinh/sinh viÃªn: Giáº£m 10%\n"
                reply += "â€¢ KhÃ¡ch quay láº¡i: Giáº£m 5%\n\n"
                reply += "**4. ChÆ°Æ¡ng trÃ¬nh tÃ­ch Ä‘iá»ƒm:**\n"
                reply += "â€¢ Má»—i tour: TÃ­ch 1 Ä‘iá»ƒm\n"
                reply += "â€¢ 5 Ä‘iá»ƒm: Giáº£m 10% tour tiáº¿p theo\n"
                reply += "â€¢ 10 Ä‘iá»ƒm: Táº·ng 1 tour 1 ngÃ y\n\n"
                reply += "ðŸ“ž **Nháº­n Æ°u Ä‘Ã£i tá»‘t nháº¥t:** 0332510486"
            
            else:
                reply = "Ruby Wings cÃ³ chÃ­nh sÃ¡ch Æ°u Ä‘Ã£i háº¥p dáº«n vÃ  quy trÃ¬nh Ä‘áº·t tour chuyÃªn nghiá»‡p. LiÃªn há»‡ hotline Ä‘á»ƒ Ä‘Æ°á»£c tÆ° váº¥n chi tiáº¿t."
        
        # ðŸ”¹ CASE 11: OUT OF SCOPE QUESTIONS (xá»­ lÃ½ báº±ng AI)
        else:
            logger.info("ðŸ¤– Processing out-of-scope question with AI")
            
            # Kiá»ƒm tra xem cÃ³ pháº£i cÃ¢u há»i ngoÃ i pháº¡m vi khÃ´ng
            out_of_scope_keywords = [
                'vÃ ng', 'chá»©ng khoÃ¡n', 'tá»‰ giÃ¡', 'thá»i sá»±', 'tin tá»©c',
                'chuyá»‡n cÆ°á»i', 'Ä‘á»‘ vui', 'game', 'giáº£i trÃ­',
                'thá»ƒ thao', 'bÃ³ng Ä‘Ã¡', 'ca nháº¡c', 'phim áº£nh',
                'chÃ­nh trá»‹', 'tÃ´n giÃ¡o', 'nháº¡y cáº£m'
            ]
            
            is_out_of_scope = any(keyword in message_lower for keyword in out_of_scope_keywords)
            
            if is_out_of_scope and client and HAS_OPENAI:
                try:
                    prompt = f"""Báº¡n lÃ  tÆ° váº¥n viÃªn Ruby Wings Travel. KhÃ¡ch há»i cÃ¢u há»i ngoÃ i pháº¡m vi tour du lá»‹ch.

CÃ‚U Há»ŽI: {user_message}

YÃŠU Cáº¦U:
1. Lá»‹ch sá»± thÃ´ng bÃ¡o khÃ´ng thá»ƒ tráº£ lá»i cÃ¢u há»i nÃ y
2. Chuyá»ƒn hÆ°á»›ng sang chá»§ Ä‘á» tour du lá»‹ch
3. Giá»›i thiá»‡u ngáº¯n vá» Ruby Wings
4. Äá» nghá»‹ liÃªn há»‡ hotline náº¿u cáº§n

Tráº£ lá»i ngáº¯n gá»n, lá»‹ch sá»±, chuyÃªn nghiá»‡p."""

                    response = client.chat.completions.create(
                        model=CHAT_MODEL,
                        messages=[
                            {"role": "system", "content": prompt},
                            {"role": "user", "content": user_message}
                        ],
                        temperature=0.4,
                        max_tokens=200
                    )
                    
                    if response.choices:
                        reply = response.choices[0].message.content or ""
                    else:
                        reply = "Xin lá»—i, tÃ´i chÆ°a thá»ƒ tráº£ lá»i cÃ¢u há»i nÃ y. TÃ´i lÃ  trá»£ lÃ½ AI cá»§a Ruby Wings Travel, chuyÃªn tÆ° váº¥n vá» cÃ¡c tour du lá»‹ch tráº£i nghiá»‡m. Báº¡n cÃ³ cÃ¢u há»i nÃ o vá» tour khÃ´ng?"
                
                except Exception as e:
                    logger.error(f"OpenAI out-of-scope error: {e}")
                    reply = "TÃ´i chuyÃªn tÆ° váº¥n vá» cÃ¡c tour du lá»‹ch cá»§a Ruby Wings. Báº¡n cÃ³ cÃ¢u há»i nÃ o vá» tour khÃ´ng?"
            
            else:
                # Default: Semantic search + AI
                search_results = query_index(user_message, TOP_K)
                
                if UpgradeFlags.is_enabled("2_DEDUPLICATION") and search_results:
                    search_results = DeduplicationEngine.deduplicate_passages(search_results)
                
                # Chuáº©n bá»‹ context cho AI
                context_info = {
                    'user_message': user_message,
                    'tour_indices': tour_indices,
                    'detected_intents': detected_intents,
                    'filters': mandatory_filters.to_dict() if mandatory_filters else {}
                }
                
                # Táº¡o prompt thÃ´ng minh
                prompt = _prepare_llm_prompt(user_message, search_results, context_info)
                
                # Gá»i AI
                if client and HAS_OPENAI:
                    try:
                        messages = [
                            {"role": "system", "content": prompt},
                            {"role": "user", "content": user_message}
                        ]
                        
                        response = client.chat.completions.create(
                            model=CHAT_MODEL,
                            messages=messages,
                            temperature=0.6,
                            max_tokens=500,
                            top_p=0.9,
                            frequency_penalty=0.2,
                            presence_penalty=0.1
                        )
                        
                        if response.choices:
                            reply = response.choices[0].message.content or ""
                        else:
                            reply = _generate_fallback_response(user_message, search_results, tour_indices)
                    
                    except Exception as e:
                        logger.error(f"OpenAI general error: {e}")
                        reply = _generate_fallback_response(user_message, search_results, tour_indices)
                else:
                    reply = _generate_fallback_response(user_message, search_results, tour_indices)
                
                sources = [m for _, m in search_results]
        
        # ================== ENHANCE RESPONSE QUALITY ==================
        # Äáº£m báº£o má»i response Ä‘á»u cÃ³ hotline
        if "0332510486" not in reply and "hotline" not in reply.lower():
            reply += "\n\nðŸ“ž **Hotline tÆ° váº¥n 24/7:** 0332510486"
        
        # Giá»›i háº¡n Ä‘á»™ dÃ i response
        if len(reply) > 2000:
            reply = reply[:2000] + "...\n\nðŸ’¡ Äá»ƒ biáº¿t thÃªm chi tiáº¿t, vui lÃ²ng liÃªn há»‡ hotline 0332510486"
        
        # ================== UPDATE CONTEXT ==================
        # Cáº­p nháº­t tour context náº¿u cÃ³ tour Ä‘Æ°á»£c Ä‘á» cáº­p
        if tour_indices and len(tour_indices) > 0:
            context.current_tour = tour_indices[0]
            tour = TOURS_DB.get(tour_indices[0])
            if tour:
                context.last_tour_name = tour.name
        
        # LÆ°u reply vÃ o history
        context.conversation_history.append({
            'role': 'assistant',
            'message': reply,
            'timestamp': datetime.utcnow().isoformat(),
            'tour_indices': tour_indices
        })
        
        # ================== FINAL RESPONSE ==================
        processing_time = time.time() - start_time
        
        chat_response = ChatResponse(
            reply=reply,
            sources=sources,
            context={
                "session_id": session_id,
                "current_tour": getattr(context, 'current_tour', None),
                "last_tour_name": getattr(context, 'last_tour_name', None),
                "user_preferences": getattr(context, 'user_profile', {}),
                "detected_intents": detected_intents,
                "processing_time_ms": int(processing_time * 1000),
                "tours_found": len(tour_indices),
                "complexity_score": complexity_score
            },
            tour_indices=tour_indices,
            processing_time_ms=int(processing_time * 1000),
            from_memory=False
        )
        
        # Cache response
        if UpgradeFlags.get_all_flags().get("ENABLE_CACHING", True):
            context_hash = hashlib.md5(json.dumps({
                'tour_indices': tour_indices,
                'detected_intents': detected_intents,
                'complexity': complexity_score
            }, sort_keys=True).encode()).hexdigest()
            
            cache_key = CacheSystem.get_cache_key(user_message, context_hash)
            CacheSystem.set(cache_key, chat_response.to_dict())
        
        logger.info(f"âœ… Processed in {processing_time:.2f}s | "
                   f"Intents: {detected_intents} | "
                   f"Tours: {len(tour_indices)} | "
                   f"Complexity: {complexity_score}")
        
        return jsonify(chat_response.to_dict())
    
    except Exception as e:
        logger.error(f"âŒ Chat endpoint error: {e}\n{traceback.format_exc()}")
        
        processing_time = time.time() - start_time
        
        # Smart error response
        error_response = ChatResponse(
            reply="âš¡ **CÃ³ chÃºt trá»¥c tráº·c ká»¹ thuáº­t, nhÆ°ng Ä‘á»™i ngÅ© Ruby Wings váº«n sáºµn sÃ ng há»— trá»£ báº¡n!**\n\n"
                  "ðŸ”§ **CÃ¡ch giáº£i quyáº¿t nhanh:**\n"
                  "1. **Gá»i ngay:** ðŸ“ž 0332510486 (tÆ° váº¥n trá»±c tiáº¿p)\n"
                  "2. **Thá»­ láº¡i:** GÃµ cÃ¢u há»i ngáº¯n gá»n hÆ¡n\n"
                  "3. **Chá»n tour:** 'Tour 1 ngÃ y Huáº¿', 'Tour gia Ä‘Ã¬nh 2 ngÃ y'\n\n"
                  "â° **ChÃºng tÃ´i hoáº¡t Ä‘á»™ng 24/7 Ä‘á»ƒ phá»¥c vá»¥ báº¡n!** ðŸ˜Š",
            sources=[],
            context={
                "error": str(e),
                "processing_time_ms": int(processing_time * 1000)
            },
            tour_indices=[],
            processing_time_ms=int(processing_time * 1000),
            from_memory=False
        )
        
        return jsonify(error_response.to_dict()), 500

# =========== OTHER ENDPOINTS ===========
@app.route("/")
def home():
    """Home endpoint"""
    return jsonify({
        "status": "ok",
        "version": "4.0",
        "upgrades": UpgradeFlags.get_all_flags(),
        "services": {
            "openai": "available" if client else "unavailable",
            "faiss": "available" if HAS_FAISS else "unavailable",
            "google_sheets": "available" if HAS_GOOGLE_SHEETS else "unavailable",
            "meta_capi": "available" if HAS_META_CAPI else "unavailable",
        },
        "counts": {
            "tours": len(TOURS_DB),
            "passages": len(FLAT_TEXTS),
            "tour_names": len(TOUR_NAME_TO_INDEX),
        }
    })

@app.route("/reindex", methods=["POST"])
def reindex():
    """Rebuild index endpoint"""
    secret = request.headers.get("X-RBW-ADMIN", "")
    if not secret and os.environ.get("RBW_ALLOW_REINDEX", "") != "1":
        return jsonify({"error": "reindex not allowed"}), 403
    
    load_knowledge()
    build_index(force_rebuild=True)
    
    return jsonify({
        "ok": True,
        "count": len(FLAT_TEXTS),
        "tours": len(TOURS_DB)
    })

# =========== GOOGLE SHEETS INTEGRATION ===========
_gsheet_client = None
_gsheet_client_lock = threading.Lock()

def get_gspread_client(force_refresh: bool = False):
    """Get Google Sheets client"""
    global _gsheet_client
    
    if not GOOGLE_SERVICE_ACCOUNT_JSON:
        logger.error("GOOGLE_SERVICE_ACCOUNT_JSON not set")
        return None
    
    with _gsheet_client_lock:
        if _gsheet_client is not None and not force_refresh:
            return _gsheet_client
        
        try:
            info = json.loads(GOOGLE_SERVICE_ACCOUNT_JSON)
            scopes = [
                "https://www.googleapis.com/auth/spreadsheets",
                "https://www.googleapis.com/auth/drive",
            ]
            creds = Credentials.from_service_account_info(info, scopes=scopes)
            _gsheet_client = gspread.authorize(creds)
            logger.info("âœ… Google Sheets client initialized")
            return _gsheet_client
        except Exception as e:
            logger.error(f"âŒ Google Sheets client failed: {e}")
            return None

@app.route('/api/save-lead', methods=['POST', 'OPTIONS'])
def save_lead():
    """Save lead from form submission - Äáº¦Y Äá»¦ 9 TRÆ¯á»œNG (A-I)"""
    if request.method == 'OPTIONS':
        return jsonify({'status': 'ok'}), 200
    
    try:
        data = request.get_json() or {}
        
        # Extract data
        phone = data.get('phone', '').strip()
        name = data.get('name', '').strip()
        email = data.get('email', '').strip()
        tour_interest = data.get('tour_interest', '').strip()
        page_url = data.get('page_url', '').strip()
        note = data.get('note', '').strip()
        
        if not phone:
            return jsonify({'error': 'Phone number is required'}), 400
        
        # Clean phone
        phone_clean = re.sub(r'[^\d+]', '', phone)
        
        # Validate phone
        if not re.match(r'^(0|\+?84)\d{9,10}$', phone_clean):
            return jsonify({'error': 'Invalid phone number format'}), 400
        
        # Timestamp
        timestamp = datetime.now().isoformat()
        
        # Create lead data
        lead_data = {
            'timestamp': timestamp,
            'phone': phone_clean,
            'name': name,
            'email': email,
            'tour_interest': tour_interest,
            'page_url': page_url,
            'note': note,
            'source': 'Lead Form'
        }
        
        # Send to Meta CAPI
        if ENABLE_META_CAPI_CALL and HAS_META_CAPI:
            try:
                result = send_meta_lead(
                    request,
                    phone=phone_clean,
                    contact_name=name,
                    email=email,
                    content_name=f"Tour: {tour_interest}" if tour_interest else "General Inquiry",
                    value=200000,
                    currency="VND"
                )
                increment_stat('meta_capi_calls')
                logger.info(f"âœ… Form lead sent to Meta CAPI: {phone_clean[:4]}***")
                if DEBUG and HAS_META_CAPI:
                    logger.debug(f"Meta CAPI result: {result}")
            except Exception as e:
                increment_stat('meta_capi_errors')
                logger.error(f"Meta CAPI error: {e}")
        
        # Save to Google Sheets - Äáº¦Y Äá»¦ 9 TRÆ¯á»œNG (A-I)
        if ENABLE_GOOGLE_SHEETS:
            try:
                import gspread
                from google.oauth2.service_account import Credentials
                
                if GOOGLE_SERVICE_ACCOUNT_JSON and GOOGLE_SHEET_ID:
                    creds_json = json.loads(GOOGLE_SERVICE_ACCOUNT_JSON)
                    creds = Credentials.from_service_account_info(
                        creds_json,
                        scopes=['https://www.googleapis.com/auth/spreadsheets']
                    )
                    
                    gc = gspread.authorize(creds)
                    sh = gc.open_by_key(GOOGLE_SHEET_ID)
                    ws = sh.worksheet(GOOGLE_SHEET_NAME)
                    
                    # ÄÃšng 9 TRÆ¯á»œNG THEO THá»¨ Tá»° A-I:
                    # A: created_at (timestamp)
                    # B: source_channel
                    # C: action_type
                    # D: page_url
                    # E: contact_name
                    # F: phone
                    # G: service_interest
                    # H: note
                    # I: raw_status
                    row = [
                        timestamp,                          # A: created_at
                        'Website - Lead Form',              # B: source_channel
                        'Form Submission',                  # C: action_type
                        page_url or '',                     # D: page_url
                        name or '',                         # E: contact_name
                        phone_clean,                        # F: phone
                        tour_interest or '',                # G: service_interest
                        note or email or '',                # H: note (dÃ¹ng email náº¿u khÃ´ng cÃ³ note)
                        'New'                               # I: raw_status
                    ]
                    
                    ws.append_row(row)
                    logger.info("âœ… Form lead saved to Google Sheets (9 fields)")
            except Exception as e:
                logger.error(f"Google Sheets error: {e}")
        
        # Fallback storage
        if ENABLE_FALLBACK_STORAGE:
            try:
                if os.path.exists(FALLBACK_STORAGE_PATH):
                    with open(FALLBACK_STORAGE_PATH, 'r', encoding='utf-8') as f:
                        leads = json.load(f)
                else:
                    leads = []
                
                leads.append(lead_data)
                leads = leads[-1000:]
                
                with open(FALLBACK_STORAGE_PATH, 'w', encoding='utf-8') as f:
                    json.dump(leads, f, ensure_ascii=False, indent=2)
                
                logger.info("âœ… Form lead saved to fallback storage")
            except Exception as e:
                logger.error(f"Fallback storage error: {e}")
        
        # Update stats
        increment_stat('leads')
        
        return jsonify({
            'success': True,
            'message': 'Lead Ä‘Ã£ Ä‘Æ°á»£c lÆ°u! Äá»™i ngÅ© Ruby Wings sáº½ liÃªn há»‡ sá»›m nháº¥t. ðŸ“ž',
            'data': {
                'phone': phone_clean[:3] + '***' + phone_clean[-2:],
                'timestamp': timestamp
            }
        })
        
    except Exception as e:
        logger.error(f"âŒ Save lead error: {e}")
        traceback.print_exc()
        return jsonify({'error': str(e)}), 500

@app.route('/api/call-button', methods=['POST', 'OPTIONS'])
def call_button():
    """Track call button click"""
    if request.method == 'OPTIONS':
        return jsonify({'status': 'ok'}), 200
    
    try:
        data = request.get_json() or {}
        
        page_url = data.get('page_url', '')
        call_type = data.get('call_type', 'regular')
        
        # Send to Meta CAPI
        if ENABLE_META_CAPI_CALL and HAS_META_CAPI:
            try:
                result = send_meta_call_button(
                    request,
                    page_url=page_url,
                    call_type=call_type,
                    button_location='fixed_bottom_left',
                    button_text='Gá»i ngay'
                )
                increment_stat('meta_capi_calls')
                logger.info(f"ðŸ“ž Call button tracked: {call_type}")
                if DEBUG and HAS_META_CAPI:
                    logger.debug(f"Meta CAPI result: {result}")
            except Exception as e:
                increment_stat('meta_capi_errors')
                logger.error(f"Meta CAPI call error: {e}")
        
        return jsonify({
            'success': True,
            'message': 'Call tracked',
            'timestamp': datetime.now().isoformat()
        })
        
    except Exception as e:
        logger.error(f"Call button error: {e}")
        traceback.print_exc()
        return jsonify({'error': str(e)}), 500


@app.route('/api/health', methods=['GET'])
def health_check():
    """Health check endpoint"""
    try:
        return jsonify({
            "status": "healthy",
            "timestamp": datetime.utcnow().isoformat(),
            "services": {
                "chatbot": "running",
                "openai": "available" if client else "unavailable",
                "faiss": "available" if INDEX else "unavailable",
                "tours_db": len(TOURS_DB),
                "upgrades": {k: v for k, v in UpgradeFlags.get_all_flags().items() 
                           if k.startswith("UPGRADE_")}
            },
            "memory_profile": {
                "ram_profile": RAM_PROFILE,
                "is_low_ram": IS_LOW_RAM,
                "is_high_ram": IS_HIGH_RAM,
                "tour_count": len(TOURS_DB),
                "context_count": len(SESSION_CONTEXTS)
            }
        })
    except Exception as e:
        return jsonify({
            "status": "unhealthy",
            "error": str(e)
        }), 500

# =========== INITIALIZATION ===========
def initialize_app():
    """Initialize the application"""
    logger.info("ðŸš€ Starting Ruby Wings Chatbot v4.0 (Dataclass Rewrite)...")
    
    # Apply memory optimizations
    optimize_for_memory_profile()
    
    # Load knowledge base
    load_knowledge()
    
    # Load or build tours database
    if os.path.exists(FAISS_MAPPING_PATH):
        try:
            with open(FAISS_MAPPING_PATH, 'r', encoding='utf-8') as f:
                MAPPING[:] = json.load(f)
            FLAT_TEXTS[:] = [m.get('text', '') for m in MAPPING]
            logger.info(f"ðŸ“ Loaded {len(MAPPING)} mappings from disk")
        except Exception as e:
            logger.error(f"Failed to load mappings: {e}")
    
    # Build tour databases
    index_tour_names()
    build_tours_db()
    
    # Build index in background
    def build_index_background():
        time.sleep(2)
        success = build_index(force_rebuild=False)
        if success:
            logger.info("âœ… Index ready")
        else:
            logger.warning("âš ï¸ Index building failed")
    
    threading.Thread(target=build_index_background, daemon=True).start()
    
    # Initialize Google Sheets client
    if ENABLE_GOOGLE_SHEETS:
        threading.Thread(target=get_gspread_client, daemon=True).start()
    
    # Log active upgrades
    active_upgrades = [name for name, enabled in UpgradeFlags.get_all_flags().items() 
                      if enabled and name.startswith("UPGRADE_")]
    logger.info(f"ðŸ”§ Active upgrades: {len(active_upgrades)}")
    for upgrade in active_upgrades:
        logger.info(f"   â€¢ {upgrade}")
    
    # Log memory profile
    logger.info(f"ðŸ§  Memory Profile: {RAM_PROFILE}MB | Low RAM: {IS_LOW_RAM} | High RAM: {IS_HIGH_RAM}")
    logger.info(f"ðŸ“Š Tours Database: {len(TOURS_DB)} tours loaded")
    
    logger.info("âœ… Application initialized successfully with dataclasses")

# =========== APPLICATION START ===========
if __name__ == "__main__":
    initialize_app()
    
    # Save mappings if not exists
    if MAPPING and not os.path.exists(FAISS_MAPPING_PATH):
        try:
            with open(FAISS_MAPPING_PATH, 'w', encoding='utf-8') as f:
                json.dump(MAPPING, f, ensure_ascii=False, indent=2)
            logger.info(f"ðŸ’¾ Saved mappings to {FAISS_MAPPING_PATH}")
        except Exception as e:
            logger.error(f"Failed to save mappings: {e}")
    
    # Start server
    logger.info(f"ðŸŒ Starting server on {HOST}:{PORT}")
    app.run(host=HOST, port=PORT, debug=DEBUG, threaded=True)

else:
    # For WSGI
    initialize_app()